<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>TCP拥塞控制</title>
      <link href="/2019/12/30/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/"/>
      <url>/2019/12/30/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h5 id="1-TCP拥塞检测"><a href="#1-TCP拥塞检测" class="headerlink" title="1. TCP拥塞检测"></a>1. TCP拥塞检测</h5><ul><li><p>什么是拥塞</p><p>路由器因无法处理高速率到达的流量而被迫丢弃数据信息的现象称为拥塞。</p></li><li><p>什么是TCP的拥塞控制</p><p>防止网络因为大规模的通信负载而瘫痪，在网络即将进入拥塞状态时减缓TCP传输。</p></li><li><p>怎么判断是否发送了拥塞</p><p>通常如果TCP发生了丢包，TCP首先采取的机制的重传，包括超时重传和快速重传，但是当网络处于拥塞崩溃状态时，TCP发送的包很可能会丢掉，如果选择重传数据包会加剧网络的拥塞状态。</p><p>判断网络拥塞状态是否已发生<strong>通常看丢包情况</strong>。其他的探测方法有，<strong>时延测量</strong>和<strong>显式拥塞通知</strong>。</p></li><li><p>如何减缓TCP发送</p><p>TCP使用滑动窗口机制发送和接收数据，发送速率的控制时通过调节发送窗口大小实现的，但是发送窗口大小只取决于接收方接收数据的能力。而拥塞控制需要考虑网络的拥塞状况，因此引入了一个拥塞窗口，TCP发送窗口要取通知窗口(awnd) 和拥塞窗口(cwnd)两者的最小值。</p></li></ul><hr><h5 id="2-TCP拥塞检查的一些经典算法"><a href="#2-TCP拥塞检查的一些经典算法" class="headerlink" title="2. TCP拥塞检查的一些经典算法"></a>2. TCP拥塞检查的一些经典算法</h5><ul><li><p><strong>慢启动</strong></p><ul><li><p>什么时候使用慢启动算法</p><p>当一个新的TCP连接建立或检测到由重传超时导致的丢包时，需要执行慢启动算法。</p></li><li><p>为什么要使用慢启动算法</p><p>在传输初始阶段，由于未知网络传输能力，需要缓慢探测可用传输资源，防止短时间内大量数据注入导致拥塞。慢启动算法正是针对这一问题设计的。在数据传输之处或者重传计时器检测到丢包后，需要执行慢启动。</p></li><li><p>慢启动算法的流程</p><ul><li>以一定数目的数据段开始慢启动，称为初始窗口（Init Window,IW）。初始窗口的值设为一个SMSS（发送方的最大段大小），但在其他的RFC文档中可以设置较大的值，如果2倍SMSS或3倍SMSS或者4SMSS</li><li>每当发送一个数据包并且收到了ACK，发送窗口会增加1SMSS，也就是经过一和传输轮次，窗口的大小会翻倍。</li><li>发送窗口不能无限制增长下去，慢启动算法执行过程中有一个满启动阈值，cwnd达到这个阈值后就会进入拥塞避免算法</li></ul></li></ul></li><li><p><strong>拥塞避免</strong></p><p>使用拥塞避免算法，cwnd的值呈线性增长。</p></li><li><p><strong>慢启动和拥塞避免的选择</strong></p><p>设置一个慢启动阈值，当cwnd的值小于阈值则使用慢启动算法，cwnd的值大于阈值则使用拥塞避免算法，cwnd等于阈值时既可以使用慢启动也可以使用拥塞避免。</p><p>注意慢启动阈值不是一个定值，他是动态变化的，当出现重传情况，TCP会认为操作窗口超过的网络传输能力范围，这是慢启动阈值会变成当前窗口大小的一半（慢启动阈值并不一定减小，也有可能增大）</p></li><li><p>Tahoe、Reno以及快速恢复算法</p><ul><li><p>Tahoe</p><p>当发生超时或者快速重传，都会重新进入慢启动状态</p></li><li><p>Reno（标准TCP的基础）</p><p>使用快速恢复机制：在恢复阶段，每收到一个ACK，cwnd就能增长1SMSS，相应地就意味着能发送一个新的数据包。</p></li></ul></li><li><p><strong>标准TCP</strong></p><ul><li><p>TCP连接建立之初首先是慢启动阶段，慢启动阈值通常取一个较大值（至少我awnd）。当接收到一个好的ACK（表示新的数据传输成功），cwnd会进行相应的更新</p><ul><li>cwnd+=SMSS(慢启动)（这个公式的意思时每收到一个ack，增加一个SMSS,与一次往返时延RTT增加一倍并不矛盾）</li><li>cwnd+=SMSS*SMSS/cwnd(拥塞避免)</li></ul></li><li><p>当收到三次重复ACK（表明丢包需要快速重传的信号）</p><ul><li>更新慢启动阈值(ssthresh)为大于等式（ssthresh=max(在外数据值/2,2*SMSS)）不同的操作系统实现的TCP版本这个值是不一样的</li><li>启用快速重传算法，将cwnd设为ssthresh+3SMSS</li><li>之后每接受到一个重复的ACK，cwnd展示增加1SMSS</li><li>当接受到一个好的ACK，将cwnd重设为ssthresh</li></ul><p>第二步和第三步就是快速恢复</p></li></ul></li></ul><hr><h5 id="3-对标准算法的改进"><a href="#3-对标准算法的改进" class="headerlink" title="3. 对标准算法的改进"></a>3. 对标准算法的改进</h5><p>针对标准的拥塞控制算法也提出了一些新的算法</p><ul><li><p><strong>NewReno</strong></p><ul><li><p>NewReno算法是为了解决什么问题、</p><p>快速恢复带来一个问题，当一个传输窗口出现多个数据包丢失时，一旦一个包重传成功，发送就收到了一个好的ACK，这样快速恢复阶段中cwnd窗口的暂时膨胀就会停止，而事实上丢失的其他数据包可能还没有重传完，导致出现这种情况的ACK称为<strong>局部ACK</strong>。</p><p>Reno算法在接收到局部ACK后就停止拥塞窗口的膨胀阶段，并将其减小至特定值，这种做法可能导致在重传计时器超时之前，传输阶段一直处于空闲状态。（这一段话可以这样理解，发送窗口的数据都发送出去了，但是都没有收到确认，假如说此时窗口缩小，那么发送方明明有数据但是无法发送导致发送通道空闲）</p></li><li><p>NewReno算法是如何改进的</p><p>NewReno算法对快速恢复做了改进，它记录了上一个数据传输窗口的最高序列号（恢复点），仅当接收到序列号不小于恢复点的ACK，才停止快速恢复阶段。这样TCP发送方每接收一个ACK都能够继续发送一个新数据包，从而减少重传超时的发生。</p></li></ul></li><li><p><strong>采用选择确认机制的TCP拥塞控制</strong></p><p>采用SACK机制的TCP，发送方可以知道多个数据段的丢失情况，而这些数据都在发送窗口，因此可以即时发送，然而，这样可能可能会在较短时间内向网络中注入大量数据，削弱拥塞控制的效果。解决方法是TCP会维护一个称为管道的变量，记录在外数据的估计值，不考虑awnd，只有当cwnd-pipe&gt;=SMSS时，SACK TCP可以发送数据。</p></li><li><p><strong>转发确认和速率减半</strong></p><p>当快速重传结束后cwnd值减小，tcp发送新数据之前至少要接收1半的ACK数据包。这样TCP发送端在前一半RTT时间内处于等待状态，在后一半RTT才能开始发送新数据。</p><p>转发确认策略提出了<strong>带界定参数的速率减半算法</strong>（RHBP）</p><p>RHBP的基本操作是，在一个RTT时间内，每重复收到两个重复ACK，TCP发送方可以发送一个新数据包，这样在恢复阶段结束前，TCP已经发送了一部分新数据，数据发送比较均衡，不会集中到RTT的后半段。</p></li><li><p><strong>限制传输</strong></p><p>在Reno算法中，通常需要三次重复ACK表明数据丢失，在窗口较小的情况下，当出现丢包，网络中可能没有足够的包去引发快速重传/快速恢复机制。</p><p>采用限制传输策略，TCP发送方没接收两个连续的重复ACK，就能发送一个新数据包，这样使得网络中的数据包维持一定数量足以触发快速重传。</p><p>限制传输使TCP能在可用窗口较小的情况下更好的工作。避免TCP等待RTO导致吞吐量下降。</p></li><li><p><strong>拥塞窗口校验（CWV）</strong></p><p>当发送方持续发送数据，使得cwnd增加成一个较大的值，然后暂停发送数据，之后cwnd就不能反映网络中的拥塞状态。</p><p>CWV机制是在发送长时间暂停的情况下，cwnd值会衰减。</p><p>空闲发送端和应用受限发送端：</p><ul><li>空闲发送端是指没有新数据发送需求，之前发送的数据都已经收到确认了</li><li>应用受限发送端是指有需要发送的数据，但是由于某些原因无法发送（如处理器正忙）</li></ul><p>长时间空闲</p><ul><li>首先判断距离上次发送操作是否超过一个RTO，如果超过则：<ul><li>更新ssthresh值，设为max(ssthresh,3/4cwnd)</li><li>每经过一个RTT，cwnd的值减半</li></ul></li></ul><p>应用受限的发送端</p><ul><li>已使用窗口记为W_used</li><li>更新ssthresh值，设为max(ssthresh,3/4cwnd)</li><li>cwnd设为cwnd与W_used的平均值</li></ul></li></ul><hr><h5 id="4-伪RTO处理-Eifel响应算法"><a href="#4-伪RTO处理-Eifel响应算法" class="headerlink" title="4. 伪RTO处理 Eifel响应算法"></a>4. 伪RTO处理 Eifel响应算法</h5><p>解决的问题</p><p>若TCP出现突发时延，即使没有丢包，也有可能造成重传超时，这就是伪重传现象，伪重传现象发生TCP会调整ssthresh并将cwnd置为IW，使得tcp进入慢开启状态，浪费传输资源。</p><p>Eifel算法包含检测算法和响应算法两部分。</p><p>Eifel响应算法用于处理重传计时器以及重传计时器超时后的拥塞控制操作。</p><p>在首次发生超时重传时，Eifel算法开始执行，若认为出现伪重传情况，会撤销对ssthresh的修改。在任何情况，若因RTO导致需要改变ssthresh值，都在修改前记录一个特殊的变量pipe_prev=min(在外数据值,ssthresh).</p><p>然后会运行一个检测算法，如果发生伪重传进行如下操作：</p><ul><li>若接受的是包含ECN-Echo标志位的好的ACK，停止操作</li><li>cwnd=在外数据值+min(bytes_Acked,IM)</li><li>ssthresh=pipe_prev</li></ul><hr><h5 id="5-共享拥塞状态信息"><a href="#5-共享拥塞状态信息" class="headerlink" title="5. 共享拥塞状态信息"></a>5. 共享拥塞状态信息</h5><p>相同的主机会建立多条TCP连接，每个tcp连接需要重新进行拥塞处理，建立自己的ssthresh和cwnd。但是实际上，新连接可能会用到相同主机之间的其他连接信息，包括已经关闭的连接或者正在处于活动状态的其他连接。</p><hr><h5 id="6-TCP友好性"><a href="#6-TCP友好性" class="headerlink" title="6. TCP友好性"></a>6. TCP友好性</h5><p>在传输路径中会经常出现几个TCP连接共享一个或多个路由的情况，然而他们并非均匀的共享带宽资源，而是根据其他连接动态地调节分配。但是也可能出现TCP与其他TCP连接恶性竞争传输资源的情况，于是提出了一种基于计算公式的速率控制方式，限制特定环境下TCP连接对带宽资源的使用。该方法称为TCP友好速率控制（RFRC）。</p><hr><h5 id="7-高速环境下的TCP"><a href="#7-高速环境下的TCP" class="headerlink" title="7. 高速环境下的TCP"></a>7. 高速环境下的TCP</h5><p>在BDP较大的高速网络中，传统TCP可能不能表现出良好的性能。因为它的窗口增加需要很长一段时间才能使窗口增至传输链路饱和。也就是说即使没有拥塞发生，TCP也不能很好地利用高速网络。TCP需要经过非常长的一段时间才能完全利用所有带宽。</p><hr><h5 id="8-基于延迟的拥塞控制算法"><a href="#8-基于延迟的拥塞控制算法" class="headerlink" title="8. 基于延迟的拥塞控制算法"></a>8. 基于延迟的拥塞控制算法</h5><ul><li>Vegas算法</li><li>FAST算法</li><li>TCP Westwood算法和Westwood+算法</li><li>复合TCP</li></ul><hr><h5 id="9-缓冲区膨胀"><a href="#9-缓冲区膨胀" class="headerlink" title="9. 缓冲区膨胀"></a>9. 缓冲区膨胀</h5><p>路由器缓存区不是越大越好，过大的缓冲区会导致网络拥塞。</p><hr><h5 id="10-积极队列管理和ECN"><a href="#10-积极队列管理和ECN" class="headerlink" title="10. 积极队列管理和ECN"></a>10. 积极队列管理和ECN</h5><ul><li><p>积极队列管理</p><p>路由器管理队列的方法称为积极队列管理机制（AQM），发生拥塞时，如果尾端没有空闲空间，会将数据包丢弃（尾部丢弃），然后按照FIFO方法转发之前到达的数据包。</p></li><li><p>RED网关机制</p><p>随机早期检测（RED）网关机制能够探测拥塞情况的发送，并且控制数据包标记，这些网关实现了一种衡量平均占用时间的队列管理方法，如果占用队列的时间超过最小值，并且小于最大值，那么这个数据包将被标记上一个不断增长的概率值，如果平均队列占用时间超过了最大值，也可以将数据包丢弃而不是标记它们。</p><p>当接收方接受到一个被标记的包，表明这个数据包经过一个阻塞的路由器，于是会在ACK确认报文中通知发送方阻塞情况。</p></li><li><p>ECN机制</p><p>ECN机制主要在IP层操作，也可以应用于TCP协议之外的其他传输层协议。当一个包含ECN功能的路由器经过长时间的拥塞，接收到一个IP数据包后，它会查看IP头中的ECN传输功能标识，如果有效，负责发送数据包的传输层协议将开启ECN功能，此时路由器会在IP头设置一个已发送拥塞（CE）标识，然后继续向下转发数据报。若拥塞情况不会持续很长时间，路由器不会将CE标识置位。</p><p>如果TCP接收端发现接收到的数据包的cE标识被置位，那么它必须将该标识发送回发送端（也可以添加到SYN+ACK报文段中发送），它会将ACK数据包的ECN-Echo置位。TCP发送端接收到Echo-Echo标识的ACk数据包时，会像探测到单个数据包丢失一样调整cwnd值。</p></li></ul><hr><h5 id="11-与TCP拥塞控制相关的攻击"><a href="#11-与TCP拥塞控制相关的攻击" class="headerlink" title="11. 与TCP拥塞控制相关的攻击"></a>11. 与TCP拥塞控制相关的攻击</h5><p>不详细总结</p><hr><p>*参考：《TCP/IP协议详解 卷一：协议》Kevin R. Fall W.Richard Stevens</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
          <category> 运输层 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
            <tag> tcp </tag>
            
            <tag> 运输层 </tag>
            
            <tag> 拥塞控制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis基础知识总结</title>
      <link href="/2019/12/28/Redis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
      <url>/2019/12/28/Redis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h4 id="1-初识Redis"><a href="#1-初识Redis" class="headerlink" title="1. 初识Redis"></a>1. 初识Redis</h4><p><a href="https://zhuanlan.zhihu.com/p/42272979" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/42272979</a></p><p><strong>1. Redis有哪些特性</strong></p><p>首先<strong>Redis的速度非常快</strong>，并且<strong>Redis支持多种数据结构</strong>，还<strong>提供了许多丰富的功能</strong>如提供了键过期的功能，发布订阅功能，支持Lua脚本等功能；<strong>Redis简单稳定</strong>，源码非常简洁；<strong>支持的客户端语言很多</strong>；<strong>支持持久化</strong>，发生断电不会丢失数据；提供了<strong>主从复制的功能</strong>；提供了<strong>集群的功能</strong>，适合分布式环境</p><p><strong>2. Redis为什么快</strong></p><ol><li><p><strong>完全基于内存</strong>，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；</p></li><li><p><strong>数据结构简单，对数据操作也简单</strong>，Redis中的数据结构是专门进行设计的；</p></li><li><p>采用<strong>单线程，避免了不必要的上下文切换和竞争条件</strong>，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</p></li><li><p><strong>使用多路I/O复用模型，非阻塞IO</strong>；</p></li><li><p>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</p></li></ol><p><strong>3. Redis有哪些应用场景</strong></p><ul><li><p>缓存</p><p>redis提供了键值过期时间设置，并且也提供了灵活控制最大内存和内存溢出后的淘汰策略，适合作为缓存。</p></li><li><p>排行榜系统</p><p>Redis提供类表和有序集合数据结构，方便实现各种排行榜</p></li><li><p>计数器应用</p><p>Redis天然支持计数功能且性能非常好。</p></li><li><p>社交网络</p><p>redis可以很方便的实现点赞，共同好友等功能</p></li><li><p>消息队列系统</p><p>Redis提供了发布订阅功能和阻塞队列的功能</p></li></ul><p><strong>4. Redis不适合什么样的应用</strong></p><p>使用Redis，基于成本考虑，最大的问题是内存的价格比较昂贵，而Redis将数据全部放在内存中，而基于内存又提供了快速访问的能力，如果一个应用中的数据量比较大并且不需要经常访问就不适合使用Redis来存放这些量大且冷门的数据。</p><hr><h4 id="2-Redis的数据结构"><a href="#2-Redis的数据结构" class="headerlink" title="2. Redis的数据结构"></a>2. Redis的数据结构</h4><hr><h4 id="3-小功能大用处"><a href="#3-小功能大用处" class="headerlink" title="3. 小功能大用处"></a>3. 小功能大用处</h4><p><strong>1. Redis命令执行的生命周期是怎样的</strong></p><p>发送命令-&gt;命令排队-&gt;命令执行-&gt;返回结果</p><p><strong>2. 如何统计执行比较慢的命令</strong></p><p>通过参数来设置慢查询阈值，执行时间超过这个阈值的命令就会被记录下来，使用<code>slowlog</code>命令就可以获取到慢查询日志。</p><p><strong>3. 什么是pipeline机制</strong></p><p>在redis中某些操作提供了批量操作的命令，但是许多操作是没有对应的批量操作的命令，所以在执行一批大量的命令时，总的执行包括真正的执行时间以及发送命令和接受响应的往返时间，往返时间取决于网络的状况，为了降低网络时延的影响，pipeline提供了将一组命令组合在一起发送给服务端的能力，这样就只有一次往返时间，提高了命令执行的效率。</p><p><strong>4. redis对事务的支持情况</strong></p><p>redis只支持简单的事务，这种事务不具备完整的ACID特性，使用事务的时候执行<code>multi</code>开启事务，后面的命令都在同一个事务中，使用<code>exec</code>来提交事务或者使用<code>exec</code>命令来取消事务，如果事务中的操作中有命令语法错误了整个事务将无法执行，但是redis的事务是不支付撤销的，在某些场景下可以使用类似乐观锁的机制来确保事务中的key没有被其他客户端修改过。</p><p><strong>5. Lua语言在Redis中扮演的角色</strong></p><p>Lua语言是一门由C语言实现的脚本语言，在Redis可以通过lua语言实现自定义的命令。</p><p><strong>6. 介绍一下Redis的Bitmaps</strong></p><p>bitmaps是一种数据结构，叫做位图，他的基本单位是二进制位，每个位只能取0或者1。在Redis中为bitmaps提供了许多位操作的功能，并且bitmap本身在redis中不是一种独立的数据结构，他的底层是字符串，因为bitmaps的基本单元是二进制位，所以数据结构占用的空间很小，适合那些只需要统计两种状态且要求空间很少的应用，比如说统计一亿用户中每天的活跃用户。</p><p><strong>7. 介绍一下HyperLogLog</strong></p><p>HyperlogLog的底层是字符串类型，通过HyperLogLog可以利用极小的内存空间完成独立总数的统计，但是统计值不是完全精确的，具有一定的误差，官方给出的失误率是0.81%。redis中实现的HyperLogLog，只需要12K内存，在标准误差0.81%的前提下，能够统计<code>2^64</code>个数据。但是，因为HyperLogLog只会根据输入元素来计算基数，而不会储存输入元素本身，所以HyperLogLog不能像集合那样，返回输入的各个元素。</p><p><strong>8. Redis的发布订阅功能</strong></p><p>Redis提供了基于“发布订阅”模式的消息机制，在这种模式下，消息发布者和订阅者不直接通信，发布者客户端向指定的频道发布消息，订阅该冰岛的每个客户端都可以收到该消息。</p><ul><li><p>发布消息</p><p><code>publish channel message</code></p></li><li><p>订阅消息</p><p><code>subscribe channel [频道名称]</code></p></li><li><p>取消订阅</p><p><code>unsubscribe [频道名称]</code></p></li></ul><p>Redis的消息队列系统比专业的消息队列系统还差很多，但是足够的简单</p><p><strong>9. GEO</strong></p><p>GEO的全称是地理信息(经纬度)定位，支持存储地理位置信息来实现如附近的人，摇一摇这类依赖于地理位置信息的功能。</p><hr><h4 id="4-客户端"><a href="#4-客户端" class="headerlink" title="4. 客户端"></a>4. 客户端</h4><p><strong>1. java中如何操作redis</strong></p><p>jedis</p><hr><h4 id="5-持久化"><a href="#5-持久化" class="headerlink" title="5. 持久化"></a>5. 持久化</h4><p><a href="https://juejin.im/post/5d09a9ff51882577eb133aa9" target="_blank" rel="noopener">https://juejin.im/post/5d09a9ff51882577eb133aa9</a></p><p><strong>1. 什么是持久化机制</strong></p><p>redis的数据是存放在内存中，由于内存的特点是断电后数据丢失，而redis需要保证redis服务器重启后数据还在，所以需要一种机制，这种机制就是持久化机制，他可以把数据持久化到物理磁盘中人，然后重启后从磁盘中读取数据恢复内存中的数据。</p><p><strong>2. Redis中有哪些持久化机制，默认是哪种</strong></p><p>Redis支持两种持久化机制，RDB和AOF，默认开启的是RDB</p><p><strong>3. 介绍一下RDB</strong></p><p><code>RDB</code>是一种快照存储持久化方式，具体就是将<code>Redis</code>某一时刻的内存数据保存到硬盘的文件当中，默认保存的文件名为<code>dump.rdb</code>，而在<code>Redis</code>服务器启动时，会重新加载<code>dump.rdb</code>文件的数据到内存当中恢复数据。</p><p><strong>4. 怎么开启RDB</strong></p><p>可以使用命令<code>save</code>和<code>bgsave</code>,两者的区别是<code>save</code>命令会阻塞Redis服务器直到rdb完成，而<code>bgsave</code>会fork一个子进程来处理不会发生阻塞。也可以通过服务器配置文件来配置触发rdb的条件</p><p><strong>5. 有哪些配置触发rdb条件的配置参数</strong></p><pre><code class="java"># 900s内至少达到一条写命令save 900 1# 300s内至少到达10条写命令save 300 10# 60s内至少达到10000条写命令save 60 10000</code></pre><p><strong>4. 生成rdb文件的过程</strong></p><ol><li>生成临时rdb文件，并写入数据</li><li>完成数据写入，用临时文件替代正式rdb文件</li><li>删除原来的rdb文件</li></ol><p><strong>5. rdb的优点</strong></p><ol><li>与AOF方式想比，通过rdb文件恢复数据比较快</li><li>rdb文件非常紧凑，适合数据备份</li><li>通过rdb进行数据备份，由于使用了子进程，所以对redis服务器的性能影响比较小</li></ol><p><strong>6. rdb的几个缺点</strong></p><ul><li><p>如果服务器宕机的话，采用<code>RDB</code>的方式会造成某个时段内数据的丢失，比如我们设置10分钟同步一次或5分钟达到1000次写入就同步一次，那么如果还没达到触发条件服务器就死机了，那么这个时间段的数据会丢失。</p></li><li><p>使用save命令会造成服务器阻塞，直接数据同步完成才能接收后续请求。</p></li><li><p>使用bgsave命令在forks子进程时，如果数据量太大，forks的过程也会发生阻塞，另外，forks子进程会耗费内存。</p></li></ul><p><strong>7. 什么是AOF</strong></p><p><code>AOF</code>持久化方式会记录客户端对服务器的每一次写操作命令，并将这些写操作以<code>Redis</code>协议追加保存到以后缀为<code>aof</code>文件末尾，在Redis服务器重启时，会加载并运行<code>aof</code>文件的命令，以达到恢复数据的目的。</p><p><strong>8. 如何开启AOF持久化方式</strong></p><p>Redis默认不开启AOF持久化方式，我们可以在配置文件中开启并进行更加详细的配置，如下面的redis.conf文件</p><pre><code class="properties"># 开启aof机制appendonly yes# aof文件名appendfilename &quot;appendonly.aof&quot;# 写入策略,always表示每个写操作都保存到aof文件中,也可以是everysec或noappendfsync always# 默认不重写aof文件no-appendfsync-on-rewrite no# 保存目录dir ~/redis/</code></pre><p><strong>9. 有哪些AOF的写入策略</strong></p><p>通过<code>appendfsync</code>来配置，可以取三个值</p><ul><li><p>always</p><p>客户端的每一个写操作都保存到<code>aof</code>文件当，这种策略很安全，但是每个写请注都有IO操作，所以也很慢。</p></li><li><p>everysec</p><p><code>appendfsync</code>的默认写入策略，每秒写入一次<code>aof</code>文件，因此，最多可能会丢失1s的数据。</p></li><li><p>no</p><p><code>Redis</code>服务器不负责写入<code>aof</code>，而是交由操作系统来处理什么时候写入<code>aof</code>文件。更快，但也是最不安全的选择，不推荐使用。</p></li></ul><p><strong>10.AOF文件太大了这么办</strong></p><p>可以进行AOF重写，通过重写在aof文件中只保存命令的最小集</p><p><strong>11. 重写的作用是什么</strong></p><p>aof不进行重写的话会有很多冗余的命令，这会使得aof越来越大，加载aof文件进行恢复时会很慢，重写aof文件的目的就是加快恢复的速度。</p><p><strong>12. 有哪些重写方式</strong></p><p>第一章是每次同步aof内容时就会发生重写，另一种是只要客户端向服务端发送bgrewriteaof命令的时候才会发生重写。</p><p><strong>13. AOF文件损坏了怎么办</strong></p><p>在写入aof日志文件时，如果Redis服务器宕机，则aof日志文件文件会出格式错误，在重启Redis服务器时，Redis服务器会拒绝载入这个aof文件，可以通过以下步骤修复aof并恢复数据。</p><ol><li>备份现在aof文件，以防万一。</li><li>使用redis-check-aof命令修复aof文件，该命令格式<code>redis-check-aof -fix file.aof</code></li></ol><p><strong>14. AOF的优点</strong></p><p>AOF只是追加日志文件，因此对服务器性能影响较小，速度比RDB要快，消耗的内存较少。</p><p><strong>15. AOF的缺点</strong></p><ol><li>AOF方式生成的日志文件太大，即使通过AFO重写，文件体积仍然很大。</li><li>恢复数据的速度比RDB慢。</li></ol><p><strong>16. AOF和RDB的对比</strong></p><table><thead><tr><th>方式</th><th>RDB</th><th>AOF</th></tr></thead><tbody><tr><td>启动优先级</td><td>低</td><td>高</td></tr><tr><td>体积</td><td>小</td><td>大</td></tr><tr><td>恢复速度</td><td>快</td><td>慢</td></tr><tr><td>数据安全性</td><td>会丢数据</td><td>由策略来决定</td></tr><tr><td>轻重</td><td>重</td><td>轻</td></tr></tbody></table><p><strong>17. rdb和aof同时开启的情况下，先使用哪种机制</strong></p><p>当RDB与AOF两种方式都开启时，Redis会优先使用AOF日志来恢复数据，因为AOF保存的文件比RDB文件更完整。</p><hr><h4 id="6-复制"><a href="#6-复制" class="headerlink" title="6. 复制"></a>6. 复制</h4><p><strong>1. redis复制功能的作用</strong></p><p>如果使用一台redis服务器来保存数据，当这个服务器不可用的时候，整个服务就会不可用，为了解决这个问题，可以通过提供相同数据的多个副本，这样当一个节点不可用，整个服务并不受影响，后续可以将不可用的服务器恢复。</p><p><strong>2. 如何建立复制</strong></p><p>参与复制的结点可以分为主节点和从节点，默认情况下redis都是主节点，并且每个从节点只能有一个主节点，一个主节点可以有多个从节点，复制的数据是单向的，只能由主节点复制到从节点，配置的方式有三种</p><ul><li>在配置文件中加入slaveof 主节点host，主节点port</li><li>在redis服务器启动命令后加–slaveof 主节点host，主节点port</li><li>redis服务器启动使用命令slaveof 主节点host，主节点port</li></ul><p><strong>3. 如何断开复制</strong></p><p>在从节点中执行<code>slaveof no one</code>命令，之后这个从节点将晋升为主节点</p><p><strong>4. 怎么保证主从复制的安全性</strong></p><p>对于数据比较重要的节点，主节点会通过设置<code>requirepass</code>参数进行密码验证，这时所有的客户端访问必须使用<code>auth</code>命令实行校验。</p><p><strong>5. 从节点可以进行写操作吗</strong></p><p>默认情况下，从节点使用slave-read-only=yes配置为只读模式。由于复制只能从主节点到从节点，对于从节点的任何修改主节点都无法感知，修改从节点会造成主从数据不一致。因此建议线上不要修改从节点的只读模式。</p><p><strong>6. 有哪些主从复制的拓扑结构，他们都有哪些特点</strong></p><p><strong>一主一从结构</strong>是最简单的复制拓扑结构，用于主节点出现宕机时从节点提供故障转移支持。<strong>一主多从结构</strong>（又称为星形拓扑结构）使得应用端可以利用多个从节点实现读写分离（见图6-5）。对于读占比较大的场景，可以把读命令发送到从节点来分担主节点压力。<strong>树状主从结构</strong>（又称为树状拓扑结构）使得从节点不但可以复制主节点数据，同时可以作为其他从节点的主节点继续向下层复制。通过引入复制中间层，可以有效降低主节点负载和需要传送给从节点的数据量</p><p><strong>7. 主从复制的原理，复制过程是怎么样的</strong></p><p>执行slaveof命令，从节点先保存主节点的ip和端口信息，然后从节点会与主节点建立网络连接，连接成功之后从节点会发生ping请求进行首次通信，主节点会返回pong命令。如果主节点设置了权限认证则需要认证权限，认证完之后就可以进行数据集的同步，首次建立连接，主节点会把所有的数据全部发送个从节点，之后如果主节点有新的数据，会将命令持续复制给从节点，保证主从数据的一致性。</p><p><strong>8. 如何实现数据同步</strong></p><p>通过psync命令来完成主从数据同步，同步过程有两种，全量复制和部分复制</p><p><strong>9. 什么是全量复制，什么是部分复制</strong></p><p><strong>全量复制</strong>一般用于初次复制场景，它会把主节点全部数据一次性发送个从节点。他的缺点是当数据流比较大时，对主从节点和网络会造成很大的开销。<strong>部分复制</strong>是用来处理主从复制中因网络闪断等原因造成的数据丢失场景，当从节点再次连上主节点后，如果条件允许，主节点会补发丢失数据给从接待您，因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销。</p><p><strong>10. psync命令需要哪些组件的支持</strong></p><p>主从节点各自的复制偏移量，主从节点复制积压缓冲区，主节点运行id。</p><ul><li><p>复制偏移量</p><p>参与复制的主从节点都会维护自身复制偏移量。主节点（master）在处理完写入命令后，会把命令的字节长度做累加记录，从节点（slave）每秒钟上报自身的复制偏移量给主节点，因此主节点也会保存从节点的复制偏移量，从节点在接收到主节点发送的命令后，也会累加记录自身的偏移量，通过对比主从节点的复制偏移量，可以判断主从节点数据是否一致。判断主从节点复制相差的数据量，根据这个差值判定当前复制的健康度。如果主从之间复制偏移量相差较大，则可能是网络延迟或命令阻塞等原因引起</p></li><li><p>复制积压缓冲区</p><p>复制积压缓冲区是保存在主节点上的一个固定长度的队列，默认大小为1MB，当主节点有连接的从节点（slave）时被创建，这时主节点（master）响应写命令时，不但会把命令发送给从节点，还会写入复制积压缓冲区。由于缓冲区本质上是先进先出的定长队列，所以能实现保存最近已复制数据的功能，用于部分复制和复制命令丢失的数据补救</p></li><li><p>运行id</p><p>每个Redis节点启动后都会动态分配一个<strong>40位的十六进制字符串</strong>作为运行ID。运行ID的主要作用是用来唯一识别Redis节点，比如从节点保存主节点的运行ID识别自己正在复制的是哪个主节点。</p></li></ul><p><strong>11. fsync命令的流程</strong></p><ul><li>从节点（slave）发送psync命令给主节点，参数runId是当前从节点保存的主节点运行ID，如果没有则默认值为，参数offset是当前从节点保存的复制偏移量，如果是第一次参与复制则默认值为-1。</li><li>主节点（master）根据psync参数和自身数据情况决定响应结果<ul><li>如果回复+FULLRESYNC{runId}{offset}，那么从节点将触发全量复制流程</li><li>如果回复+CONTINUE，从节点将触发部分复制流程。</li><li>如果回复+ERR，说明主节点版本低于Redis2.8，无法识别psync命令</li></ul></li></ul><p><strong>12. 全量复制的流程</strong></p><ul><li>发送psync命令进行数据同步，由于是第一次进行复制，从节点没有复制偏移量和主节点的运行ID，所以发送psync-1。</li><li>主节点根据psync-1解析出当前为全量复制，回复+FULLRESYNC响应。</li><li>从节点接收主节点的响应数据保存运行ID和偏移量offset</li><li>主节点执行bgsave保存RDB文件到本地（也可以使用无盘复制不用保存到本地）</li><li>主节点发送RDB文件给从节点，从节点把接收的RDB文件保存在本地并直接作为从节点的数据文件</li><li>对于从节点开始接收RDB快照到接收完成期间，主节点仍然响应读写命令，因此主节点会把这期间写命令数据保存在复制客户端缓冲区内，当从节点加载完RDB文件后，主节点再把缓冲区内的数据发送给从节点，保证主从之间数据一致性</li><li>从节点接收完主节点传送来的全部数据后会清空自身旧数据</li><li>从节点清空数据后开始加载RDB文件</li><li>从节点成功加载完RDB后，如果当前节点开启了AOF持久化功能，它会立刻做bgrewriteaof操作</li></ul><p><strong>13. 部分复制的流程</strong></p><ul><li>当主从节点之间网络出现中断时，如果超过repl-timeout时间，主节点会认为从节点故障并中断复制连接</li><li>主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存1MB</li><li>当主从节点网络恢复后，从节点会再次连上主节点</li><li>当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们当作psync参数发送给主节点，要求进行部分复制操作</li><li>主节点接到psync命令后首先核对参数runId是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数offset在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送+CONTINUE响应，表示可以进行部分复制。</li><li>主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态</li></ul><p><strong>10. 主从机制的心跳机制</strong></p><ul><li>主从节点彼此都有心跳检测机制，各自模拟成对方的客户端进行通信</li><li>主节点默认每隔10秒对从节点发送ping命令，判断从节点的存活性和连接状态。</li><li>从节点在主线程中每隔1秒发送replconf ack{offset}命令，给主节点上报自身当前的复制偏移量</li><li>主节点根据replconf命令判断从节点超时时间，体现在info replication统计中的lag信息中，lag表示与从节点最后一次通信延迟的秒数，正常延迟应该在0和1之间。如果超过repl-timeout配置的值（默认60秒），则判定从节点下线并断开复制客户端连接。即使主节点判定从节点下线后，如果从节点重新恢复，心跳检测会继续进行</li></ul><p><strong>11. 什么是异步复制</strong></p><p>主节点不但负责数据读写，还负责把写命令同步给从节点。写命令的发送过程是异步完成，也就是说主节点自身处理完写命令后直接返回给客户端，并不等待从节点复制完成。</p><p><strong>12. 什么是读写分离</strong></p><p>对于读占比较高的场景，可以通过把一部分读流量分摊到从节点来减轻主节点压力，同时需要注意永远只对主节点执行写操作。</p><p><strong>13. 读写分离要注意什么问题</strong></p><p>·复制数据延迟、读到过期数据、从节点故障</p><ul><li><p>复制数据延迟</p><p>Redis复制数据的延迟由于异步复制特性是无法避免的，延迟取决于网络带宽和命令阻塞情况，比如刚在主节点写入数据后立刻在从节点上读取可能获取不到。</p></li><li><p>读到过期数据</p><p>当主节点存储大量设置超时的数据时，如缓存数据，Redis内部需要维护过期数据删除策略，删除策略主要有两种：惰性删除和定时删除。</p><ul><li><p>惰性删除</p><p>主节点每次处理读取命令时，都会检查键是否超时，如果超时则执行del命令删除键对象，之后del命令也会异步发送给从节点，为了保证复制的一致性，从节点自身永远不会主动删除超时数据。</p></li><li><p>定时删除</p><p>Redis主节点在内部定时任务会循环采样一定数量的键，当发现采样的键过期时执行del命令，之后再同步给从节点。</p></li></ul></li><li><p>从节点故障</p><p>对于从节点的故障问题，需要在客户端维护可用从节点列表，当从节点故障时立刻切换到其他从节点或主节点上。</p></li></ul><p><strong>14. 什么时候会发生全量复制</strong></p><p>全量复制是一个非常消耗资源的操作，发生全量复制的时机有</p><ul><li>第一次建立复制</li><li>节点运行ID不匹配</li><li>复制积压缓冲区不足</li></ul><p><strong>15. 什么是复制风暴，如何规避复制风暴</strong></p><p>复制风暴是指大量从节点对同一主节点或者对同一台机器的多个主节点短时间内发起全量复制的过程。复制风暴对发起复制的主节点或者机器造成大量开销，导致CPU、内存、带宽消耗。</p><p>应该把主节点尽量分散在多台机器上，避免在单台机器上部署过多的主节点。当主节点所在机器故障后提供故障转移机制，避免机器恢复后进行密集的全量复制。</p><hr><h4 id="7-Redis的噩梦：阻塞"><a href="#7-Redis的噩梦：阻塞" class="headerlink" title="7. Redis的噩梦：阻塞"></a>7. Redis的噩梦：阻塞</h4><hr><h4 id="8-理解内存"><a href="#8-理解内存" class="headerlink" title="8. 理解内存"></a>8. 理解内存</h4><hr><h4 id="9-哨兵"><a href="#9-哨兵" class="headerlink" title="9. 哨兵"></a>9. 哨兵</h4><p><a href="https://juejin.im/post/5b7d226a6fb9a01a1e01ff64" target="_blank" rel="noopener">https://juejin.im/post/5b7d226a6fb9a01a1e01ff64</a></p><p><strong>1. 什么是redis哨兵</strong></p><p>Redis的主从复制模式下，一旦主节点由于故障不能提供服务，需要人工将从节点晋升为主节点，同时还要通知应用方更新主节点地址，对于很多应用场景这种故障处理的方式是无法接受的。当主节点出现故障时，Redis Sentinel能自动完成故障发现和故障转移，并通知应用方，从而实现真正的高可用。</p><p><strong>2. redis主从复制带来的问题</strong></p><p>Redis主从复制模式下，一旦主节点出现了故障不可达，需要人工干预进行故障转移，无论对于Redis的应用方还是运维方都带来了很大的不便。对于应用方来说无法及时感知到主节点的变化，必然会造成一定的写数据丢失和读数据错误，甚至可能造成应用方服务不可用。对于Redis的运维方来说，整个故障转移的过程是需要人工来介的，故障转移实时性和准确性上都无法得到保障。</p><p><strong>3. redis哨兵方案</strong></p><p>Redis Sentinel是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方。整个过程完全是自动的，不需要人工<br>来介入</p><p><strong>4. redis哨兵如何监控节点的</strong></p><p>Redis Sentinel通过三个定时监控任务完成对各个节点发现和监控</p><ul><li>每隔10秒，每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构</li><li>每隔2秒，每个Sentinel节点会向Redis数据节点的<strong>sentinel</strong>：hello频道上发送该Sentinel节点对于主节点的判断以及当前Sentinel节点的信息，同时每个Sentinel节点也会订阅该频道，来了解其他Sentinel节点以及它们对主节点的判断。</li><li>每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达</li></ul><p><strong>5. 什么是主观下线</strong></p><p>每个Sentinel节点会每隔1秒对主节点、从节点、其他Sentinel节点发送ping命令做心跳检测，当这些节点超过down-after-milliseconds没有进行有效回复，Sentinel节点就会对该节点做失败判定，这个行为叫做主观下线。</p><p><strong>6. 什么是客观下线</strong></p><p>当Sentinel主观下线的节点是主节点时，该Sentinel节点会通过sentinel ismaster-down-by-addr命令向其他Sentinel节点询问对主节点的判断，当超过<quorum>个数，Sentinel节点认为主节点确实有问题，这时该Sentinel节点会做出客观下线的决定，这样客观下线的含义是比较明显了，也就是大部分Sentinel节点都对主节点的下线做了同意的判定，那么这个判定就是客观的。</p><p><strong>7. 如何进行领导的选举</strong></p><p>假如Sentinel节点对于主节点已经做了客观下线，那么是不是就可以立即进行故障转移了？当然不是，实际上故障转移的工作只需要一个Sentinel节点来完成即可，所以Sentinel节点之间会做一个领导者选举的工作，选出一个Sentinel节点作为领导者进行故障转移的工作。</p><ul><li>每个在线的Sentinel节点都有资格成为领导者，当它确认主节点主观下线时候，会向其他Sentinel节点发送sentinel is-master-down-by-addr命令，要求将自己设置为领导者。</li><li>收到命令的Sentinel节点，如果没有同意过其他Sentinel节点的sentinelis-master-down-by-addr命令，将同意该请求，否则拒绝。</li><li>如果该Sentinel节点发现自己的票数已经大于等于max（quorum，num（sentinels）/2+1），那么它将成为领导者。</li><li>如果此过程没有选举出领导者，将进入下一次选举。</li></ul><p><strong>8. 故障转移是如何实现的</strong></p><ol><li><p>在从节点列表中选出一个节点作为新的主节点，选择方法如下</p><ul><li>过滤：“不健康”（主观下线、断线）、5秒内没有回复过Sentinel节点ping响应、与主节点失联超过down-after-milliseconds*10秒。</li><li>选择slave-priority（从节点优先级）最高的从节点列表，如果存在则返回，不存在则继续。</li><li>选择复制偏移量最大的从节点（复制的最完整），如果存在则返回，不存在则继续。</li><li>选择runid最小的从节点。</li></ul></li><li><p>Sentinel领导者节点会对第一步选出来的从节点执行slaveof no one命令让其成为主节点</p></li><li><p>Sentinel领导者节点会向剩余的从节点发送命令，让它们成为新主节点的从节点</p></li><li><p>Sentinel节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复后命令它去复制新的主节点</p></li></ol><hr><h4 id="10-集群"><a href="#10-集群" class="headerlink" title="10. 集群"></a>10. 集群</h4><p><strong>1. Redis集群是如何决定数据存放在哪台主机中的</strong></p><p>redis使用虚拟槽来进行分区的，首先规定槽的范围为0到16384，槽是集群内数据管理和迁移的基本单位，采用大范围槽的主要目的是为了方便树拆分和集群扩展。每个节点会负责一定数量的槽。所有的键通过哈希算法映射到0到16384整数槽中，计算公式为<code>slot=CRC16(key)&amp;16383</code></p><p><strong>2. 虚拟槽的特点</strong></p><ul><li>解耦了数据与节点之间的关系，简化了节点扩容和收缩的难度</li><li>节点自身维护槽的映射关系，不需要客户端或代理服务维护槽分区</li><li>支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景</li></ul><p><strong>3. redis集群功能有什么限制</strong></p><ul><li>对key的批量操作支持有限</li><li>key事务操作支持有</li><li>key作为数据分区的最小粒度，因此不能将一个大的键值对象如hash、list等映射到不同的节点</li><li>不支持多数据库空间</li><li>复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。</li></ul><p><strong>4. 如何搭建集群</strong></p><p>一种是手动方式，一种是通过ruby脚本来实现</p><ul><li>首先准备节点，节点的个数最少为6个，通过配置参数开启集群模式<ul><li>节点启动成功后会检查是否存在集群配置文件，如果没有会自动创建一份。</li><li>当集群内节点信息发生变化，如添加节点、节点下线、故障转移等。节点会自动保存集群状态到配置文件中。需要注意的是，Redis自动维护集群配置文件，不要手动修改，防止节点重启时产生集群信息错乱</li><li>集群中的每一个节点使用一个40位长度的16进制字符串的节点id表示，这个id与运行id不同.节点ID在集群初始化时只创建一次，节点重启时会加载集群配置文件进行重用，而Redis的运行ID每次重启都会变化</li></ul></li><li>通过节点握手让6个节点彼此建立联系从而组成一个集群<ul><li>节点握手是指一批运行在集群模式下的节点通过Gossip协议彼此通信，达到感知对方的过程</li><li>节点握手是集群彼此通信的第一步，由客户端发起命令：<code>cluster meet{ip}{port}</code></li><li>我们只需要在集群内任意节点上执行cluster meet命令加入新节点，握手状态会通过消息在集群内传播，这样其他节点会自动发现新节点并发起握手流程。最后执行cluster nodes命令确认6个节点都彼此感知并组成集群</li><li>节点建立握手之后集群还不能正常工作，这时集群处于下线状态，所有的数据读写都被禁止</li></ul></li><li>Redis集群把所有的数据映射到16384个槽中<ul><li>每个key会映射为一个固定的槽，只有当节点分配了槽，才能响应和这些槽关联的键命令</li></ul></li><li>每个负责处理槽的节点应该具有从节点，保证当它出现故障时可以自动进行故障转移,使用cluster<br>replicate{nodeId}命令让一个节点成为从节点</li></ul><p><strong>5. 集群中节点通信的流程</strong></p><p>Gossip协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，这种方式类似流言传播。</p><p><strong>6. 常用的Gossip消息有哪些</strong></p><ul><li><strong>meet消息</strong>：用于通知新节点加入。消息发送者通知接收者加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换</li><li><strong>ping消息</strong>：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。ping消息发送封装了自身节点和部分其他节点的状态数据</li><li><strong>pong消息</strong>：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内部封装了自身状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新</li><li><strong>fail消息</strong>：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。</li></ul><p><strong>7. Gossip协议如何选择通信的节点</strong></p><p>集群内每个节点维护定时任务默认每秒执行10次，每秒会随机选取5个节点找出最久没有通信的节点发送ping消息，用于保证Gossip信息交换的随机性。每100毫秒都会扫描本地节点列表，如果发现节点最近一次接受pong<br>消息的时间大于cluster_node_timeout/2，则立刻发送ping消息，防止该节点信息太长时间未更新。每次消息头的大小为2kb</p><p><strong>8. 集群伸缩的原理</strong></p><p>集群伸缩=槽和数据在节点之间的移动</p><p><strong>9. 如何扩容集群</strong></p><ul><li><p>准备新节点</p><p>需要提前准备好新节点并运行在集群模式下，新节点建议跟集群内的节点配置保持一致，便于管理统一</p></li><li><p>加入集群</p><p>新节点依然采用cluster meet命令加入到现有集群中</p></li><li><p>迁移槽和数据</p><p>槽是Redis集群管理数据的基本单位，首先需要为新节点制定槽的迁移计划，确定原有节点的哪些槽需要迁移到新节点。迁移计划需要确保每个节点负责相似数量的槽，从而保证各节点的数据均匀</p></li></ul><p><strong>10. 如何收缩集群</strong></p><ul><li>首先需要确定下线节点是否有负责的槽，如果是，需要把槽迁移到其他节点，保证节点下线后整个集群槽节点映射的完整性</li><li>当下线节点不再负责槽或者本身是从节点时，就可以通知集群内其他节点忘记下线节点，当所有的节点忘记该节点后可以正常关闭</li></ul><p><strong>11. 什么是集群的故障转移</strong></p><p>Redis集群自身实现了高可用。高可用首先需要解决集群部分失败的场景：当集群内少量节点出现故障时通过自动故障转移保证集群可以正常对外提供服务。</p><p><strong>12. 集群如何发现故障</strong></p><p>当集群内某个节点出现问题时，需要通过一种健壮的方式保证识别出节点是否发生了故障。Redis集群内节点通过ping/pong消息实现节点通信，消息不但可以传播节点槽信息，还可以传播其他状态如：主从状态、节点故障<br>等。因此故障发现也是通过消息传播机制实现的。</p><p><strong>13. 集群如何标记主观下线</strong></p><p>集群中每个节点都会定期向其他节点发送ping消息，接收节点回复pong消息作为响应。如果在cluster-node-timeout时间内通信一直失败，则发送节点会认为接收节点存在故障，把接收节点标记为主观下线（pfail）状态</p><p><strong>14. 集群如何标记客观下线</strong></p><p>当某个节点判断另一个节点主观下线后，相应的节点状态会跟随消息在集群内传播。ping/pong消息的消息体会携带集群1/10的其他节点状态数据，当接受节点发现消息体中含有主观下线的节点状态时，会在本地找到故障节<br>点的ClusterNode结构，保存到下线报告链表中.</p><p>通过Gossip消息传播，集群内节点不断收集到故障节点的下线报告。当半数以上持有槽的主节点都标记某个节点是主观下线时。</p><p><strong>15. 为什么必须是负责槽的主节点参与故障发现决策</strong></p><p>因为集群模式下只有处理槽的主节点才负责读写请求和集群槽等关键信息维护，而从节点只进行主节点数据和状态信息的复制。</p><p><strong>16. 为什么半数以上处理槽的主节点</strong></p><p>必须半数以上是为了应对网络分区等原因造成的集群分割情况，被分割的小集群因为无法完成从主观下线到<br>客观下线这一关键过程，从而防止小集群完成故障转移之后继续对外提供服务。</p><p><strong>17. 如何进行故障转移</strong></p><p>故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它的从节点中选出一个替换它，从而保证集群的高可用.</p><ul><li><strong>资格检查</strong>：每个从节点都要检查最后与主节点断线时间，判断是否有资格替换故障的主节点。如果从节点与主节点断线时间超过cluster-node-time*cluster-slave-validity-factor，则当前从节点不具备故障转移资格。参数cluster-slavevalidity-factor用于从节点的有效因子，默认为10。</li><li><strong>准备选举时间</strong>：当从节点符合故障转移资格后，更新触发故障选举的时间，只有到达该时间后才能执行后续流程</li><li><strong>发起选举</strong>：当从节点定时任务检测到达故障选举时间（failover_auth_time）到达后，发起选举流程<ul><li><strong>更新配置纪元</strong>：配置纪元是一个只增不减的整数，每个主节点自身维护一个配置纪标示当前主节点的版本，所有主节点的配置纪元都不相等，从节点会复制主节点的配置纪元。</li></ul></li><li><strong>选举投票</strong></li></ul><hr><hr><h4 id="11-缓存设计"><a href="#11-缓存设计" class="headerlink" title="11. 缓存设计"></a>11. 缓存设计</h4><p><strong>1. 缓存带来了哪些收益</strong></p><ul><li><p>加速读写</p><p>缓存通常是基于内存的，读写性能非常高。</p></li><li><p>降低后端负载</p><p>帮助后端减少访问量和复杂计算（例如很复杂的SQL语句），在很大程度降低了后端的负载。</p></li></ul><p><strong>2. 缓存带来了哪些成本</strong></p><ul><li>数据不一致性：缓存层和存储层的数据存在着一定时间窗口的不一致性，时间窗口跟更新策略有关。</li><li>代码维护成本：加入缓存后，需要同时处理缓存层和存储层的逻辑，增大了开发者维护代码的成本。</li><li>运维成本：以Redis Cluster为例，加入后无形中增加了运维成本。</li></ul><p><strong>3. 什么场景应该使用缓存</strong></p><p>开销大的复杂计算：以MySQL为例子，一些复杂的操作或者计算（例如大量联表操作、一些分组计算），如果不加缓存，不但无法满足高并发量，同时也会给MySQL带来巨大的负担。</p><p>加速请求响应：即使查询单条后端数据足够快（例如select*from table where id=），那么依然可以使用缓存，以Redis为例子，每秒可以完成数万次读写，并且提供的批量操作可以优化整个IO链的响应时间。</p><p><strong>4. 什么是缓存穿透</strong></p><p>缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，通常出于容错的考虑，如果从存储层查不到数据则不写入缓存层。缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。缓存穿透问题可能会使后端存储负载加大，由于很多后端存储不具备高并发性，甚至可能造成后端存储宕掉。</p><p><strong>5. 为什么会发生缓存穿透</strong></p><ul><li><p>自身业务代码或者数据出现问题</p></li><li><p>一些恶意攻击、爬虫等造成大量空命中。下面我们来看一下如何解决缓存穿透问题</p></li></ul><p><strong>6. 如何优化缓存穿透问题</strong></p><ul><li><p>当存储层不命中后，仍然将空对象保留到缓存层中，之后再访问这个数据将会从缓存中获取，这样就保护了后端数据源。</p></li><li><p>使用布隆过滤器进行拦截</p></li></ul><p><strong>7. 什么是无底洞现象</strong></p><p>添加新的节点，性能没有上升反而下降，这种现象称为无底洞现象</p><p><strong>8. 无底洞现象是怎么产生的</strong></p><p>键值数据库由于通常采用哈希函数将key映射到各个节点上，造成key的分布与业务无关，但是由于数据量和访问量的持续增长，造成需要添加大量节点做水平扩容，导致键值分布到更多的节点上，所以无论是Memcache还是Redis的分布式，批量操作通常需要从不同节点上获取，相比于单机批量操作只涉及一次网络操作，分布式批量操作会涉及多次网络时间。客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着节点的增多，耗时会不断增大。</p><p><strong>9. 无底洞现象怎么优化</strong></p><p><strong>10. 什么是缓存雪崩</strong></p><p>由于缓存层承载着大量请求，有效地保护了存储层，但是如果缓存层由于某些原因不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会级联宕机的情况。</p><p><strong>11. 如何优化缓存雪崩</strong></p><p><strong>12. 什么是缓存击穿</strong></p><p><strong>13. 如何优化缓存击穿</strong></p><hr><p><em>参考：《Redis开发与运维》</em></p><p><strong>（未完待续）</strong></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 数据库 </tag>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL索引优化</title>
      <link href="/2019/12/27/MySQL%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/"/>
      <url>/2019/12/27/MySQL%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h4 id=""><a href="#" class="headerlink" title=""></a></h4><h5 id="1-建立索引的技巧"><a href="#1-建立索引的技巧" class="headerlink" title="1. 建立索引的技巧"></a>1. 建立索引的技巧</h5><ol><li>最左前缀匹配原则</li><li>=和in可以乱序，查询优化器会帮你优化成索引可以识别的形式</li><li>查询优化器会帮你优化成索引可以识别的形式</li><li>索引列不能参与计算，保持列“干净”</li><li>尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可，当然要考虑原有数据和线上使用情况</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> mysql </tag>
            
            <tag> 索引优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB锁总结</title>
      <link href="/2019/12/26/InnoDB%E9%94%81%E6%80%BB%E7%BB%93/"/>
      <url>/2019/12/26/InnoDB%E9%94%81%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h5 id="1-什么是锁，为什么要加锁"><a href="#1-什么是锁，为什么要加锁" class="headerlink" title="1. 什么是锁，为什么要加锁"></a>1. 什么是锁，为什么要加锁</h5><p>锁是一种用来实现对共享资源安全访问的工具，当多个用户并发地存取数据时，在数据库中就可能会产生多个事务同时操作同一行数据的情况，若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据的一致性。</p><h5 id="2-InnoDB锁的类型"><a href="#2-InnoDB锁的类型" class="headerlink" title="2. InnoDB锁的类型"></a>2. InnoDB锁的类型</h5><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/InnoDB%E9%94%81%E6%80%BB%E7%BB%93/image-202001302035.jpg" alt="img"></p><ul><li><p><strong>按照锁的粒度来分</strong></p><ul><li><p>表锁</p><p>MySQL中锁定粒度最大的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率越高，并发度最低，MyISAM和InnoDB引擎都支持表级锁。</p></li><li><p>行锁</p><p>Mysql中锁定粒度最小的一种锁，只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。</p></li><li><p>页锁</p></li></ul></li><li><p><strong>按照锁算法来分</strong></p><ul><li>Recodrd Lock</li><li>Gap Lock</li><li>Next-key Lock</li></ul></li><li><p><strong>按照加锁机制来分</strong></p><ul><li><p>乐观锁</p><p>乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务；</p></li><li><p>悲观锁</p><p>悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁；</p></li></ul></li><li><p><strong>按照兼容性来分</strong></p><ul><li><p>共享锁</p><p>共享锁（<strong>Share Locks</strong>，简记为S锁）又称为<strong>读锁</strong>。其它事务可以并发地读取数据，可以再加共享锁，但任何事务都不能获取数据上的排它锁，直至已经释放所有共享锁。</p></li><li><p>排他锁</p><p>排它锁（<strong>Exclusive lock</strong>，简记为X锁）又称为<strong>写锁</strong>。若事务对数据对象加上了排它锁，则只允许该事务对数据对象进行读取和修改，其它事务不能再对数据对象加任何类型的锁，直到该事务释放对象上的排它锁。在更新操作(INSERT、UPDATE 或 DELETE)过程中始终应用排它锁。</p></li><li><p>意向锁</p><p>为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是<strong>表锁</strong>。</p><ul><li><p>意向共享锁（IS）</p><p>表示事务准备给数据行加入共享锁，事务在给一个数据行加共享锁之前必须先取得该表的IS锁。</p></li><li><p>意向排它锁（IX）</p><p>表示事务准备给数据行加入排它锁，事务在给一个数据行加排它锁之前必须先取得该表的IX锁。</p></li></ul></li></ul></li></ul><h5 id="3-一些锁的细节"><a href="#3-一些锁的细节" class="headerlink" title="3. 一些锁的细节"></a>3. 一些锁的细节</h5><ul><li><p>意向锁的细节</p><p>MySQL中表锁和行锁共存，若不引入意向锁，该如何判断是否锁冲突呢？</p><p>假设事务T要对表T1加X锁，那就必须要判断T1表下每一个数据行是否加了S锁或者X锁。这样做的效率会非常低，需要对整个表进行遍历。在引入意向锁之后情况变得简单了。</p><p>假设事务T要对表T1加X锁，在这之前假设已经有事务A对数据行R加了S锁，那么此时表上已经有IS锁了（事务在给一个数据行加S锁之前必须先取得该表的IS锁）。由于X锁和IS锁冲突，所以事务T需要等待锁操作完成。这样就省去了遍历的操作，提高了冲突判断效率。</p><ul><li><p>意向锁是表锁，表示的是一种意向，仅仅表示事务正在读或写某一行记录，在真正加行锁时才会判断是否冲突。意向锁是InnoDB自动加的，不需要用户干预。</p></li><li><p>IX和IS是表锁，不会与行锁发生冲突，只会与表锁发生冲突。</p></li></ul></li><li><p>有哪些锁算法</p><ul><li><p>Record Lock</p><p>记录锁，锁定一个行记录。</p><p>由于InnoDB特殊的索引机制，数据库操作使用主键索引时，InnoDB会锁住主键索引；使用非主键索引时，InnoDB会先锁住非主键索引，再锁定主键索引</p></li><li><p>Gap Lock</p><p>间隙锁，锁定一个区间，不包括记录本身</p></li><li><p>Next-Key Lock</p><p>记录锁+间隙锁（临键锁），锁定行记录和区间</p><p>InnoDB引擎采用Next-Key Lock来解决幻读问题。因为Next-Key Lock是锁住一个范围，所以就不会产生幻读问题。但是需要注意的是，InnoDB只在Repeatable Read隔离级别下使用该机制。</p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> mysql </tag>
            
            <tag> InnoDB </tag>
            
            <tag> 数据库锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL存储引擎总结</title>
      <link href="/2019/12/26/MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%80%BB%E7%BB%93/"/>
      <url>/2019/12/26/MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h5 id="1-有哪些存储引擎"><a href="#1-有哪些存储引擎" class="headerlink" title="1. 有哪些存储引擎"></a>1. 有哪些存储引擎</h5><ul><li><p>InnoDB</p><p>行锁设计，支持外键和事务，支持一致性非锁定读，支持多版本并发控制，实现了SQL标准的四种隔离级别，提供插入缓冲，二次写，自适应哈希索引和预读等功能。</p></li><li><p>MyISAM</p><p>表锁设计，不支持事务，支持全文索引，适合OLAP应用</p></li><li><p>NDB</p><p>NDB是一个集群存储引擎，索数据全部方内存中</p></li><li><p>Memory</p><p>将表中的数据全部放在内存中，如果数据库重启或者发生崩溃，数据都将小时，非常适合临时数据的临时表，默认使用哈希索引</p></li><li><p>Archive存储引擎</p><p>只支持插入和查询操作，支持行压缩存储，压缩比一般可以达到1：10，使用行锁来实现插入，适合存储日志信息</p></li><li><p>Federated存储引擎</p><p>不存放数据，类似一个网关，指向远程的MYSQL数据库服务器</p></li><li><p>Maria存储引擎</p><p>用来替代MyISAM存储引擎，缓存数据和索引文件，行锁设计，提供MVCC功能，支持事务</p></li></ul><h5 id="2-InnoDB存储引擎与MyISAM存储引擎的对比"><a href="#2-InnoDB存储引擎与MyISAM存储引擎的对比" class="headerlink" title="2. InnoDB存储引擎与MyISAM存储引擎的对比"></a>2. InnoDB存储引擎与MyISAM存储引擎的对比</h5><ol><li>InnoDB支持事务；MyISAM不支持事务。</li><li>InnoDB支持外键；MyISAM不支持外键。</li><li>InnoDB锁的粒度是行锁；MyISAM锁的粒度是表锁。</li><li>InnoDB把数据和索引存在一起；MyISAM把表分为三个文件：表结构(.frm)、表内容(MYD)、表索引(MYI)。</li><li>InnoDB不保存表的具体行数，需要通过扫描表来获取有多少行；MyISAM保存表的具体行数。</li><li>InnoDB删除表中数据时是一行一行的删除；MyISAM删除表时是先<code>drop</code>表，然后重建表。</li><li>InnoDB可跨平台拷贝直接使用；MyISAM很难跨平台直接使用。</li><li>InnoDB表格很难压缩；MyISAM表格可以被压缩。</li><li>InnoDB中必须包含只有该字段的索引；MyISAM表中可以和其他字段一起建立联合索引。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> mysql </tag>
            
            <tag> InnoDB </tag>
            
            <tag> 存储引擎 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL调优：Explain命令的使用</title>
      <link href="/2019/12/26/MySQL%E8%B0%83%E4%BC%98%20Explain%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2019/12/26/MySQL%E8%B0%83%E4%BC%98%20Explain%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h5 id="1-Explain是什么有什么用"><a href="#1-Explain是什么有什么用" class="headerlink" title="1. Explain是什么有什么用"></a>1. Explain是什么有什么用</h5><p>使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。分析你的查询语句或是表结构的性能瓶颈。</p><h5 id="2-Explain执行计划包含哪些字段-每个字段表示什么"><a href="#2-Explain执行计划包含哪些字段-每个字段表示什么" class="headerlink" title="2. Explain执行计划包含哪些字段,每个字段表示什么"></a>2. Explain执行计划包含哪些字段,每个字段表示什么</h5><ol><li><p><strong>id</strong></p><p>select查询的序列号,包含一组数字，表示查询中执行select子句或操作表的顺序</p><ul><li>id相同的时候 ，执行顺序是由上至下</li><li>id不同的时候，id值越大的越先执行</li><li>id相同和不同同时存在的时候，id如果相同，可以认为是一组，从上往下顺序执行；<br>在所有组中，id值越大，优先级越高，越先执行</li></ul></li><li><p><strong>select_type</strong></p><p>查询的类型，主要是用于区别普通查询、联合查询、子查询等的复杂查询。</p><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>SIMPLE</td><td>简单的 select 查询,查询中不包含子查询或者UNION</td></tr><tr><td>PRIMARY</td><td>查询中若包含任何复杂的子部分，最外层查询则被标记为Primary</td></tr><tr><td>DERIVED</td><td>在FROM列表中包含的子查询被标记为DERIVED(衍生)MySQL会递归执行这些子查询, 把结果放在临时表里。</td></tr><tr><td>SUBQUERY</td><td>在SELECT或WHERE列表中包含了子查询</td></tr><tr><td>DEPENDENT SUBQUERY</td><td>在SELECT或WHERE列表中包含了子查询,子查询基于外层</td></tr><tr><td>UNCACHEABLE SUBQUREY</td><td>无法被缓存的子查询</td></tr><tr><td>UNION</td><td>若第二个SELECT出现在UNION之后，则被标记为UNION；若UNION包含在FROM子句的子查询中,外层SELECT将被标记为：DERIVED</td></tr><tr><td>UNION RESULT</td><td>从UNION表获取结果的SELECT</td></tr></tbody></table></li><li><p><strong>table</strong></p><p>显示这一行的数据是关于哪张表的</p></li><li><p><strong>type</strong></p><p>type显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是： </p><p>system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range(尽量保证) &gt; index &gt; ALL </p><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>system</td><td>表只有一行记录（等于系统表），这是const类型的特列，平时不会出现，这个也可以忽略不计</td></tr><tr><td>const</td><td>表示通过索引一次就找到了,const用于比较primary key或者unique索引。因为只匹配一行数据，所以很快,如将主键置于where列表中，MySQL就能将该查询转换为一个常量</td></tr><tr><td>eq_ref</td><td>唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描</td></tr><tr><td>ref</td><td>非唯一性索引扫描，返回匹配某个单独值的所有行,本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以他应该属于查找和扫描的混合体</td></tr><tr><td>range</td><td>只检索给定范围的行,使用一个索引来选择行。key 列显示使用了哪个索引&lt;br一般就是在你的where语句中出现了between、&lt;、&gt;、in等的查询。这种范围扫描索引扫描比全表扫描要好，因为它只需要开始于索引的某一点，而结束语另一点，不用扫描全部索引。</td></tr><tr><td>index</td><td>Full Index Scan，index与ALL区别为index类型只遍历索引树。这通常比ALL快，因为索引文件通常比数据文件小。（也就是说虽然all和Index都是读全表，但index是从索引中读取的，而all是从硬盘中读的）</td></tr><tr><td>all</td><td>Full Table Scan，将遍历全表以找到匹配的行</td></tr></tbody></table><p>至少要到达range级别</p></li><li><p><strong>possible_keys</strong></p><p>显示可能应用在这张表中的索引，一个或多个。查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用。（可能会用到）</p></li><li><p><strong>key</strong></p><p>实际使用的索引。如果为NULL，则没有使用索引</p></li><li><p><strong>key_len</strong></p><p>表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。 </p></li><li><p><strong>ref</strong></p><p>显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值</p></li><li><p><strong>rows</strong></p><p>rows列显示MySQL认为它执行查询时必须检查的行数。</p></li><li><p><strong>extra</strong></p><p>包含不适合在其他列中显示但十分重要的额外信息，文件排序/使用where信息/临时表等信息。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB存储引擎总结</title>
      <link href="/2019/12/25/InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%80%BB%E7%BB%93/"/>
      <url>/2019/12/25/InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h4 id="1-MySQL体系结构和存储引擎"><a href="#1-MySQL体系结构和存储引擎" class="headerlink" title="1. MySQL体系结构和存储引擎"></a>1. MySQL体系结构和存储引擎</h4><p><strong>1. 什么是数据库，什么是数据库实例</strong></p><p>数据库是操作系统文件的集合。数据库实例时操作数据库文件的进程。</p><p><strong>2. MySQL的线程架构</strong></p><p>MySQL时单进程多线程架构的数据库</p><p><strong>3. MySQL由哪几部分组成</strong></p><p>连接池组件，管理服务和工具组件，SQL接口组件，查询分析器组件，优化器组件，缓冲组件，插件式存储引擎，物理文件组成。</p><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%80%BB%E7%BB%93/image-202001302029.jpg" alt="img"></p><p><strong>4. MySQL与其他数据库的区别</strong></p><p>拥有插件式的表存储引擎（存储引擎是基于表的不是基于数据库的）</p><p><strong>5. 有哪些存储引擎，各自的特点是什么</strong></p><ul><li><p>InnoDB</p><p>行锁设计，支持外键和事务，支持一致性非锁定读，支持多版本并发控制，实现了SQL标准的四种隔离级别，提供插入缓冲，二次写，自适应哈希索引和预读等功能。</p></li><li><p>MyISAM</p><p>表锁设计，不支持事务，支持全文索引，适合OLAP应用</p></li><li><p>NDB</p><p>NDB是一个集群存储引擎，索数据全部方内存中</p></li><li><p>Memory</p><p>将表中的数据全部放在内存中，如果数据库重启或者发生崩溃，数据都将小时，非常适合临时数据的临时表，默认使用哈希索引</p></li><li><p>Archive存储引擎</p><p>只支持插入和查询操作，支持行压缩存储，压缩比一般可以达到1：10，使用行锁来实现插入，适合存储日志信息</p></li><li><p>Federated存储引擎</p><p>不存放数据，类似一个网关，指向远程的MYSQL数据库服务器</p></li><li><p>Maria存储引擎</p><p>用来替代MyISAM存储引擎，缓存数据和索引文件，行锁设计，提供MVCC功能，支持事务</p></li></ul><p><strong>6. InnoDB存储引擎与MyISAM存储引擎的对比</strong></p><ol><li>InnoDB支持事务；MyISAM不支持事务。</li><li>InnoDB支持外键；MyISAM不支持外键。</li><li>InnoDB锁的粒度是行锁；MyISAM锁的粒度是表锁。</li><li>InnoDB把数据和索引存在一起；MyISAM把表分为三个文件：表结构(.frm)、表内容(MYD)、表索引(MYI)。</li><li>InnoDB不保存表的具体行数，需要通过扫描表来获取有多少行；MyISAM保存表的具体行数。</li><li>InnoDB删除表中数据时是一行一行的删除；MyISAM删除表时是先<code>drop</code>表，然后重建表。</li><li>InnoDB可跨平台拷贝直接使用；MyISAM很难跨平台直接使用。</li><li>InnoDB表格很难压缩；MyISAM表格可以被压缩。</li><li>InnoDB中必须包含只有该字段的索引；MyISAM表中可以和其他字段一起建立联合索引。</li></ol><p><strong>7. 如何查看数据库支持哪些存储引擎</strong></p><p><code>show engine</code></p><p><strong>8. 连接MySQL的方式有哪些</strong></p><ol><li>TCP/IP</li><li>命名管道和共享内存（windows）</li><li>Unix域套接字（xxx.socket）</li></ol><hr><h4 id="2-InnoDB存储引擎"><a href="#2-InnoDB存储引擎" class="headerlink" title="2. InnoDB存储引擎"></a>2. InnoDB存储引擎</h4><p><strong>1. 有哪些InnoDB版本</strong></p><table><thead><tr><th>版本</th><th>功能</th></tr></thead><tbody><tr><td>老版本InnoDB</td><td>支持事务，行锁设计，MVCC</td></tr><tr><td>InnoDB 1.0.x</td><td>增加了compress和dynamic页格式</td></tr><tr><td>InnoDB 1.1.x</td><td>增加了Linux AIO，多回滚段</td></tr><tr><td>InnoDB 1.2.x</td><td>增加了全文索引支持，在线索引添加</td></tr></tbody></table><p><strong>2. InnoDB存储引擎的体系结构</strong></p><p>由<code>内存池</code>和<code>后台线程</code>组成</p><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%80%BB%E7%BB%93/image-20200116093058928.png" alt="image-20200116093058927"></p><p><strong>3. 由哪些后台线程，作用是什么</strong></p><ul><li><p>Master Thread</p><p>负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲、undo页的回收等。</p></li><li><p>IO Thread</p><p>处理异步IO请求的回调，有四种IO Threa，包括write、read、insert buffer和log IO Thread</p></li><li><p>Purge Thread</p><p>事务提交后，undo页就不需要了，Purge Thread用来回收已分配的undo页。</p></li><li><p>Page Cleaner Thread</p><p>进行脏页的刷新（这个功能是从Master Thread中抽出来的）</p></li></ul><p><strong>4. 有哪些内存池，都用来存放什么</strong></p><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%80%BB%E7%BB%93/image-20200116094402831.png" alt="image-20200116094402830"></p><ul><li><p>缓冲池</p><p>缓存数据页、索引页、插入缓冲、自适应哈希索引、锁信息和数据字典信息等。</p></li><li><p>重做日志缓冲池</p><p>缓存重做日志，首先将重做日志信息放入重做日志缓冲池，然后按一定的频率将其刷新到重做日志文件。</p></li><li><p>额外的内存缓冲池</p><p>对数据结构本身的内存分配使用额外的内存缓冲池管理</p></li></ul><p><strong>5. 缓冲池如何管理的</strong></p><p>由LRU列表、Free列表和Flush列表管理。</p><ul><li><p>LRU List</p><p>使用LRU（最近最少使用）算法管理页，使用频繁的页放在列表的前端，使用不频繁的页放在列表尾端，当内存不足时，首先释放LRU尾端的页。存储引擎中的LRU算法做了优化，插入新的页时不是放到前端，而是放在列表长度的5/8处，原因是，如何直接读取到的页放LRU的首部，对于某些操作需要访问表中的许多页，但这些页仅在本次操作中需要，并不是活跃的热点数据，这样会将热点数据页从LRU中刷出。</p></li><li><p>Free List</p><p>用来管理空闲的页，分配新的页时必须在这个列表中查找空闲页，如果没有就淘汰LRU列表中的页。</p></li><li><p>Flush List</p><p>管理脏页列表，注意脏页既存在于Flush列表又存在于LRU列表。</p></li></ul><p><strong>6. 什么是checkpoint</strong></p><p>checkpoint就是将脏页刷新到磁盘的一种机制。InnoDB存储引擎提交事务的时候，需要先写重做日志，然后把修改缓存中的页，这样即使数据库宕机也可以通过重做日志恢复，但是问题是重做日志的大小是有限制的，当重做日志文件不足时就可能导致数据丢失，另外如果只通过重做日志来恢复，则需要把所有的修改重做一遍时间太长了，因此引入了checkpoint技术，他可以在某些情况下将脏页刷新到磁盘，这样就不用担心重做日志文件大小不足的问题，并且恢复时checkpoint之前的重做日志不需要恢复，加快来了恢复的时间。</p><p><strong>7. checkpoint解决的问题</strong></p><ul><li>缩短数据库恢复的时间</li><li>缓冲池不够用时，将脏页刷新到磁盘</li><li>重做日志不可用时，将脏页刷新到磁盘</li></ul><p><strong>8. checkpoint的分类</strong></p><ul><li><p>Sharo Checkpoint</p><p>数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式。</p></li><li><p>Fuzzy Checkpoint</p><ul><li><p>Master Thread Checkpoint</p><p>隔一定时间间隔从缓冲池的脏页列表中刷新一定比列的页到磁盘（异步执行）</p></li><li><p>FLUSH_LRU_LIST Checkpoint</p><p>InnoDB要保证LRU列表中有差不多100个空闲页，如果不足会溢出LRU列表尾端的页，如果这些页中有脏页，会进行Checkpoint</p></li><li><p>Aysnc/Sync Flush Checkpoint</p><p>重做日志不可用时，这时需要强制将一些页刷新回磁盘，而此时脏页是从脏页列表中选取的。</p></li><li><p>Dirty Page too much Checkpoint</p><p>脏页数量太多会导致InnoDB存储引擎强制进行Checkpoint</p></li></ul></li></ul><p><strong>9. Master线程的工作方式</strong></p><p><strong>10. InnoDB有哪些关键特性</strong></p><ul><li>插入缓冲</li><li>两次写</li><li>自适应哈希索引</li><li>异步IO</li><li>刷新邻接页</li></ul><p><strong>11. 什么是插入缓冲</strong></p><p>对于自增长主键聚集索引的插入是顺序的不需要磁盘的随机读取，效率非常高，但是每张表只有一个聚集索引，其他的都是非聚集索引，对于非聚集索引的插入需要随机读取磁盘（离散的访问非聚集索引页），效率非常低，因此InnoDB存储引擎引入了插入缓冲来解决非聚集索引的插入性能问题：对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入，若不在则先放入一个插入缓冲对象中，然后再以一定的频率和情况进行插入缓冲和富非聚集多月叶子结点的合并操作，这样多个插入就合并到一个操作中，这就大大提高了对非聚集索引插入的性能问题。插入缓冲只适应与非唯一的非聚集索引，非唯一的原因是如果是唯一的，那么就要检查每一个页判断是否已存在，这样查找也是离散读取，插入缓冲就没有任何意义了。除了插入缓冲对于更新和删除也有类似的操作（他们的思想是在内存中进行操作，这是一种欺骗，但是之后会写入磁盘保证一致性）。</p><p><strong>11. 插入缓冲是如何实现的</strong></p><p>插入缓冲是B+树</p><p><strong>12. 什么是两次写</strong></p><p>InnoDB的页默认大小为16k，但是写入磁盘是按照磁盘的块为单位写，也就是说每次将数据页写会磁盘不是一个原子过程，可能写到一半的时候突然数据库宕机，这个问题叫做部分写失效，这个时候是无法通过redo日志来恢复的，因为redo日志是一个逻辑日日志，只记录了某个偏移量写什么记录，而这个页本身就已经损坏了，所有没有无法恢复。两次写是为了解决这个问题：在内存中有一个2m大小的两次写缓存，在进行脏页刷新的时候，首先会将脏页分两次复制到两次写缓存中，然后两次写缓存会刷新到磁盘中的共享表中，写入磁盘后再进行脏页的刷新，这样就算发生部分写失效，也可以找到该页的副本进行恢复。</p><p><strong>13. 什么是自适应哈希索引</strong></p><p>哈希是一种快速查询的方法，时间复杂度为O(1)；InnoDB存储引擎会监控各索引页的查询，如果发现建立哈希所有可以提高效率就坏建立哈希索引，这种哈希索引称为自适应哈希索引，他是不需要用户干预的。</p><p><strong>14. 什么是异步IO</strong></p><p>异步IO是指可以发出一个IO后不需要等待直接发起另一个IO，当所有IO请求发送出去，等待所有IO完成，这样可以提高IO效率。</p><p><strong>15. 什么是刷新邻接页</strong></p><p>当刷新一个脏页的时候，会检查这个脏页所在的区的其他页，如果也是脏页那么也会被刷新，这样的好处是可以通过AIO把多个IO合并成一个IO</p><hr><h4 id="3-文件"><a href="#3-文件" class="headerlink" title="3. 文件"></a>3. 文件</h4><p><strong>1. MySQL中有哪些文件</strong></p><p>有参数文件、日志文件、套接字文件、pid文件、表结构定义文件。</p><p><strong>2. MySQL数据库的参数类型有哪些</strong></p><p>有静态参数和动态参数，动态参数可以在数据库实例启动的情况下修改生效，静态参数必须关闭数据库实例修改后重启。</p><p><strong>3. 有哪些日志文件</strong></p><ul><li><p>错误日志</p><p>记录数据库在启动运行关闭过程中发生的错误信息。</p></li><li><p>二进制日志</p><p>记录了对数据库执行更改的所有操作，用于恢复，复制和审计的功能</p></li><li><p>慢查询日志</p><p>可以在数据库启动时设置一个慢查询阈值，所有查询时间大于这个阈值的sql语句都会被记录下来，通过慢查询日志可以定位到查询效率低的sql语句，方便排查问题。</p></li><li><p>查询日志</p><p>记录了所有的查询sql语句包括未执行的</p></li></ul><p><strong>4. InnoDB存储引擎有哪些独有的文件</strong></p><p>表空间文件和重做日志文件。</p><hr><h4 id="4-表"><a href="#4-表" class="headerlink" title="4. 表"></a>4. 表</h4><hr><h4 id="5-索引和算法"><a href="#5-索引和算法" class="headerlink" title="5. 索引和算法"></a>5. 索引和算法</h4><p><strong>1. 什么是索引</strong></p><p>索引是一种用于快速查询和排好序的数据结构</p><p><strong>2. 有哪些索引</strong></p><ul><li>从数据结构的角度<ul><li>B+树索引</li><li>hash索引</li><li>全文索引</li></ul></li><li>从物理存储角度<ul><li>聚集索引</li><li>非聚集索引</li></ul></li><li>从逻辑角度<ul><li>主键索引</li><li>单列索引</li><li>符合索引</li><li>唯一索引或非唯一索引</li><li>空间索引</li></ul></li></ul><p><strong>3. 什么是聚集索引，什么是非聚集索引</strong></p><p>聚集索引就是按照表的主键构造一棵B+树，叶节点存放了整张表的行记录数据，聚集索引的特性是数据是索引的一部分。非聚集索引指定了表中记录的逻辑顺序，但记录的物理顺序和索引的顺序不一致。聚集索引和非聚集索引都采用了B+树的结构，但非聚集索引的叶子层并不与实际的数据页相重叠，而采用叶子层包含一个指向表中的记录在数据页中的指针的方式。</p><p><strong>4. 聚集索引的优点和缺点</strong></p><p>聚集索引的优点是查询速度快，并且一点某个记录找到了其相邻的记录就在这条记录的前后，适合范围查找。缺点是对表进行修改的速度比较慢，这是为了保持表中的记录的物理顺序与索引的顺序一致，而把记录插入到数据页的相应位置，必须在数据页中进行数据重排， 降低了执行速度。</p><p><strong>5. 什么时候建聚集索引</strong></p><ol><li>此列包含有限数目的不同值；</li><li>查询的结果返回一个区间的值；</li><li>查询的结果返回某值相同的大量结果集。</li></ol><p><strong>6. 什么时候需要建立索引</strong></p><ol><li>主键自动建立唯一索引</li><li>频繁作为查询条件的字段应该创建索引</li><li>查询中与其他表管理的字段，外键关系建立索引</li><li>查询中排序的字段建立索引</li><li>查询中统计或者分组字段</li></ol><p><strong>7. 说明时候不需要建立索引</strong></p><ul><li>表记录太少</li><li>经常增删改的表</li><li>where条件用不到的字段</li><li>数据区分度比较小的字段、</li></ul><p><strong>8. 什么是B+树</strong></p><p>B+树是一个多路的平衡搜索树，B+树的结点由有序的元素和指针组成，指针的个数称为B+树的阶，B+树的特点是。</p><ul><li>根节点至少有一个元素，非根节点元素的范围为m/2&lt;=k&lt;=m-1</li><li>B+树有两种类型的节点，内部节点和叶子节点，内部节点不存储数据，只存储所有，数据都存储在叶子节点。</li><li>内部节点的key是按顺序存放的，元素的左子树的key都小于它，右子树的key都大于它，叶子结点中的记录也按照key的大小排列。</li><li>每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。</li><li>父节点存有右孩子的第一个元素的索引。</li></ul><p><strong>9. 什么是B树</strong></p><p>B树也称B-树,它是一颗多路平衡查找树。二叉树我想大家都不陌生，其实，B树和后面讲到的B+树也是从最简单的二叉树变换而来的</p><ul><li><p>每个节点最多有m-1个<strong>关键字</strong>（可以存有的键值对）。</p></li><li><p>根节点最少可以只有1个<strong>关键字</strong>。</p></li><li><p>非根节点至少有m/2个<strong>关键字</strong>。</p></li><li><p>每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。</p></li><li><p>所有叶子节点都位于同一层，或者说根节点到每个叶子节点的长度都相同。</p></li><li><p>每个节点都存有索引和数据，也就是对应的key和value。</p></li></ul><p><strong>10. 对比以下B+树比B树的优点（为什么MySQL采用B+树作为索引而不是B树）</strong></p><ul><li>单一节点存储的元素更多，使得查询的IO次数更少，所以也就使得它更适合做为数据库MySQL的底层数据结构了。</li><li>所有的查询都要查找到叶子节点，查询性能是稳定的，而B树，每个节点都可以查找到数据，所以不稳定。</li><li>所有的叶子节点形成了一个有序链表，更加便于查找。</li></ul><hr><h4 id="6-锁"><a href="#6-锁" class="headerlink" title="6. 锁"></a>6. 锁</h4><p><strong>1. 什么是锁，为什么要加锁</strong></p><p>锁是一种用来实现对共享资源安全访问的工具，当多个用户并发地存取数据时，在数据库中就可能会产生多个事务同时操作同一行数据的情况，若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据的一致性。</p><p><strong>2. InnoDB锁的类型</strong></p><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%80%BB%E7%BB%93/image-202001302035.jpg" alt="img"></p><ul><li><p>按照锁的粒度来分</p><ul><li><p>表锁</p><p>MySQL中锁定粒度最大的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率越高，并发度最低，MyISAM和InnoDB引擎都支持表级锁。</p></li><li><p>行锁</p><p>Mysql中锁定粒度最小的一种锁，只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。</p></li><li><p>页锁</p></li></ul></li><li><p>按照锁算法来分</p><ul><li>Recodrd Lock</li><li>Gap Lock</li><li>Next-key Lock</li></ul></li><li><p>按照加锁机制来分</p><ul><li><p>乐观锁</p><p>乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务；</p></li><li><p>悲观锁</p><p>悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁；</p></li></ul></li><li><p>按照兼容性来分</p><ul><li><p>共享锁</p><p>共享锁（<strong>Share Locks</strong>，简记为S锁）又称为<strong>读锁</strong>。其它事务可以并发地读取数据，可以再加共享锁，但任何事务都不能获取数据上的排它锁，直至已经释放所有共享锁。</p></li><li><p>排他锁</p><p>排它锁（<strong>Exclusive lock</strong>，简记为X锁）又称为<strong>写锁</strong>。若事务对数据对象加上了排它锁，则只允许该事务对数据对象进行读取和修改，其它事务不能再对数据对象加任何类型的锁，直到该事务释放对象上的排它锁。在更新操作(INSERT、UPDATE 或 DELETE)过程中始终应用排它锁。</p></li><li><p>意向锁</p><p>为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是<strong>表锁</strong>。</p><ul><li><p>意向共享锁（IS）</p><p>表示事务准备给数据行加入共享锁，事务在给一个数据行加共享锁之前必须先取得该表的IS锁。</p></li><li><p>意向排它锁（IX）</p><p>表示事务准备给数据行加入排它锁，事务在给一个数据行加排它锁之前必须先取得该表的IX锁。</p></li></ul></li></ul></li></ul><p><strong>3. 意向锁是什么，解决了什么问题</strong></p><p>MySQL中表锁和行锁共存，若不引入意向锁，该如何判断是否锁冲突呢？</p><p>假设事务T要对表T1加X锁，那就必须要判断T1表下每一个数据行是否加了S锁或者X锁。这样做的效率会非常低，需要对整个表进行遍历。在引入意向锁之后情况变得简单了。</p><p>假设事务T要对表T1加X锁，在这之前假设已经有事务A对数据行R加了S锁，那么此时表上已经有IS锁了（事务在给一个数据行加S锁之前必须先取得该表的IS锁）。由于X锁和IS锁冲突，所以事务T需要等待锁操作完成。这样就省去了遍历的操作，提高了冲突判断效率。</p><ul><li><p>意向锁是表锁，表示的是一种意向，仅仅表示事务正在读或写某一行记录，在真正加行锁时才会判断是否冲突。意向锁是InnoDB自动加的，不需要用户干预。</p></li><li><p>IX和IS是表锁，不会与行锁发生冲突，只会与表锁发生冲突。</p></li></ul><p><strong>4. 有哪些锁算法</strong></p><ul><li><p>Record Lock</p><p>记录锁，锁定一个行记录。</p><p>由于InnoDB特殊的索引机制，数据库操作使用主键索引时，InnoDB会锁住主键索引；使用非主键索引时，InnoDB会先锁住非主键索引，再锁定主键索引</p></li><li><p>Gap Lock</p><p>间隙锁，锁定一个区间，不包括记录本身</p></li><li><p>Next-Key Lock</p><p>记录锁+间隙锁（临键锁），锁定行记录和区间</p><p>InnoDB引擎采用Next-Key Lock来解决幻读问题。因为Next-Key Lock是锁住一个范围，所以就不会产生幻读问题。但是需要注意的是，InnoDB只在Repeatable Read隔离级别下使用该机制。</p></li></ul><hr><h4 id="7-事务"><a href="#7-事务" class="headerlink" title="7. 事务"></a>7. 事务</h4><p><strong>1. 事务有哪些特性</strong></p><ul><li><p>A（原子性）</p><p>原子性指的是一组操作不可分割要么全部执行成功要么全部执行失败，这有全部执行成功整个事务才算成功。</p></li><li><p>C（一致性）</p><p>事务将数据库从一种状态转变为下一种状态，事务开始和结束后，数据库的完整性约束没有被破坏。</p></li><li><p>I（隔离性）</p><p>事务与事务之间是相互分离的，一个事务提交前对其他事务是不可见的。</p></li><li><p>D（持久性）</p><p>事务一旦提交，其结果是永久性的，即使发生宕机数据库也能恢复。</p></li></ul><p><strong>2. 什么是事务</strong></p><p>事务就是访问或者更新数据库时的一个执行单元，这个执行单元中的所有操作，要么全部完成要么全部要失败</p><p><strong>3. 事务有哪些分类</strong></p><ul><li><p>扁平事务</p><p>所有操作都是在一个层次，操作是原子的，要么全部执行要么都回滚，不能回滚部分。</p></li><li><p>带保存点是扁平事务</p><p>允许事务回滚到当事务的一个较早的状态。（保存点）</p></li><li><p>链事务</p><p>在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式的传给下一个要开始的事务。需要注意，提交事务操作和下一个事务操作将合并为一个<strong>原子操作</strong>，就是下一个事务可以看到上一个事务的结果。</p><p>链事务，就是指回滚时，只能恢复到最近一个保存点；而带有保存点的扁平事务则可以回滚到任意正确的保存点。</p><p>链事务在执行commit后就会释放当前事务所持有的所有锁，而带有保存点的扁平事务不会影响所持有的锁。</p></li><li><p>嵌套事务</p><p>事务与事务之间是有层次结构的</p></li><li><p>分布式事务</p><p>分布式环境下的事务</p></li></ul><p><strong>4. 事务的隔离级别</strong></p><ul><li>未提交读</li><li>已提交读</li><li>可重复读</li><li>可串行化</li></ul><p><strong>5. 事务是怎么实现的</strong></p><p>事务具有四种属性ACID，其中隔离性是通过锁来实现的，其他的三种属性是用过undo log和redo log来实现的。</p><p><strong>6. redo日志和undo日志的区别</strong></p><ul><li>redo日志用来保证事务的原子性和持久性，undo日志用来保证事务的一致性</li><li>redo日志和undo日志都可以视为一种恢复操作，redo日志恢复提交修改的页操作，undo日志用来回滚行记录到某个特定的版本</li><li>redo日志是物理日志，记录的是对页的物理修改，undo日志是逻辑日志，根据每行记录进行记录</li></ul><p><strong>7. 事务的ACID是怎么实现的</strong></p><p>事务的原子性是通过undo日志实现的、持久性是通过redo日志或二进制日志实现的、隔离性是通过锁机制实现的，一致性是通过保证原子性、持久性和隔离性，数据库本身和应用层面进行保证的。</p><p><a href="https://www.cnblogs.com/kismetv/p/10331633.html" target="_blank" rel="noopener">https://www.cnblogs.com/kismetv/p/10331633.html</a></p><p><strong>7. 详细介绍重做日志</strong></p><ul><li><p>什么是重做日志，重做日志有什么用</p><p>在事务提交前必须将该事务的所有日志写到重做日志文件中，重做日志文件由两部分组成，分别是redo日志和undo日志。</p></li><li><p>如何保证重做日志缓冲写入重做日志文件</p><p>在每次重做日志缓冲写入重做日志文件时都会调用fsync操作，将数据同步到磁盘，因此重做日志文件写入的效率与fsync操作调用的频率有关，允许用户控制重做日志刷新到磁盘的策略，主要由三种策略，事务提交时必须调用一次fsync；事务提交时不进行出写入重做日志操作，这个操作交给master thread完成，它会没1秒钟进行一次fsync操作；不进行fsync操作，由操作系统来决定什么时候同步。fsync执行的越频繁效率越低，但是越不容易丢失数据，</p></li><li><p>redo日志的作用</p><p>redo日志是来保证数据库的持久性的，当事务提交后会将修改写入缓存，如果发生了宕机可以通过redo日志来恢复。</p></li><li><p>undo日志的作用</p><p>事务在对数据库进行修改时，由于某种原因失败了，或者用户请求回滚，可以利用undo信息将数据回滚到修改之前的样子。</p><p>undo log属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作：对于每个insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。</p></li><li><p>为什么redo日志的写入会比刷新脏页的速度快</p><ul><li><p>刷脏是随机IO，因为每次修改的数据位置随机，但写redo log是追加操作，属于顺序IO。</p></li><li><p>刷脏是以数据页（Page）为单位的，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入；而redo log中只包含真正需要写入的部分，无效IO大大减少。</p></li></ul></li><li><p>redo日志和二进制日志的区别</p><ul><li>作用不同：redo log是用于crash recovery的，保证MySQL宕机也不会影响持久性；binlog是用于point-in-time recovery的，保证服务器可以基于时间点恢复数据，此外binlog还用于主从复制。</li><li>层次不同：redo log是InnoDB存储引擎实现的，而binlog是MySQL的服务器层(可以参考文章前面对MySQL逻辑架构的介绍)实现的，同时支持InnoDB和其他存储引擎。</li><li>内容不同：redo log是物理日志，内容基于磁盘的Page；binlog的内容是二进制的，根据binlog_format参数的不同，可能基于sql语句、基于数据本身或者二者的混合。</li><li>写入时机不同：binlog在事务提交时写入；redo log的写入时机相对多元</li></ul></li></ul><hr><h4 id="8-备份与恢复"><a href="#8-备份与恢复" class="headerlink" title="8. 备份与恢复"></a>8. 备份与恢复</h4><hr><p><em>参考：《MySQL技术内幕：InnoDB存储引擎》</em></p><p><strong>（未完待续）</strong></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> mysql </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL索引总结</title>
      <link href="/2019/12/25/MySQL%E7%B4%A2%E5%BC%95%E6%80%BB%E7%BB%93/"/>
      <url>/2019/12/25/MySQL%E7%B4%A2%E5%BC%95%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>MySQL索引包含两部分内容，一部分是MySQL索引本身，一部分是B树和B+树。</p><p>对于MySQL索引本身需要了解基本的概念和原理，知道有哪些索引？怎么建立索引？什么时候应该建索引，索引建立在什么字段上。</p><h5 id="1-MySQL索引"><a href="#1-MySQL索引" class="headerlink" title="1. MySQL索引"></a>1. MySQL索引</h5><ul><li><p>什么是索引</p><p>索引是一种用于快速查询和排好序的数据结构</p></li><li><p>索引的分类（分类一定是基于某种标准来分的）</p><ul><li>从数据结构的角度<ul><li>B+树索引</li><li>hash索引</li><li>全文索引</li></ul></li><li>从物理存储角度<ul><li>聚集索引</li><li>非聚集索引</li></ul></li><li>从逻辑角度<ul><li>主键索引</li><li>单列索引</li><li>符合索引</li><li>唯一索引或非唯一索引</li><li>空间索引</li></ul></li></ul></li><li><p>什么是聚集索引，什么是非聚集索引</p></li></ul><ul><li><p>什么时候需要建立索引</p><ol><li>主键自动建立唯一索引</li><li>频繁作为查询条件的字段应该创建索引</li><li>查询中与其他表管理的字段，外键关系建立索引</li><li>查询中排序的字段建立索引</li><li>查询中统计或者分组字段</li></ol></li><li><p>说明时候不需要建立索引</p><ul><li>表记录太少</li><li>经常增删改的表</li><li>where条件用不到的字段</li><li>数据区分度比较小的字段、</li></ul></li></ul><h5 id="2-B树和B-树的概念"><a href="#2-B树和B-树的概念" class="headerlink" title="2. B树和B+树的概念"></a>2. B树和B+树的概念</h5><ul><li><p>什么是B+树</p><p>B+树是一个多路的平衡搜索树，B+树的结点由有序的元素和指针组成，指针的个数称为B+树的阶，根节点至少有一个元素，非根节点元素的范围为m/2&lt;=k&lt;=m-1,B+树有两种类型的节点，内部节点和叶子节点，内部节点不存储数据，只存储所有，数据都存储在叶子节点。内部节点的key是按顺序存放的，元素的左子树的key都小于它，右子树的key都大于它，叶子结点中的记录也按照key的大小排列。每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。父节点存有右孩子的第一个元素的索引。</p></li></ul><ul><li><p>什么是B树</p><p>B树也称B-树,它是一颗多路平衡查找树。二叉树我想大家都不陌生，其实，B树和后面讲到的B+树也是从最简单的二叉树变换而来的</p><ul><li><p>每个节点最多有m-1个<strong>关键字</strong>（可以存有的键值对）。</p></li><li><p>根节点最少可以只有1个<strong>关键字</strong>。</p></li><li><p>非根节点至少有m/2个<strong>关键字</strong>。</p></li><li><p>每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。</p></li><li><p>所有叶子节点都位于同一层，或者说根节点到每个叶子节点的长度都相同。</p></li><li><p>每个节点都存有索引和数据，也就是对应的key和value。</p></li></ul></li></ul><h5 id="3-对比以下B-树比B树的优点（为什么用B-树作为索引而不是B树）"><a href="#3-对比以下B-树比B树的优点（为什么用B-树作为索引而不是B树）" class="headerlink" title="3. 对比以下B+树比B树的优点（为什么用B+树作为索引而不是B树）"></a>3. 对比以下B+树比B树的优点（为什么用B+树作为索引而不是B树）</h5><ul><li>单一节点存储的元素更多，使得查询的IO次数更少，所以也就使得它更适合做为数据库MySQL的底层数据结构了。</li><li>所有的查询都要查找到叶子节点，查询性能是稳定的，而B树，每个节点都可以查找到数据，所以不稳定。</li><li>所有的叶子节点形成了一个有序链表，更加便于查找。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> mysql </tag>
            
            <tag> MySQL索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP数据流与窗口管理</title>
      <link href="/2019/12/22/TCP%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%8E%E7%AA%97%E5%8F%A3%E7%AE%A1%E7%90%86/"/>
      <url>/2019/12/22/TCP%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%8E%E7%AA%97%E5%8F%A3%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h5 id="1-交互式通信"><a href="#1-交互式通信" class="headerlink" title="1. 交互式通信"></a>1. 交互式通信</h5><ul><li><p>什么是交互式通信</p><p>交互式通信是指双方通信时传输一些较小的信息，这些信息会封装成<strong>较小的报文段</strong>，但是<strong>又希望延迟尽量低</strong>。这里的问题在于，TCP每次传输的信息量很少（也就是说大部分都是TCP首部）降低了网络的利用率，但是如果让TCP发送的数据多一点(比如说几个小数据累积在一起后发送)又会带来较大的时延，如何平衡这两者关系是交互式通信要研究的问题。</p></li><li><p>交互式通信是如何做的</p><p>通常交互式通信，用户在一端输入信息希望马上看到另一方的回显信息，采取的做法是首先发送方向接收方发送一个报文，接收方收到报文后要对其进行确认，但是不同的是接收方会把回显信息与ACK信息一起返回，发生放收到后再进行确认，通过这样的优化，可以少发一个报文并且发送方也可以少等一个报文发送的时间。</p></li></ul><h5 id="2-延迟确认"><a href="#2-延迟确认" class="headerlink" title="2. 延迟确认"></a>2. 延迟确认</h5><p>TCP不会对每一个数据包都返回ACK确认,而是<strong>采取累积确认</strong>的方式，这样就可以大量减少网络中的ACK数据包，但是TCP不能够延迟任意时长，否则发送方会超时，不同的操作系统实现的延时时间不一样。延时确认不能用在对时延要求高的应用上。</p><h5 id="3-Nagle算法"><a href="#3-Nagle算法" class="headerlink" title="3. Nagle算法"></a>3. Nagle算法</h5><ul><li><p>Nagle算法解决了什么问题</p><p>Nagle算法是一种拥塞控制算法。每次发送少量的数据时，TCP的头部和IP的首部会有很大的开销，这会造成相当高的网络传输代价（这种代价对局域网没有影响，对广域网可能造成拥塞，如糊涂窗口综合征），Nagle算法就是用来解决这种<strong>小包可能导致网络拥塞的问题</strong>。</p></li><li><p>Nagle算法的原理</p><p>Nagle算法要求，当一个TCP连接中有在传数据（已经发生但还未经确认），小的报文段（长度小于SMSS，SMSS是指发送方能够发送的最大数据段的长度）就不能被发送，直到所有的在传数据都收到ACK，TCP会将小数据收集整合到一个报文段中发送。大的报文段不受Nagle算法的影响，实际上Nagle算法对于小的报文段来说就是一个停止等待协议。</p></li><li><p>Nagle算法为什么有效</p><p>因为要等到所有在传数据收到ACK才发小数据，那么ACK返回的越快，小数据包传输也就越快，如果是时延比较高的广域网中，ACK返回就会越慢，小数据被发送出去的速度也会变慢，这样小数据包就不会加重网络的阻塞。也就是说RTT可以控制发包速率。</p></li><li><p>如果延时ACK与Nagle算法结合会发生什么</p><p>延时ACK与Nagle算法直接结合使用效果会很差，延迟确认会使得接受方推迟发送ACK报文，而使用了Nagle算法的发送方又要等到接收到ACK报文才发送，<strong>导致网络处于空闲状态</strong>。</p></li><li><p>Nagle算法不适用于什么场景</p><p><strong>要求时延尽量小的应用不适合使用Nagle算法</strong>如网络游戏，远程控制等。</p></li></ul><h5 id="4-流量控制与窗口管理"><a href="#4-流量控制与窗口管理" class="headerlink" title="4. 流量控制与窗口管理"></a>4. 流量控制与窗口管理</h5><p>TCP使用滑动窗口来实现流量控制，”流量控制“控制的是发送方的发送速率，它与拥塞控制不同的是，流量控制考虑的是接收方的接受能力（如果接收方接受能力差，接收缓存满了，发送方发过来的数据包就会被丢弃然后重传，显然这是不必要的）</p><ul><li><p>滑动窗口的机制</p><p>发送方和接收方都会维护一个窗口，称为<strong>发送窗口</strong>和<strong>接收窗口</strong>，它们都是<strong>以字节为单位</strong>的。</p><ul><li><p>发送窗口</p><p>假设发送窗口向右移动，则发送窗口左边的数据是<strong>已经发送且确认</strong>了的可以从缓存区中清除，发送窗口右边的数据是<strong>还不能发送的</strong>，发送窗口内部维护了一个指针，指针的左边是<strong>已发送但还未确认</strong>的数据，指针右边是<strong>可发送但还未发送</strong>的数据。</p></li><li><p>接收窗口</p><p>接收窗口左边界的数据是<strong>已接受并确认</strong>的数据，右窗口是<strong>不能接收</strong>的数据，窗口内部是<strong>接受后还未确认</strong>的数据</p></li></ul></li><li><p>如何利用滑动窗口实现流量控制</p><p>TCP发送端向接收端使用滑动窗口机制发送数据，发送速率取决于发送方的发送窗口大小，所以为了实现流量控制，接收方会携带窗口大小信息来控制发送方发送窗口的大小，以达到发送端流量控制的目的。</p></li><li><p>零窗口问题</p><p>流量控制过程中的一种极端情况是，接收端告知发送端窗口为0，这样发送端就无法发送数据给接收端了，当接收端窗口大小恢复为非零值，会给发送端传输一个<strong>窗口更新报文</strong>告知其可以继续发送数据，但是如果发送方发送的一个包含窗口更新的ACK丢失了，通信双方就会一直处于等待状态。</p></li><li><p>TCP持续计时器</p><p><strong>持续计时器解决了零窗口问题</strong>，发送端会维护一个持续计时器间歇性的查询接收端，看其窗口是否已经增长。计时器会触发发送端发送一个<strong>窗口探测报文</strong>，接收端会回一个带有窗口信息的ACK报文。采用指数退避的方式来设置持续计时器的时间。</p></li><li><p>糊涂窗口综合症</p><p>糊涂窗口综合症是指当发送端应用进程产生数据很慢、或接收端应用进程处理接收缓冲区数据很慢，或二者兼而有之；就会使<strong>应用进程间传送的报文段很小，特别是有效载荷很小</strong>； 极端情况下，有效载荷可能只有1个字节；传输开销有40字节(20字节的IP头+20字节的TCP头) 这种现象。</p><p>发送方和接收方都可能会引发糊涂窗口综合征</p><ul><li><p>发送方</p><p>发送方产生的数据比较慢，每次产生的数据都很小。对于<strong>发送方不应该发送小的报文段，可以使用Nagle算法来控制何时发送</strong></p></li><li><p>接收方</p><p>接收方的原因是进程处理缓存中的数据不及时，然后通知了一个较小的窗口给发送方。对于<strong>接收方应该避免通告小的窗口值，可以使用延迟确认的方式等缓存中的数据被情空了再告知窗口值</strong>。</p></li></ul></li></ul><h5 id="5-紧急机制"><a href="#5-紧急机制" class="headerlink" title="5. 紧急机制"></a>5. 紧急机制</h5><p><strong>带外数据</strong></p><p>传输层协议使用带外数据（out-of-band，OOB）来发送一些重要的数据，如果通信一方有重要的数据需要通知对方时，协议能够将这些数据快速地发送到对方。为了发送这些数据，协议一般不使用与普通数据相同的通道，而是使用另外的通道。</p><p>TCP协议没有真正意义上的带外数据。为了发送重要协议，TCP提供了一种称为紧急模式（urgent mode）的机制。TCP协议在数据段中设置URG位，表示进入紧急模式。接收方可以对紧急模式采取特殊的处理。</p><p><strong>紧急模式</strong></p><p>TCP头部有一个位字段URG标志紧急数据，当URG位为1时，TCP头部节点的紧急指针位会记录一个偏移量，指向紧急数据的最后一位，在读取到紧急指针所指向的位置之前，TCP的接受进程都处于紧急状态，当读取到紧急数据后一位时，恢复到正常状态。</p><p>当URG置1时，发送方应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的最前面。</p><p>在紧急指针字段的具体实现上，由于过去的文档有错误或不太明确的地方，因而导致对有关RFC文档产生了不同的理解。</p><hr><p><em>参考：《TCP/IP详解 卷1：协议》Kevin R. Fall W.Richard Stevens</em></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
          <category> 传输层 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
            <tag> tcp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP协议总结</title>
      <link href="/2019/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AEHTTP/"/>
      <url>/2019/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AEHTTP/</url>
      
        <content type="html"><![CDATA[<p>通常计算机网络的知识中，每一层都会要求深入了解一个协议，而应用层协议是我们日常接触到的最多的协议，HTTP则是应用层协议中最常用的协议，所以一定一定要对HTTP协议有非常深刻的认识。除了要理解HTTP协议本身（这里通常指的是HTTP1.1），我们还要对不同版本的HTTP进行研究，如HTTP1.0/HTTP1.1/HTTP2.0,要了解每一个版本的协议的特点，解决了上一个版本的哪一个问题。</p><h5 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h5><ul><li><p>HTTP协议是什么（下一个定义）</p><p>HTTP被设计于20世纪90年代初期，是一种可扩展的协议。它是应用层的协议，通过TCP或者是TLS加密的TCP连接来发送，理论上任何可靠的传输协议都可以使用。因为其良好的扩展性，时至今日，它不仅被用来传输超文本文档，还用来传输图片、视频或者向服务器发送如HTML表单这样的信息。HTTP还可以根据网页需求，仅获取部分Web文档内容更新网页。</p></li><li><p>HTTP的组件有哪些</p><ul><li><p>客户端（用户代理）</p><p>就是任何能够为用户发起行为的工具，大多数时指的是浏览器，但是只要能够发起http请求的都成为用户代理，如程序员写的爬虫等</p></li><li><p>代理</p><p>在浏览器和服务器之间，有许多计算机和其他设备转发了HTTP消息。由于Web栈层次结构的原因，它们大多都出现在传输层、网络层和物理层上，对于HTTP应用层而言就是透明的，虽然它们可能会对应用层性能有重要影响。还有一部分是表现在应用层上的，被称为<strong>代理（Proxies）</strong>。代理（Proxies）既可以表现得透明，又可以不透明（“改变请求”会通过它们）。</p><p>常用的代理的作用：</p><ul><li>缓存</li><li>过滤</li><li>负载均衡</li><li>认证</li><li>日志记录</li></ul></li><li><p>服务端</p><p>提供客户端请求的文档或资源的运行在服务器上的程序</p></li></ul></li><li><p>HTTP的特点</p><ul><li><p>HTTP是简单的，HTTP1.1和HTTP1.0都是基于ASCII码的文本协议，非常易读</p></li><li><p>HTTP是可扩展的，通过添加headers,只要服务端和客户端就新 headers 达成语义一致，新功能就可以被轻松加入进来.</p></li><li><p>HTTP是<strong>无状态</strong>的（重点，什么是无状态）：在同一个连接中，两个执行成功的请求之间是没有关系的，服务器不能确定两个来自同一个连接的http请求是不是同一个用户</p></li><li><p>HTTP与连接</p><p>HTTP并不需要其底层的传输层协议是面向连接的，只需要它是可靠的，或不丢失消息的（这句话是说HTTP不要求底层协议面向连接），但是通常HTTP协议基于TCP协议（这里说的是通常还是基于面向连接的协议）</p><p>HTTP1.0 一次HTTP请求响应就要建立和释放一次TCP连接</p><p>HTTP1.1引入了流水线（很难实现）和持久连接（TCP连接在一个给定的时间内不会被释放）的机制。</p><p>HTTP2.0</p></li></ul></li><li><p>HTTP的工作过程</p><ol><li>打开一个TCP连接</li><li>发送一个HTTP报文（请求报文）</li><li>读取服务端返回的报文信息（响应报文）</li><li>关闭连接或者为后续请求重用连接</li></ol><p>其中第一步和最后一步是对底层传输层协议的控制，不同的HTTP版本是不一样的</p></li><li><p>HTTP报文的结构（问你对HTTP报文是否了解）</p><ul><li><p>请求报文</p><p><img src="C:%5CUsers%5Czeng%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200119104706044.png" alt="image-20200119104706044"></p></li><li><p>响应报文</p><p><img src="C:%5CUsers%5Czeng%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200119104631508.png" alt="image-20200119104631508"></p></li></ul></li></ul><hr><h5 id="2-HTTP缓存"><a href="#2-HTTP缓存" class="headerlink" title="2. HTTP缓存"></a>2. HTTP缓存</h5><ul><li><p>缓存的作用</p><p>缓解服务器端压力，提升性能(获取资源的耗时更短了)。对于网站来说，缓存是达到高性能的重要组成部分。</p></li><li><p>什么是web缓存</p><p>缓存是一种保存资源副本并在下次请求时直接使用该副本的技术。当 web 缓存发现请求的资源已经被存储，它会拦截请求，返回该资源的拷贝，而不会去源服务器重新下载</p></li><li><p>HTTP缓存的分类</p><ul><li><p>私有缓存</p><p>私有缓存只能用于单独用户，如用户浏览器中的缓存</p></li><li><p>共享缓存</p><p>共享缓存存储的响应能够被多个用户使用，如缓存代理服务器。</p></li></ul></li><li><p>缓存什么样的资源</p><p>​    HTTP缓存只能缓存GET方法请求的资源，其他方法响应的资源无能为力。</p></li><li><p>缓存如何控制</p><p>这个问题指的是怎么对资源进行缓存？</p><ul><li><p>Cache-Controller请求头</p><ul><li><p>禁止进行缓存</p><p>缓存中不得存储任何关于客户端请求和服务端响应的内容。每次由客户端发起的请求都会下载完整的响应内容。(就是说不使用缓存)</p><pre><code class="http">Cache-Control: no-store</code></pre></li><li><p>强制确认缓存</p><p>每次有请求发出时，缓存会将此请求发到服务器（译者注：该请求应该会带有与本地缓存相关的验证字段），服务器端会验证请求中所描述的缓存是否过期，若未过期（注：实际就是返回304），则缓存才使用本地缓存副本</p><pre><code class="http">Cache-Control: no-cache</code></pre></li><li><p>私有缓存和公共缓存</p><p>“public” 指令表示该响应可以被任何中间人（译者注：比如中间代理、CDN等）缓存。若指定了”public”，则一些通常不被中间人缓存的页面（译者注：因为默认是private）（比如 带有HTTP验证信息（帐号密码）的页面 或 某些特定状态码的页面），将会被其缓存。</p><p>而 “private” 则表示该响应是专用于某单个用户的，中间人不能缓存此响应，该响应只能应用于浏览器私有缓存中。（设置的是缓存类型）</p><pre><code class="http">Cache-Control: privateCache-Control: public</code></pre></li><li><p>缓存过期机制</p><p>max-age表示资源能够被缓存的最大时间，也就是说资源多久之后会过期。（设置缓存过期时间）</p><pre><code class="http">Cache-Control: max-age=31536000</code></pre></li></ul></li><li><p>Pragma头</p><p>Pragma 是HTTP/1.0标准中定义的一个header属性，请求中包含Pragma的效果跟在头信息中定义Cache-Control: no-cache相同，但是HTTP的响应头没有明确定义这个属性，所以它不能拿来完全替代HTTP/1.1中定义的Cache-control头。通常定义Pragma以向后兼容基于HTTP/1.0的客户端。（只用理解他是http1.0的东西，通常我们不用了解http1.0的具体细节）</p></li></ul></li><li><p>新鲜度</p><ul><li><p>缓存驱逐</p><p>理论上来讲，当一个资源被缓存存储后，该资源应该可以被永久存储在缓存中。由于缓存只有有限的空间用于存储资源副本，所以缓存会定期地将一些副本删除，这个过程叫做缓存驱逐。</p></li><li><p>什么是新鲜度</p><p>当服务器上面的资源进行了更新，那么缓存中的对应资源也应该被更新，由于HTTP是C/S模式的协议，服务器更新一个资源时，不可能直接通知客户端更新缓存，所以双方必须为该资源约定一个过期时间，在该过期时间之前，该资源（缓存副本）就是新鲜的。（简单的说就是这个资源还没过期就是新鲜的）</p></li><li><p>如何清除掉陈旧的资源</p><ul><li><p>驱逐算法用于将陈旧的资源（缓存副本）替换为新鲜的，注意，一个陈旧的资源（缓存副本）是不会直接被清除或忽略的，当客户端发起一个请求时，缓存检索到已有一个对应的陈旧资源（缓存副本），则缓存会先将此请求附加一个<code>If-None-Match</code>头，然后发给目标服务器，以此来检查该资源副本是否是依然还是算新鲜的，若服务器返回了 <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/304" target="_blank" rel="noopener"><code>304</code></a> (Not Modified)（该响应不会有带有实体信息），则表示此资源副本是新鲜的。</p></li><li><p>对于含有特定头信息的请求，会去计算缓存寿命。比如<code>Cache-control: max-age=N</code>的头，相应的缓存的寿命就是<code>N</code>。通常情况下，对于不含这个属性的请求则会去查看是否包含<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Expires" target="_blank" rel="noopener">Expires</a>属性，通过比较Expires的值和头里面<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Date" target="_blank" rel="noopener">Date</a>属性的值来判断是否缓存还有效。如果max-age和expires属性都没有，找找头里的<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Last-Modified" target="_blank" rel="noopener">Last-Modified</a>信息。如果有，缓存的寿命就等于头里面Date的值减去Last-Modified的值除以10</p></li></ul></li></ul></li><li><p>加速资源</p><p>更多地利用缓存资源，可以提高网站的性能和响应速度。为了优化缓存，过期时间设置得尽量长是一种很好的策略。对于定期或者频繁更新的资源，这么做是比较稳妥的，但是对于那些长期不更新的资源会有点问题。</p><ul><li><p>如何解决长期不更新资源的更新问题</p><p>不频繁更新的文件会使用特定的命名方式：在URL后面（通常是文件名后面）会加上版本号。加上版本号后的资源就被视作一个完全新的独立的资源，同时拥有一年甚至更长的缓存过期时长。</p></li><li><p>问题</p><p>需要手动的修改每一个引用该资源的地方</p></li></ul></li><li><p>缓存如何验证</p><ul><li><p>什么时候开始缓存验证</p><ul><li>用户点击刷新按钮</li><li>如果缓存的响应头信息里含有”Cache-control: must-revalidate”的定义，在浏览的过程中也会触发缓存验证</li><li>在浏览器偏好设置里设置Advanced-&gt;Cache为强制验证缓存也能达到相同的效果</li></ul></li><li><p>ETags</p><p>客户端请求一个页面（A）。 服务器返回页面A，并在给A加上一个ETag。 客户端展现该页面，并将页面连同ETag一起缓存。 客户再次请求页面A，并将上次请求时服务器返回的ETag一起传递给服务器。 服务器检查该ETag，并判断出该页面自上次客户端请求之后还未被修改，直接返回响应304（未修改——Not Modified）和一个空的响应体。（能区分相同URL不同的对象）</p></li></ul></li><li><p>带Vary头的响应</p><p>不同客户端对内容格式的支持程度不同（比如有些支持数据压缩，有些不支持），所以即便请求URL 和请求方法都相同，服务器返回的数据也会不同（称为内容协商）。Vary 字段记录了缓存服务器返回特定数据参考了哪些请求字段。缓存服务器拿到源服务器的响应报文，会根据 Vary 里的字段列表，缓存不同版本的数据。当客户端再次访问时，缓存服务器会分析请求字段，返回正确的版本。（这段话的意思是，相同的资源有不同的版本，如何正确返回）</p></li></ul><hr><h5 id="3-HTTP-Cookies"><a href="#3-HTTP-Cookies" class="headerlink" title="3. HTTP Cookies"></a>3. HTTP Cookies</h5><ul><li><p>Cookies是什么</p><p>HTTP Cookie（也叫Web Cookie或浏览器Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie使基于无状态的HTTP协议记录稳定的状态信息成为了可能。（简单的说Cookies是存在客户端的会话管理技术）</p></li><li><p>Cookies有什么用</p><ul><li>会话状态管理</li><li>个性化设置</li><li>浏览器行为跟踪</li></ul></li><li><p>如何设置Cookies</p><p>服务端通过如下请求头设置客户端的Cookues</p><pre><code class="http">Set-Cookie: &lt;cookie名&gt;=&lt;cookie值&gt;</code></pre></li><li><p>Cookies的有效时间</p><ul><li><p>会话期Cookies</p><p>会话期Cookie是最简单的Cookie：浏览器关闭之后它会被自动删除，不需要指定过期时间或者有效期。有些浏览器提供了会话恢复功能，这种情况下即使关闭了浏览器，会话期Cookie也会被保留下来，就好像浏览器从来没有关闭一样。（思考怎么办？）</p></li><li><p>持久性Cookies</p><p>和关闭浏览器便失效的会话期Cookie不同，持久性Cookie可以指定一个特定的过期时间（<code>Expires</code>）或有效期（<code>Max-Age</code>）</p><p>当Cookie的过期时间被设定时，设定的日期和时间只与客户端相关，而不是服务端。</p><pre><code class="http">Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;</code></pre></li></ul></li><li><p>Cookies的标记</p><ul><li><p>Secure</p><p>标记为 <code>Secure</code> 的Cookie只应通过被HTTPS协议加密过的请求发送给服务端（但是敏感信息不能放在Cookies中，有的浏览器会禁止Secure这个标记）</p></li><li><p>HttpOnly</p><p>如果包含服务端 Session 信息的 Cookie 不想被客户端 JavaScript 脚本调用，那么就应该为其设置 <code>HttpOnly</code> 标记（防止跨站脚本攻击XSS）</p></li></ul></li><li><p>Cookie的作用域</p><p><code>Domain</code> 和 <code>Path</code> 标识定义了Cookie的<em>作用域：</em>即Cookie应该发送给哪些URL。</p><ul><li><p>Domain</p><p><code>Domain</code> 标识指定了哪些主机可以接受Cookie。如果不指定，默认为当前文档的主机</p></li><li><p>Path</p><p><code>Path</code> 标识指定了主机下的哪些路径可以接受Cookie</p></li></ul></li><li><p>SameSite Cookie</p><p><code>SameSite</code> Cookie允许服务器要求某个cookie在跨站请求时不会被发送，从而可以阻止跨站请求伪造攻击（CSRF）</p><ul><li><p>None</p><p>浏览器会在同站请求、跨站请求下继续发送cookies，不区分大小写。</p></li><li><p>Strict</p><p>浏览器将只发送相同站点请求的cookie(即当前网页URL与请求目标URL完全一致)。如果请求来自与当前location的URL不同的URL，则不包括标记为Strict属性的cookie。</p></li><li><p>Lax</p><p>在新版本浏览器中，为默认选项，Same-site cookies 将会为一些跨站子请求保留，如图片加载或者frames的调用，但只有当用户从外部站点导航到URL时才会发送。如link链接</p></li></ul></li></ul><hr><h5 id="4-跨域问题"><a href="#4-跨域问题" class="headerlink" title="4. 跨域问题"></a>4. 跨域问题</h5><ul><li><p>同源策略</p><p>同源策略是浏览器的一个安全策略，所谓同源是指，域名，协议，端口相同。</p><p>同源策略是浏览器的行为，是为了保护本地数据不被JavaScript代码获取回来的数据污染，因此拦截的是客户端发出的请求回来的数据接收，即请求发送了，服务器响应了，但是无法被浏览器接收。</p></li><li><p>什么是跨域访问问题</p><p>为了用户浏览的安全，浏览器使用了同源策略，禁止浏览器在一个域中访问另一个域的资源，但是有的时候我们必须要访问不同域的问题，这样就造成了跨域问题。</p></li><li><p>如何解决跨域访问问题(之后重点讲)</p><ul><li>跨域资源共享（CORS）</li><li>jsonp</li><li>nginx反向代理</li></ul></li><li><p>CORS</p><p>跨域资源共享是一种机制，它使用额外的HTTP头来告诉浏览器 让运行在一个 origin上的Web应用被准许访问来自不同源服务器上的指定的资源。跨域资源共享机制<strong>允许 Web 应用服务器进行跨域访问控制</strong>，从而使跨域数据传输得以安全进行</p><ul><li>请求分为两种，不同种类的请求处理不同<ul><li>对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个<code>Origin</code>字段，<code>Origin</code>字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。服务器根据这个值，决定是否同意这次请求，如果<code>Origin</code>指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应。浏览器发现，这个回应的头信息没有包含<code>Access-Control-Allow-Origin</code>字段（详见下文），就知道出错了，从而抛出一个错误。</li><li>非简单请求是那种对服务器有特殊要求的请求，比如请求方法是<code>PUT</code>或<code>DELETE</code>，或者<code>Content-Type</code>字段的类型是<code>application/json</code>。非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求。一旦服务器通过了”预检”请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个<code>Origin</code>头信息字段。服务器的回应，也都会有一个<code>Access-Control-Allow-Origin</code>头信息字段</li></ul></li></ul></li><li><p>JSONP</p><ul><li>JSONP只支持<code>GET</code>请求，CORS支持所有类型的HTTP请求。JSONP的优势在于支持老式浏览器，以及可以向不支持CORS的网站请求数据。</li></ul></li></ul><hr><h5 id="5-HTTP协议的演变"><a href="#5-HTTP协议的演变" class="headerlink" title="5. HTTP协议的演变"></a>5. HTTP协议的演变</h5><p>这一节讲的是HTTP的发展史从HTTP0.9到HTTP1.0再到HTTP1.1再到HTTP2.0,需要了解每个版本协议的特点。</p><ul><li><p>HTTP0.9（单行协议，最早的版本，所以功能很少，不能以现在的眼光去看待这个协议）</p><p>HTTP/0.9 极其简单：请求由单行指令构成，以唯一可用方法GET开头，其后跟目标资源的路径.</p><pre><code class="http">GET /mypage.html</code></pre><p>响应也极其简单的：只包含响应文档本身。</p><pre><code class="html">&lt;HTML&gt;这是一个非常简单的HTML页面&lt;/HTML&gt;</code></pre></li><li><p>HTTP1.0（构建扩展性，这个时候的HTTP协议已经有了现代协议的雏形了，但是没有完成标准化）</p><ul><li>比上一代的优点<ul><li>协议版本信息现在会随着每个请求发送（<code>HTTP/1.0</code>被追加到了<code>GET</code>行）。</li><li>状态码会在响应开始时发送，使浏览器能了解请求执行成功或失败，并相应调整行为（如更新或使用本地缓存）。</li><li>引入了HTTP头的概念，无论是对于请求还是响应，允许传输元数据，使协议变得非常灵活，更具扩展性。</li><li>在新HTTP头的帮助下，具备了传输除纯文本HTML文件以外其他类型文档的能</li></ul></li></ul></li><li><p>HTTP1.1（标准化协议，20多年后的今天依然还有很多人使用）</p><ul><li>比上一代的优点<ul><li>连接可以复用，节省了多次打开TCP连接加载网页文档资源的时间。</li><li>增加流水线操作，允许在第一个应答被完全发送之前就发送第二个请求，以降低通信延迟。（难以实现）</li><li>支持响应分块。</li><li>引入额外的缓存控制机制。</li><li>引入内容协商机制，包括语言，编码，类型等，并允许客户端和服务器之间约定以最合适的内容进行交换。</li><li>使用Host，能够使不同域名配置在同一个IP地址的服务器上。</li></ul></li></ul></li><li><p>HTTP2.0</p><p>这些年来，网页愈渐变得的复杂，甚至演变成了独有的应用，可见媒体的播放量，增进交互的脚本大小也增加了许多：更多的数据通过HTTP请求被传输。HTTP/1.1链接需要请求以正确的顺序发送，理论上可以用一些并行的链接（尤其是5到8个），带来的成本和复杂性堪忧。比如，HTTP流水线就成为了Web开发的负担。（这是说虽然http1.1流水线解决了某些问题，但是引入了复杂性，解决的不够优雅，自然HTTP2.0会重新解决这个问题）</p><ul><li>特点<ul><li>HTTP/2是二进制协议而不是文本协议。不再可读，也不可无障碍的手动创建，改善的优化技术现在可被实施。（改变了协议的格式）</li><li>这是一个复用协议。并行的请求能在同一个链接中处理，移除了HTTP/1.x中顺序和阻塞的约束。（连接复用，并行的请求可以在同一个连接中完成）</li><li>压缩了headers。因为headers在一系列请求中常常是相似的，其移除了重复和传输重复数据的成本。（压缩了头部，将报文段的长度减少了）</li><li>其允许服务器在客户端缓存中填充数据，通过一个叫服务器推送的机制来提前请求。（引入服务端推送机制）</li></ul></li></ul></li><li><p>HTTPS</p><p>HTTP的版本解决的是HTTP协议的效率问题，每一代都有效率上的提升，但是没有解决安全问题，HTTPs就是来解决安全的。</p><p>HTTP协议遇到的安全问题</p><ul><li>篡改</li><li>监听</li><li>伪造</li></ul><p>简单的说HTTPS就是在HTTP协议之下TCP之上引入了TLS协议</p></li></ul><hr><h5 id="6-HTTP消息"><a href="#6-HTTP消息" class="headerlink" title="6. HTTP消息"></a>6. HTTP消息</h5><p>这一节讲的是HTTP报文的格式，这是学习任何一个协议都要注意的问题</p><ul><li><p>HTTP请求报文</p><ul><li><p>请求行</p><p>HTTP请求是由客户端发出的消息，用来使服务器执行动作。<em>起始行 (start-line)</em> 包含三个元素</p><ul><li>请求方法</li><li>请求目标（URL）</li><li>HTTP版本</li></ul></li><li><p>请求头</p><p>分为三种类型</p><ul><li>通用头部</li><li>请求头部</li><li>实体头部</li></ul></li><li><p>请求体</p><p>有些请求将数据发送到服务器以便更新数据：常见的的情况是 POST 请求（包含 HTML 表单数据）</p></li></ul></li><li><p>HTTP响应报文</p><ul><li><p>响应行</p><p>HTTP 响应的起始行被称作 <em>状态行</em> <em>(status line)</em>，包含以下信息：</p><ul><li>协议版本</li><li>状态码</li><li>状态文本信息</li></ul><pre><code class="http">HTTP/1.1 404 Not Found</code></pre></li><li><p>响应头</p></li><li><p>响应体</p><p>响应的最后一部分是 body。不是所有的响应都有 body：具有状态码 (如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/201" target="_blank" rel="noopener"><code>201</code></a> 或 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/204" target="_blank" rel="noopener"><code>204</code></a>) 的响应，通常不会有 body</p></li></ul></li><li><p>HTTP2帧格式</p><ul><li>HTTP/1.x 报文有一些性能上的缺点：<ul><li>Header 不像 body，它不会被压缩。</li><li>两个报文之间的 header 通常非常相似，但它们仍然在连接中重复传输。</li><li>无法复用。当在同一个服务器打开几个连接时：TCP 热连接比冷连接更加有效</li></ul></li><li>HTTP/2 引入了一个额外的步骤：它将 HTTP/1.x 消息分成帧并嵌入到流 (stream) 中。数据帧和报头帧分离，这将允许报头压缩。将多个流组合，这是一个被称为 <em>多路复用 (multiplexing)</em> 的过程，它允许更有效的底层 TCP 连接。</li><li>HTTP 帧现在对 Web 开发人员是透明的。在 HTTP/2 中，这是一个在  HTTP/1.1 和底层传输协议之间附加的步骤。Web 开发人员不需要在其使用的 API 中做任何更改来利用 HTTP 帧；当浏览器和服务器都可用时，HTTP/2 将被打开并使用。</li></ul></li></ul><hr><h5 id="6-经典的HTTP会话"><a href="#6-经典的HTTP会话" class="headerlink" title="6. 经典的HTTP会话"></a>6. 经典的HTTP会话</h5><ul><li>建立连接</li><li>发送客户端请求</li><li>服务器响应</li></ul><hr><h5 id="7-HTTP1-x的连接管理"><a href="#7-HTTP1-x的连接管理" class="headerlink" title="7.HTTP1.x的连接管理"></a>7.HTTP1.x的连接管理</h5><p>连接管理是一个 HTTP 的关键话题：打开和保持连接在很大程度上影响着网站和 Web 应用程序的性能。在 HTTP/1.x 里有多种模型：<em>短连接</em>, <em>长连接</em>, 和 <em>HTTP 流水线。</em></p><ul><li><p>短链接</p><p>HTTP 最早期的模型，也是  HTTP/1.0 的默认模型，是短连接。每一个 HTTP 请求都由它自己独立的连接完成；这意味着发起每一个 HTTP 请求之前都会有一次 TCP 握手，而且是连续不断的。</p><p>TCP 协议握手本身就是耗费时间的，所以 TCP 可以保持更多的热连接来适应负载。短连接破坏了 TCP 具备的能力，新的冷连接降低了其性能。</p><p>这是 HTTP/1.0 的默认模型(如果没有指定 Connection协议头，或者是值被设置为 <code>close</code>)。而在 HTTP/1.1 中，只有当Connection被设置为 <code>close</code> 时才会用到这个模型。</p></li><li><p>长连接</p><ul><li><p>短连接有两个比较大的问题：创建新连接耗费的时间尤为明显，另外 TCP 连接的性能只有在该连接被使用一段时间后(<strong>热连接</strong>)才能得到改善（这也是影响性能的一个因素不能忘记）。为了缓解这些问题，<em>长连接</em> 的概念便被设计出来了，甚至在 HTTP/1.1 之前。或者这被称之为一个 <em>keep-alive</em> 连接。</p></li><li><p>一个长连接会保持一段时间，重复用于发送一系列请求，节省了新建 TCP 连接握手的时间，还可以利用 TCP 的性能增强能力。当然这个连接也不会一直保留着：连接在空闲一段时间后会被关闭(服务器可以使用 Keep-Alive 协议头来指定一个最小的连接保持时间。（这里说明了HTTP长连接怎样提高效率的）</p></li><li><p>长连接也还是有缺点的；就算是在空闲状态，它还是会消耗服务器资源，而且在重负载时，还有可能遭受 DoS attacks攻击。这种场景下，可以使用非长连接，即尽快关闭那些空闲的连接，也能对性能有所提升。（这段话说明长连接潜在的问题）</p></li><li><p>在 HTTP/1.1 里，默认就是长连接的，协议头都不用再去声明它。</p></li></ul></li></ul><ul><li><p>HTTP流水线</p><ul><li>默认情况下，HTTP请求是按顺序发出的。下一个请求只有在当前请求收到应答过后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。</li><li>流水线是在同一条长连接上发出连续的请求，而不用等待应答返回。这样可以避免连接延迟</li><li>目前没有现代浏览器默认启用这个特性，流水线很复杂，难以实现</li></ul></li><li><p>域名分片</p><ul><li>这是一种过时技术，如果用这个机制不如升级到HTTP2.0</li><li>这种机制的理论是：浏览器为每个域名的连接都是有限的，如果要加快访问速度，可以想到的就是为每个域名增加连接数量，但是这无法实现（无法改变浏览器的行为），一种妥协的方法是，将同一个域名的资源拆分到不同的域中，这样连接数量就可以提高，从而提高性能，但是这种解决方法不够优雅。</li><li>例子：如果服务器端想要更快速的响应网站或应用程序的应答，它可以迫使客户端建立更多的连接。例如，不要在同一个域名下获取所有资源，假设有个域名是 <code>www.example.com</code>，我们可以把它拆分成好几个域名：<code>www1.example.com</code>、<code>www2.example.com</code>、<code>www3.example.com</code>。所有这些域名都指向同一台服务器，浏览器会同时为每个域名建立 6 条连接(在我们这个例子中，连接数会达到 18 条)。这一技术被称作域名分片。</li></ul></li></ul><hr><h5 id="8-HTTP首部"><a href="#8-HTTP首部" class="headerlink" title="8. HTTP首部"></a>8. HTTP首部</h5><ul><li>太多了所以不用记住，只要熟悉常用的就要可以，或者是为了实现某种机制需要的请求头，如设置cookie，缓存控制。</li><li><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers" target="_blank" rel="noopener">HTTP首部</a></li></ul><h5 id="8-HTTP请求方法"><a href="#8-HTTP请求方法" class="headerlink" title="8. HTTP请求方法"></a>8. HTTP请求方法</h5><p>差不多是面试中问道HTTP必问的问题，需要属性每种方法并且知道他们的区别，还有restful风格api的对应关系，以及每种方法的幂等性，什么是幂等性等问题（京东一面又问到）</p><ul><li>GET</li><li>POST</li><li>PUT</li><li>PETCH</li><li>HEAD</li><li>DELETE</li><li>CONNECT</li><li>OPTIONS</li><li>TRACE</li></ul><h5 id="9-HTTP状态码"><a href="#9-HTTP状态码" class="headerlink" title="9. HTTP状态码"></a>9. HTTP状态码</h5><ul><li><p>HTTP 响应状态代码指示特定 HTTP请求是否已成功完成。响应分为五类：信息响应(<code>100</code>–<code>199</code>)，成功响应(<code>200</code>–<code>299</code>)，重定向(<code>300</code>–<code>399</code>)，客户端错误(<code>400</code>–<code>499</code>)和服务器错误 (<code>500</code>–<code>599</code>)。</p></li><li><p>记住常用的几个状态码，以及某些状态码的区别如同样是重定向301和304的区别</p></li><li><p>301与304的相同点和不同点</p><p>301和304都表示地址重定向，也就是当访问一个url会被指向另一个url，但是301重定向是永久的移动，304是临时重定向。</p></li></ul><hr><p>参考：</p><ul><li><p><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP" target="_blank" rel="noopener">HTTP协议文档</a></p></li><li><p><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status" target="_blank" rel="noopener">HTTP状态码</a></p></li><li><p><a href="https://juejin.im/post/5a276865f265da432c23b8d2#heading-21" target="_blank" rel="noopener">掘金文章参考文章</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
          <category> 应用层 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
            <tag> HTTP协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>三大查找算法</title>
      <link href="/2019/12/21/%E4%B8%89%E5%A4%A7%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/"/>
      <url>/2019/12/21/%E4%B8%89%E5%A4%A7%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h5 id="1-二分查找"><a href="#1-二分查找" class="headerlink" title="1. 二分查找"></a>1. 二分查找</h5><ul><li><p>算法思路</p><p>已知数组是有序的，假设是升序的，取中间位置的数字与目标数字进行比较，如果相等那么就找到了，如果中间位置大，目标数字就在右边，下一步只用在数组左半部分查找，假如中间的数字小，则目标数字一个在数组的右边，下一步只用在数组右半部查找。</p></li><li><p>时间复杂度</p><p>O(logn)</p></li><li><p>代码</p><pre><code class="java">public class BinarySearch {    public static void main(String[] args) {        int[] arr={1,2,3,4,5,6,7,8,9};        int search = search(arr, 4);        System.out.println(search);    }    private static int search(int[] arr,int target){        int start=0;        int end=arr.length-1;        while (start&lt;=end){            int mid=start+(end-start)/2;            if (arr[mid]==target){                return mid;            }else if (arr[mid]&gt;target){                end=mid-1;            }else {                start=mid+1;            }        }        return -1;    }}</code></pre></li><li><p>扩展</p><p>如果要求找到与某个数字最接近的数字也可以通过二分查找找到。</p></li></ul><h5 id="2-分块查找"><a href="#2-分块查找" class="headerlink" title="2. 分块查找"></a>2. 分块查找</h5><p>也称索引顺序查找</p><h5 id="3-哈希查找"><a href="#3-哈希查找" class="headerlink" title="3. 哈希查找"></a>3. 哈希查找</h5><ul><li><p>算法思想</p><p>哈希查找是通过计算数据元素的存储地址进行查找的一种方法。在插入元素的时候通过hash函数根据键的值计算出插入的下标位置，元素存放在该下标位置的数组中，如果冲突了可以采用拉链法或者开放地址法解决，查找的时候只需根据键计算出插入位置，然后就能查找到元素。</p></li><li><p>时间复杂度</p><p>O(1)</p></li><li><p>代码</p><p>哈希查找算法的实现在于哈希类的实现，哈希的实现有两个关键：一是hash函数如何选择？而是哈希冲突如何解决？这两个问题很可能会问道，建议百度了解，已经可能会提到优化，比如说java1.8的优化。</p><pre><code class="java">public class HashSearch {    public static void main(String[] args) {        Hash hash=new Hash();        hash.put(1,1);        hash.put(2,2);        hash.put(3,3);        System.out.println(hash.get(1));    }}/** * 实现一个简单的哈希类,采用拉链法解决hash冲突 */class Hash{    private Node[] tables=new Node[10];    public void put(int key,int value){        Node last = getNode(key);        if (last!=null){            last.value=value;            return;        }        int index = hash(key);        if (tables[index]==null){            tables[index]=new Node(key,value);        }else{            Node node = new Node(key, value);            node.next=tables[index];            tables[index]=node;        }    }    private Node getNode(int key){        int index = hash(key);        if (tables[index]==null){            return null;        }        Node p=tables[index];        while (p!=null){            if (p.key==key){                return p;            }            p=p.next;        }        return null;    }    public Integer get(int key){        Node node = getNode(key);        if (node==null){            return null;        }        return node.value;    }</code></pre></li></ul><pre><code>  private int hash(int key){      return key%10;  }  private static class Node{      int key;      int value;      Node next;      public Node(int key, int value) {          this.key = key;          this.value = value;      }  }</code></pre><p>  }</p><pre><code></code></pre>]]></content>
      
      
      <categories>
          
          <category> 经典算法 </category>
          
          <category> 查找 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 查找 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>十大排序算法分析</title>
      <link href="/2019/12/20/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/"/>
      <url>/2019/12/20/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>排序算法是面试中常问的算法，大厂中排序算法问的深度很深，对排序算法的理解有多个层次</p><ul><li>知道常用算法的写法，了解各种算法的时间复杂度，空间复杂度和稳定性</li><li>了解每种算法的性能瓶颈</li><li>对于每种算法知道如何优化</li><li>知道每种算法的应用场景</li></ul><h5 id="1-选择排序"><a href="#1-选择排序" class="headerlink" title="1. 选择排序"></a>1. 选择排序</h5><ul><li><p>算法思想</p><p>将一组数据分为两部分，前面是已排序部分，后面是未排序部分，初始状态可认为位置 0 为已排序部分 (数组下标从0开始)，其余为未排序部分，每一次都从未排序部分选择一个最小元素放在已排序部分的末尾，然后已排序部分增加一个元素，未排序部分减少一个元素，直到数据全部有序。</p></li><li><p>时间复杂度</p><p>选择排序无论数据初始是何种状态，均需要在未排序元素中选择最小或最大元素与未排序序列中的首尾元素交换，因此它的最好、最坏、平均时间复杂度均为 O(n^2)。</p></li><li><p>空间复杂度</p><p>空间复杂度为O(1)</p></li><li><p>稳定性</p><p>直接选择排序是不稳定的。因为每次遍历比较完后会使用本次遍历选择的最小元素和无序区的第一个元素交换位置，所以如果无序区第一个元素后面有相同元素的，则可能会改变相同元素的相对顺序（<strong>稳定性：能保证两个相等的数,经过排序之后,其在序列的前后位置顺序不变</strong>）</p></li><li><p>优化思路</p><ol><li>每次查找时不仅找出最小值，还找出最大值，分别插到前面和后面，可以减少一半的查询时间。</li><li>如果数组元素重复率高，可以考虑使用辅助空间在每一次循环的时候，将本次选择的数及相同元素的索引记录下来，一起处理。</li></ol></li><li><p>代码</p><pre><code class="java">public class SelectionSort {    public static void main(String[] args) {        int[] arr={1,4,3,2,3,2,1,2,6};        sort(arr);        for (int i : arr) {            System.out.print(i+&quot; &quot;);        }    }    public static void sort(int[] arr){        for (int i=0;i&lt;arr.length-1;i++){            int minPos=i;            for (int j = minPos+1; j &lt; arr.length; j++) {                if (arr[j]&lt;arr[minPos]){                    minPos=j;                }            }            swap(arr,i,minPos);        }    }    private static void swap(int[] arr,int i,int j){        int temp=arr[i];        arr[i]=arr[j];        arr[j]=temp;    }}</code></pre></li></ul><h5 id="2-冒泡排序"><a href="#2-冒泡排序" class="headerlink" title="2.  冒泡排序"></a>2.  冒泡排序</h5><ul><li><p>算法思想</p><p>通过比较相邻的两个元素，将大的元素或者小的元素交换到后面，这样越大或者越小的元素都会交换到数组的后端。</p></li><li><p>时间复杂度</p><p>时间复杂度是O(n^2)</p></li><li><p>空间复杂度</p><p>空间复杂度为O(1)</p></li><li><p>稳定性</p><p>稳定</p></li><li><p>优化思路</p><ul><li>用一个计数器记录交换的次数，当某一轮交换次数为0则表示数组已经有序，那么就不用继续进行了。</li><li>记录最后一次交换的位置，该位置之后没有进行交换说明是有序的了，下一轮只用遍历该位置即可。</li></ul></li><li><p>代码</p><pre><code class="java">public class BubbleSort {    public static void main(String[] args) {        int[] arr={1,4,23,2,1,1,23,2,1,8};        sort(arr);        for (int i=0;i&lt;arr.length;i++){            System.out.print(arr[i]+&quot; &quot;);        }    }    public static void sort(int[] arr){        for (int i=0;i&lt;arr.length-1;i++){            for (int j=0;j&lt;arr.length-i-1;j++){                if (arr[j]&gt;arr[j+1]){                    swap(arr,j,j+1);                }            }        }    }    private static void swap(int[] arr,int i,int j){        int temp=arr[i];        arr[i]=arr[j];        arr[j]=temp;    }}</code></pre></li></ul><h5 id="3-直接-插入排序"><a href="#3-直接-插入排序" class="headerlink" title="3. (直接)插入排序"></a>3. (直接)插入排序</h5><ul><li><p>算法思想</p><p>每趟将一个元素，按照其关键字的大小插入到它前面已经排序的子序列中，依此重复，直到插入全部元素。</p></li><li><p>时间复杂度</p><p>时间复杂度为O(n^2)</p></li><li><p>空间复杂度</p><p>空间复杂度为O(1)</p></li><li><p>稳定性</p><p>稳定</p></li><li><p>优化思路</p><ul><li>希尔排序</li><li>二分查找插入排序<ul><li>二分查找插入排序的原理：是直接插入排序的一个变种，区别是：在有序区中查找新元素插入位置时，为了减少元素比较次数提高效率，采用二分查找算法进行插入位置的确定。</li></ul></li></ul></li><li><p>代码</p><pre><code class="java">public class InsertionSort {    public static void main(String[] args) {        int[] arr={1,5,4,3,2,6,7,8,9};        sort(arr);        for (int i : arr) {            System.out.print(i+&quot; &quot;);        }    }    public static void sort(int[] arr){        for (int i=0;i&lt;arr.length;i++){            int temp=arr[i];            int j=i-1;            for (;j&gt;=0&amp;&amp;arr[j]&gt;temp;j--){                arr[j+1]=arr[j];            }            arr[j+1]=temp;        }    }}</code></pre></li></ul><h5 id="4-希尔排序"><a href="#4-希尔排序" class="headerlink" title="4. 希尔排序"></a>4. 希尔排序</h5><ul><li><p>算法思路</p><p>希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。</p></li><li><p>时间复杂度</p><p>​    时间复杂度取决于增量序列的选择O(n^1.3)</p></li><li><p>空间复杂度</p></li><li><p>稳定性</p><p>不稳定</p></li><li><p>代码</p><pre><code class="java">public class ShellSort {    public static void main(String[] args) {        int[] arr={1,3,2,4,6,5,7,9,8,0};        sort(arr);        for (int i : arr) {            System.out.print(i+&quot; &quot;);        }    }    public static void sort(int [] arr){        // 增量序列        int[] ds={1,3,7};        for (int i=ds.length-1;i&gt;=0;i--){            insertSort(arr,1);        }    }    /**     * 按增量分组进行直接插入排序     * @param arr 数组     * @param d 增量     */    private static void insertSort(int[] arr,int d){        for (int i=0;i&lt;d;i++){            for (int j=i;j&lt;arr.length;j+=d){                int k=j-d;                int temp=arr[j];                for (;k&gt;=i&amp;&amp;arr[k]&gt;temp;k-=d){                    arr[k+d]=arr[k];                }                arr[k+d]=temp;            }        }    }}</code></pre></li></ul><h5 id="5-堆排序"><a href="#5-堆排序" class="headerlink" title="5. 堆排序"></a>5. 堆排序</h5><ul><li><p>算法思路</p><p>堆是这样一种数据结构，首先堆是一个完全二叉树，其父节点一定大于其所有的子节点。堆排序就是利用堆这种数据结构进行排序，首先构造一个堆，堆顶元素就是最大或最小的元素，把他与堆的最后一个元素交换，这样堆顶元素就调整到了排序后的顺序，而堆的元素个数减少了一个且结构发生了变化，只需要重新调整堆就可以了。循环这个步骤数组就变成有序的了。</p></li><li><p>时间复杂度</p><p>nlogn -&gt; n表示第几轮 logn为调整堆的时间复杂度</p></li><li><p>空间复杂度</p><p>O(1)</p></li><li><p>稳定性</p><p>不稳定</p></li><li><p>代码</p><pre><code class="java">public class HeapSort {    public static void main(String[] args) {        int[] arr={1,4,3,2,5,7,6,8,9,0};        sort(arr);        for (int i : arr) {            System.out.print(i+&quot; &quot;);        }    }    public static void sort(int[] arr){        // 首先要对整个数组进行heapify操作        for (int i=arr.length/2;i&gt;=0;i--){            heapify(arr,arr.length,i);        }        for (int i=1;i&lt;=arr.length;i++){            swap(arr,0,arr.length-i);            heapify(arr,arr.length-i,0);        }    }    private static void swap(int[] arr,int i,int j){        int temp=arr[i];        arr[i]=arr[j];        arr[j]=temp;    }    private static void heapify(int[] arr,int len,int i){        int left=i*2+1;        int right=i*2+2;        int max=i;        if (left&lt;len&amp;&amp;arr[left]&gt;arr[max]){            max=left;        }        if (right&lt;len&amp;&amp;arr[right]&gt;arr[max]){            max=right;        }        if (max!=i){            swap(arr,i,max);            heapify(arr,len,max);        }    }}</code></pre></li></ul><h5 id="6-归并排序"><a href="#6-归并排序" class="headerlink" title="6. 归并排序"></a>6. 归并排序</h5><ul><li><p>算法思路</p><p>基于二路归并算法，将数组分成两个部分，对每一部分递归采取归并排序，这样数组两个部分就排好序了，对于两个已排好序的数组，只需要进行二路归并就可以得到一个有序的数组。</p></li><li><p>时间复杂度</p><p>O(nlogn)</p></li><li><p>空间复杂度</p><p>O(n)</p></li><li><p>稳定性</p><p>稳定</p></li><li><p>优化思路</p><ul><li><p>原地归并</p><p>因为用归并将一个大数组排序时，需要进行多次归并，而且每次归并会都创建一个新数组来存储排序结果会带来问题。由于原地归并排序不需要额外的空间，所以空间复杂度为O(1)。</p></li><li><p>当递归到规模足够小时，利用插入排序 </p></li></ul></li><li><p>代码</p><pre><code class="java">public class MergeSort {    private static int[] tempArr;    public static void main(String[] args) {        int[] arr={1,2,5,4,3,6,9,7,8,0};        sort(arr);        for (int i : arr) {            System.out.print(i+&quot; &quot;);        }    }    public static void sort(int[] arr){        tempArr=new int[arr.length];        sort(arr,0,arr.length-1);    }    private static void sort(int[] arr,int start,int end){        if (start==end){            return;        }        int mid=start+(end-start)/2;        sort(arr,start,mid);        sort(arr,mid+1,end);        merge(arr,start,mid,end);    }    private static void merge(int[] arr,int start,int mid,int end){        System.arraycopy(arr,0,tempArr,0,arr.length);        int i=start;        int j=mid+1;        int k=start;        while (i&lt;=mid&amp;&amp;j&lt;=end){            if (tempArr[i]&lt;tempArr[j]){                arr[k++]=tempArr[i++];            }else{                arr[k++]=tempArr[j++];            }        }        while (i&lt;=mid){            arr[k++]=tempArr[i++];        }        while (j&lt;=end){            arr[k++]=tempArr[j++];        }    }}</code></pre></li></ul><h5 id="7-快速排序"><a href="#7-快速排序" class="headerlink" title="7. 快速排序"></a>7. 快速排序</h5><ul><li><p>算法思路</p><p>快速排序使用分治法策略来把一个序列分为较小和较大的2个子序列，然后递归地排序两个子序列。具体步骤是选择一个元素作为基准元素，将比它小的元素放置在它的左边，将比它大的元素排它的后面，这样基准元素的位置就确定了，然后分别对基准元素左边和右边的序列进行相同操作，每次都能将一个元素排放到正确的位置。</p></li><li><p>时间复杂度</p><p>O(nlogn) 递归的过程O(n) partition过程O(n)-&gt;O(nlogn)</p></li><li><p>空间复杂度</p><p>空间复杂度为logn</p></li><li><p>优化思路</p></li><li><p>代码</p><pre><code class="java">public class QuickSort {    public static void main(String[] args) {        int[] arr={1,4,2,3,6,5,7,9,8,0};        sort(arr);        for (int i : arr) {            System.out.print(i+&quot; &quot;);        }    }    public static void sort(int[] arr){        quickSort(arr,0,arr.length-1);    }    private static void quickSort(int[] arr,int start,int end){        if (start&gt;=end){            return;        }        int pos=partition(arr,start,end);        quickSort(arr,start,pos-1);        quickSort(arr,pos+1,end);    }    private static int partition(int[] arr,int start,int end){       int left=start-1;       int k=start;       while (k&lt;=end){           if(arr[k]&gt;arr[start]){               k++;           }else{               swap(arr,++left,k++);           }       }       swap(arr,start,left);       return left;    }    private static void swap(int[] arr,int i,int j){        int temp=arr[i];        arr[i]=arr[j];        arr[j]=temp;    }}</code></pre></li></ul><h5 id="8-桶排序"><a href="#8-桶排序" class="headerlink" title="8. 桶排序"></a>8. 桶排序</h5><ul><li><p>算法思路</p><p>这是一种算法思想，基于非比较的排序算法，时间复杂度比较低但是一般需要额外的空间，将数组中的元素分配到不同的桶，桶与桶之间是有顺序的，桶的内部元素无序，对每个不为空的桶进行排序（可以使用别的排序算法），然后将不为空的桶中的元素进行输出就可以完成排序。</p></li><li><p>代码</p><pre><code class="java">public class BucketSort {    public static void main(String[] args) {        int[] arr={1,3,2,5,4,6,9,8,7,0};        sort(arr);        for (int i : arr) {            System.out.printf(i+&quot; &quot;);        }    }    public static void sort(int[] arr){        int max=arr[0];        int min=arr[0];        for (int value : arr) {            min = Math.min(value, min);            max = Math.max(value, max);        }        ArrayList&lt;Integer&gt;[] buckets=new ArrayList[max/10-min/10+1];        for (int i=0;i&lt;buckets.length;i++){            buckets[i]=new ArrayList&lt;Integer&gt;();        }        for (int value : arr) {            buckets[(value-min)/10].add(value);        }        for (int i=0;i&lt;buckets.length;i++){            if (buckets[i].size()!=0){                Collections.sort(buckets[i]);            }        }        int k=0;        for (int i=0;i&lt;buckets.length;i++){            if (buckets[i].size()!=0){                for (int j=0;j&lt;buckets[i].size();j++){                    arr[k++]=buckets[i].get(j);                }            }        }    }}</code></pre></li></ul><h5 id="9-基数排序"><a href="#9-基数排序" class="headerlink" title="9. 基数排序"></a>9. 基数排序</h5><ul><li><p>算法思想</p><p>基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。是桶排序思想的一种。是一种多关键字排序。</p></li><li><p>代码</p><pre><code class="java">public class RadixSort {    public static void main(String[] args) {        int[] arr={123,43,231,24,56,432,124};        sort(arr);        for (int i : arr) {            System.out.print(i+&quot; &quot;);        }    }    public static void sort(int[] arr){        int[] result=new int[arr.length];        int[] count=new int[10];        int maxLen=maxLen(arr);        // 分别对十位，个位，百位......进行排序        for (int i=0;i&lt;=maxLen;i++){            int temp= (int) Math.pow(10,i);            for (int value : arr) {                count[value / temp % 10]++;            }            for (int j=1;j&lt;count.length;j++){                count[j]+=count[j-1];            }            for (int j=arr.length-1;j&gt;=0;j--){                result[--count[arr[j]/temp%10]]=arr[j];            }            System.arraycopy(result,0,arr,0,arr.length);            Arrays.fill(count,0);        }    }    private static int maxLen(int[] arr){        int max=arr[0];        for (int i : arr) {            max=Math.max(i,max);        }        int len=0;        while (max!=0){            max/=10;            len++;        }        return len;    }}</code></pre></li></ul><h5 id="10-计数排序"><a href="#10-计数排序" class="headerlink" title="10. 计数排序"></a>10. 计数排序</h5><ul><li><p>算法思路</p><p>准备一个桶，桶的长度为n，且待排序数组的范围都在0到n-1之间，这样数组中的数i就可以放入桶的第i项，桶只要记住每个数字出现的次数，然后扫描桶就可以得到排序后的序列，适合数组范围不大的元素。</p></li><li><p>代码</p><pre><code class="java">public class CountSort {    public static void main(String[] args) {        int[] arr={1,3,2,4,5,6,8,7,9,0};        sort(arr);        for (int i : arr) {            System.out.print(i+&quot; &quot;);        }    }    private static void sort(int[] arr){        int[] count=new int[10];// 计数数组，数组的数的范围落在0-count.length-1        for (int value : arr) {            count[value]++;        }        int k=0;        for (int i=0;i&lt;count.length;i++){            while (count[i]&gt;0){                count[i]--;                arr[k++]=i;            }        }    }}</code></pre></li></ul><h5 id="11-常用排序一览表"><a href="#11-常用排序一览表" class="headerlink" title="11. 常用排序一览表"></a>11. 常用排序一览表</h5><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/image-20200111095013095.png" alt=""></p><h5 id="12-常见面试问题总结"><a href="#12-常见面试问题总结" class="headerlink" title="12. 常见面试问题总结"></a>12. 常见面试问题总结</h5><ul><li>告诉你某种算法，比如很明确的问你某种算法然后不断追问，如快速排序（字节跳动一面）<ol><li>说一下快速排序的思想（先考你知不知道思想）</li><li>快速排序的时间复杂度/空间复杂度/稳定(考一下你会不会分析算法或者说这个算法是不是你背下来的实际上你并不知道或不理解)</li><li>快速排序不适合什么样的数据（考你某种算法的缺点，进一步看你理不理解这个算法）</li><li>如果要排上面的算法，怎么优化（基于某个问题，要求你进行优化，这类问题最深应该就问到这一步了，后面也问不下去了）</li></ol></li><li>不明确告诉你某种算法，问你排某一类特征的数据应该用什么算法排序(字节跳动一面)<ul><li>这类问题难在要逆向思考，你得对所有算法都得足够的熟悉</li><li>问题：排一组比较有序的数组用什么算法，为什么可以用这种算法</li></ul></li></ul><h5 id="13-一些其他排序算法"><a href="#13-一些其他排序算法" class="headerlink" title="13.一些其他排序算法"></a>13.一些其他排序算法</h5><ul><li>置换选择排序</li><li>枚举排序</li></ul><h5 id="14-总结"><a href="#14-总结" class="headerlink" title="14. 总结"></a>14. 总结</h5><ul><li>一共有四种不稳定的排序算法，选择排序，堆排序，希尔排序，快速排序，其他的都是稳定的排序。</li><li>数据的特征大概有：数据基本有序，数据范围不大，数据逆序</li><li>分析数据的时间复杂度必须知道他的循环嵌套关系，以及每层循环的时间复杂度，优化也是这么思考的，看每一层循环这么优化</li><li>空间复杂度比较好分析，但是注意递归的情况，比如快速排序的空间时间复杂度不是O(1)而是logn(上面的表示错误的)</li><li>要理解算法的稳定性有什么影响，不稳定为什么不好？</li></ul>]]></content>
      
      
      <categories>
          
          <category> 经典算法 </category>
          
          <category> 排序 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 排序 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java虚拟机问题总结</title>
      <link href="/2019/12/19/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
      <url>/2019/12/19/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h3 id="java虚拟机问题总结"><a href="#java虚拟机问题总结" class="headerlink" title="java虚拟机问题总结"></a>java虚拟机问题总结</h3><h4 id="一-自动内存管理机制"><a href="#一-自动内存管理机制" class="headerlink" title="一. 自动内存管理机制"></a>一. 自动内存管理机制</h4><h5 id="1-java虚拟机运行时数据区有哪些，各自的功能"><a href="#1-java虚拟机运行时数据区有哪些，各自的功能" class="headerlink" title="1. java虚拟机运行时数据区有哪些，各自的功能"></a>1. java虚拟机运行时数据区有哪些，各自的功能</h5><ul><li><p>程序计数器</p><p>程序计数器是一块较小的内存空间，它可以看作是当前线程所执行的字节码的<strong>行号指示器</strong>。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。</p></li><li><p>java堆</p><p>此内存区域的唯一目的就是<strong>存放对象实例</strong>，几乎所有的对象实例都在这里分配内存，由于栈上分配、标量替换技术的存在，<strong>对象不一定都在堆中分配</strong>。</p></li><li><p>方法区</p><p>用于存储已被虚拟机加载的<strong>类信息、常量、静态变量、即时编译器编译后的代码</strong>等数据。</p></li><li><p>虚拟机栈</p><p>每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个<strong>方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程</strong>。</p></li><li><p>本地方法栈</p><p>本地方法栈与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法服务，而本地方法栈则为虚拟机使用到的Native方法服务。</p><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/image-20200128195246.png" alt=""></p></li></ul><h5 id="2-永久代和元空间的概念"><a href="#2-永久代和元空间的概念" class="headerlink" title="2. 永久代和元空间的概念"></a>2. 永久代和元空间的概念</h5><p>在JDK1.8之前方法区被称为“永久代”，原因是当时将方法区划分出一块永久代来实现方法区，这样垃圾收集器就可以像管理java堆来管理方法区，而到了jdk1.8，则是使用本地空间实现的元空间来代替永久代。</p><h5 id="3-什么是运行时常量池，存放什么"><a href="#3-什么是运行时常量池，存放什么" class="headerlink" title="3. 什么是运行时常量池，存放什么"></a>3. 什么是运行时常量池，存放什么</h5><p>运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的<strong>各种字面量</strong>和<strong>符号引用</strong>，这部分内容将在类加载后进入方法区的运行时常量池中存放。</p><h5 id="4-什么是直接内存，有什么用"><a href="#4-什么是直接内存，有什么用" class="headerlink" title="4.什么是直接内存，有什么用"></a>4.什么是直接内存，有什么用</h5><p>直接内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。</p><p>在JDK 1.4中新加入了NIO类，引入了一种基于通道与缓冲区的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。</p><p>本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存限制。</p><h5 id="5-对象是如何创建的"><a href="#5-对象是如何创建的" class="headerlink" title="5. 对象是如何创建的"></a>5. 对象是如何创建的</h5><ul><li><p>虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。</p></li><li><p>在类加载检查通过后，接下来虚拟机将为新生对象分配内存</p></li><li><p>内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值</p></li><li><p>接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头之中。根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。</p></li><li><p>执行new指令之后会接着执行＜init＞方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。</p></li></ul><h5 id="6-对象在内存中是怎样分配的"><a href="#6-对象在内存中是怎样分配的" class="headerlink" title="6.对象在内存中是怎样分配的"></a>6.对象在内存中是怎样分配的</h5><p>一个对象在内存中由三部分组成：<strong>对象头</strong>，<strong>实例数据</strong>，<strong>对齐填充</strong>。</p><ul><li><p>HotSpot虚拟机的对象头包括两部分信息组成，第一部分用于存储对象自身的运行时数据，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，官方称它为“Mark Word”。对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据。</p></li><li><p>实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。</p></li><li><p>对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或者2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。</p></li></ul><h5 id="7-对象分配的方式"><a href="#7-对象分配的方式" class="headerlink" title="7. 对象分配的方式"></a>7. 对象分配的方式</h5><ul><li><p>指针碰撞（非线程安全）</p><p>假设Java堆中内存是绝对规整的，所有被使用过的内存都被放在一边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间方向挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”。</p></li><li><p>CAS同步处理（线程安全）</p><p>对分配内存空间的动作进行同步处理，虚拟机采用CAS配上失败重试的方式保证更新操作的原子性。</p></li><li><p>TALB（线程安全）</p><p>把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local AllocationBuffer，TLAB），哪个线程要分配内存，就在哪个线程的本地缓冲区中分配，只有本地缓冲区用完了，分配新的缓存区时才需要同步锁定。</p></li></ul><h5 id="8-如何定位到一个对象，这些方法有什么优点和缺点"><a href="#8-如何定位到一个对象，这些方法有什么优点和缺点" class="headerlink" title="8. 如何定位到一个对象，这些方法有什么优点和缺点"></a>8. 如何定位到一个对象，这些方法有什么优点和缺点</h5><p>有两种方式，一种是<strong>直接指针访问</strong>，一种是<strong>对象句柄访问</strong>。如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，对象引用中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。直接指针访问，对象引用存放了对象的真实地址。直接指针引用的优点是定位快，但是缺点是，当对象移动时需要修改对象引用的内容，句柄访问的缺点是需要两次定位才能找到对象，但是优点是对象移动，不需要改变对象引用的内容。<strong>使用句柄访问的方式更加常见</strong>。</p><h5 id="9-JVM中可能发生的OOM的情况"><a href="#9-JVM中可能发生的OOM的情况" class="headerlink" title="9. JVM中可能发生的OOM的情况"></a>9. JVM中可能发生的OOM的情况</h5><p>什么是OOM，OOM的全称是OutOfMemory，当申请的内存太大，java虚拟机无法满足我们的时候就会抛出OOM异常。</p><p>java运行时数据区<strong>只有程序计数器不会发生OOM，其他区域都有可能发生OOM</strong></p><ul><li>方法区OOM</li><li>java堆OOM</li><li>虚拟方法栈OOM</li><li>本地方法栈OOM</li><li>本机直接内存OOM</li></ul><h5 id="10-如何确定哪些内存需要回收"><a href="#10-如何确定哪些内存需要回收" class="headerlink" title="10. 如何确定哪些内存需要回收"></a>10. 如何确定哪些内存需要回收</h5><p>主要两种方法，一种是<strong>引用计数算法</strong>，一种是<strong>可达性分析算法</strong>。</p><ul><li><p>引用计数算法：对象都拥有一个计数器，当有一个地方引用该对象则计数器加1,引用失效就减1，当计数器的值为0的时候，这个对象就需要被回收</p></li><li><p>可达性分析算法：通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。</p></li></ul><h5 id="11-哪些对象可以作为GC-ROOT"><a href="#11-哪些对象可以作为GC-ROOT" class="headerlink" title="11. 哪些对象可以作为GC ROOT"></a>11. 哪些对象可以作为GC ROOT</h5><p>基本上就是java代码可以写出来的对象引用</p><ul><li>虚拟机栈中的对象（本地变量）</li><li>方法区静态属性引用的对象(静态变量)</li><li>方法区中常量引用的对象（常量）</li><li>本地方法栈中JNI(native方法)引用的对象</li></ul><h5 id="12-引用有哪些类型"><a href="#12-引用有哪些类型" class="headerlink" title="12. 引用有哪些类型"></a>12. 引用有哪些类型</h5><ul><li><p>强引用</p><p>强引用就是指在程序代码之中普遍存在的，类似“Object obj=new Object（）”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象</p></li><li><p>软引用</p><p>软引用是用来描述一些还有用但并非必需的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常</p></li><li><p>弱引用</p><p>弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。</p></li><li><p>虚引用</p><p>虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知</p></li></ul><h5 id="13-finalize方法的作用"><a href="#13-finalize方法的作用" class="headerlink" title="13. finalize方法的作用"></a>13. finalize方法的作用</h5><p>一个对象被标记为不可达的时候，并不意味着一定会回收这个对象，还需要经过一次筛选，筛选的条件是这个对象的finalize方法是否有必要执行。。当对象没有覆盖finalize（）方法，或者finalize（）方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行“。当一个对象被判断有必要执行，会把这个对象放置在一个做作F-QUEUE的队列中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。如果在finalize方法中重新把这个对象赋到对象引用链中，这个对象就不会被回收。</p><h5 id="14-方法区是否会被回收，回收的内容是什么，什么时候需要回收方法区"><a href="#14-方法区是否会被回收，回收的内容是什么，什么时候需要回收方法区" class="headerlink" title="14. 方法区是否会被回收，回收的内容是什么，什么时候需要回收方法区"></a>14. 方法区是否会被回收，回收的内容是什么，什么时候需要回收方法区</h5><p>java虚拟机规范中没有定义必须回收方法区，并且回收方法区的收益非常低。主要回收两部分内容：<strong>废弃常量</strong>和<strong>无用的类</strong>。一个无用的类是指：该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。加载该类的ClassLoader已经被回收。该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</p><p>在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。</p><h5 id="15-有哪些垃圾收集算法"><a href="#15-有哪些垃圾收集算法" class="headerlink" title="15. 有哪些垃圾收集算法"></a>15. 有哪些垃圾收集算法</h5><ul><li><p>标记清除算法</p><p>最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。</p><p>标记清除算法可能会造成大量的内存碎片</p></li><li><p>标记整理算法</p><p>标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。</p></li><li><p>复制算法</p><p>将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着<br>的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。</p><p>这种方法的缺点就是浪费了空间。</p><p>s实际上：将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。</p></li><li><p>分代收集算法</p><p>这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。</p></li></ul><h5 id="16-Partial-GC、Minor-GC、Major-GC、Mixed-GC、Full-GC"><a href="#16-Partial-GC、Minor-GC、Major-GC、Mixed-GC、Full-GC" class="headerlink" title="16. Partial GC、Minor GC、Major GC、Mixed GC、Full GC"></a>16. Partial GC、Minor GC、Major GC、Mixed GC、Full GC</h5><table><thead><tr><th>名词</th><th>含义</th></tr></thead><tbody><tr><td>Partial GC</td><td>不是完整收集整个Java堆的垃圾收集，分为：Minor GC，Major GC和Mixed GC</td></tr><tr><td>Minor GC</td><td>指目标只是新生代的垃圾收集，Young GC</td></tr><tr><td>Major GC</td><td>指目标只是老年代的垃圾收集，Old GC，这个概念有点资料指整堆收集</td></tr><tr><td>Mixed GC</td><td>指目标是收集整个新生代以及部分老年代的垃圾收集。目前G1收集器会有这种行为</td></tr><tr><td>Full GC</td><td>收集整个Java堆和方法区的垃圾收集。</td></tr></tbody></table><h5 id="17-Remember-Set"><a href="#17-Remember-Set" class="headerlink" title="17. Remember Set"></a>17. Remember Set</h5><p>通常将java堆划分为不同的区域，每次只对一个区域进行回收。假如要现在进行一次只局限于新生代区域内的收集（Minor GC），但新生代中的对象是完全有可能被老年代所引用的，为了找出该区域中的存活对象，不得不在固定的GC Roots之外，再额外遍历整个老年代中所有对象来确保可达性分析结果的正确性，反过来也是一样。遍历整个老年代所有对象的方案虽然理论上可行，但无疑<strong>会为内存回收带来很大的性能负担</strong>。为了解决这个问题提出了跨代引用假说，即跨代引用相对于同代引用来说仅占极少数。基于这条假说，我们就不应再为了少量的跨代引用去扫描整个老年代，也不必浪费空间专门记录每一个对象是否存在及存在哪些跨代引用，只需在新生代上建立一个全局的数据结构（该结构被称为“记忆集”，RememberedSet），这个结构把老年代划分成若干小块，标识出老年代的哪一块内存会存在跨代引用。此后当发生Minor GC时，只有包含了跨代引用的小块内存里的对象才会被加入到GC Roots进行扫描。虽然这种方法需要在对象改变引用关系（如将自己或者某个属性赋值）时维护记录数据的正确性，会增加一些运行时的开销，但比起收集时扫描整个老年代来说仍然是划算的。</p><h5 id="18-什么是OopMap"><a href="#18-什么是OopMap" class="headerlink" title="18. 什么是OopMap"></a>18. 什么是OopMap</h5><p>采用可达性分析算法来识别需要回收的对象，通常第一步是进行GC-Roots的枚举（也就是在整个内存中把Gc-roots找出来），但是在整片内存中查找符合要求的对象引用需要扫描内存，这个步骤是非常耗时间的，并且枚举根节点需要在一个不变的内存快照中进行，所以会先阻塞所有用户线程的执行，因此如果花大量的时间进行枚举根节点，程序会进行长时间的停顿，这一点是无法让用户接受的。为了解决这个问题，我们使用了OopMap这种数据结构，一旦类加载动作完成的时候，HotSpot就会把对象内什么偏移量上是什么类型的数据计算出来，在即时编译过程中，也会在特定的位置记录下栈里和寄存器里哪些位置是引用。这样收集器在扫描时就可以直接从得知这些信息了，并不需要真正一个不漏地从方法区等GC Roots开始查找。</p><p>OopMap是一种数据结构，利用它可以解决枚举根节点长时间停顿的问题。</p><h5 id="19-什么是安全点"><a href="#19-什么是安全点" class="headerlink" title="19. 什么是安全点"></a>19. 什么是安全点</h5><p>虽然OopMap解决了枚举根节点的时间问题，但是程序运行时，引用关系是变化的，因此每一条指令都可能生成新的OopMap，这样的话内存中需要存放许多OopMap，占用大量的额外空间，安全点就是来解决引入OopMap带来的空间消耗问题的。</p><p>安全点的思想是不在每一条指令生成OopMap，而只在特定的指令生成OopMap，这些指令的位置就是安全点，程序执行时，只有在安全点才会停顿下来开始GC。</p><p>安全点的选定会带来一些问题，如果安全点选的太少，会让两次GC的等待时间太长，太频繁会导致工作线程经常停顿，增大运行时的负荷。因此安全点的选取必须遵循一个特定的原则，真实情况下，所以，安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定，比如方法调用，循环跳转，异常跳转等。</p><p>但是还有一个问题，如何保证GC时所有的线程都停顿在安全点位置，有两种方式，一种是抢先式中断，一种是主动式中断。</p><ul><li><p>抢先式中断式先把所有线程中断，对于没有在安全点中断的线程恢复其执行，直到它运行到安全点。</p></li><li><p>当GC需要中断线程的时候，不直接对线程操作，会在安全点位置设置标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。</p></li></ul><h5 id="20-什么是安全区域"><a href="#20-什么是安全区域" class="headerlink" title="20. 什么是安全区域"></a>20. 什么是安全区域</h5><p>安全区域解决了安全点没有解决的问题，比如安全点机制下，如果某个线程处于阻塞状态或者放弃了CPU，那么该线程无法响应JVM的中断请求。</p><p>安全区域是指在一段代码片段中，引用关系不会发生改变，在这个区域中的任意位置开始GC都是安全的。</p><p>当线程执行到安全区域中的代码时，首先标识自己已经进入了安全区域，那样，当在这段时间里JVM要发起GC时，就不用管标识自己为安全区域状态的线程了。在线程要离开安全区域时，它要检查系统是否已经完成了根节点枚举（或者是整个GC过程），如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开安全区域的信号为止。</p><h5 id="21-你知道哪些垃圾收集器"><a href="#21-你知道哪些垃圾收集器" class="headerlink" title="21. 你知道哪些垃圾收集器"></a>21. 你知道哪些垃圾收集器</h5><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/image-20200120144239677.png" alt="image-20200120144239677"></p><ul><li><p>Serial、Serial Old</p><p>Serial收集器是一个单线程的收集器，当它进行垃圾收集时，必须暂停其他所有的工作线程，然后启动一个收集线程进行垃圾收集，直到它收集结束。Serial Old是老年版本</p><p><strong>Serial作用于新生代使用复制算法，Serial Old作用于老年代使用标记整理算法。</strong></p><ul><li><p><strong>Serial如此简单，并且会引发STW，它的应用场景是什么</strong></p><p>简单而高效（与其他收集器的单线程相比），对于内存资源受限的环境，它是所有收集器里额外<strong>内存消耗最小</strong>的；对于单核处理器或处理器核心数较少的环境来说，Serial收集器由于<strong>没有线程交互的开销</strong>，专心做垃圾收集自然可以获得最高的单线程收集效率。在<strong>用户桌面的应用场景</strong>以及近年来流行的<strong>部分微服务应用</strong>中，分配给虚拟机管理的内存一般来说并不会特别大，收集几十兆甚至一两百兆的新生代，垃圾收集的停顿时间完全可以控制在十几、几十毫秒，最多一百多毫秒以内，只要不是频繁发生收集，这点停顿时间对许多用户来说是完全可以接受的。</p></li></ul></li><li><p>ParNew</p><p>ParNew收集器其实就是Serial收集器的多线程版本，新生代使用复制算法，老年代使用标记整理算法。<strong>除了Serial收集器外，目前只有它能与CMS收集器配合工作</strong>。</p></li><li><p>Parallel Scavenge</p><p>Parallel Scavenge收集器是一个新生代收集器，使用复制算法，是并行的多线程收集器。Parallel Scavenge收集器的目标是达到一个可控制的吞吐量。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值。</p><p>Parallel Scavenge收集器提供了<strong>两个参数用于精确控制吞吐量</strong>，分别是控制<strong>最大垃圾收集停顿时间</strong>的-XX：MaxGCPauseMillis参数以及<strong>直接设置吞吐量大小</strong>的-XX：GCTimeRatio参数</p></li><li><p>Parallel Old</p><p>Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。</p></li><li><p>CMS</p><p>CMS收集器是一种以获取最短回收停顿时间为目标的收集器，它的优点是<strong>并发收集、低停顿</strong>；</p><p>它的缺点是<strong>对处理器资源很敏感</strong>，在并发阶段，它虽然不会导致用户线程停顿，但却会因为占用了一部分线程而导致应用程序变慢，降低总吞吐量。CMS收集器<strong>无法处理“浮动垃圾”</strong>，有可能出现“Con-current Mode Failure”失败进而导致另一次完全“StopThe World”的Full GC的产生。基于标记清除算法，收集结束时<strong>会有大量空间碎片产生</strong>。</p><ul><li><p><strong>什么是浮动垃圾</strong></p><p>在CMS的并发标记和并发清理阶段，用户线程是还在继续运行的，程序在运行自然就还会伴随有新的垃圾对象不断产生，但这一部分垃圾对象是出现在标记过程结束以后，CMS无法在当次收集中处理掉它们，只好留待下一次垃圾收集时再清理掉。这一部分垃圾就称为“浮动垃圾”。</p></li></ul></li><li><p>G1</p><p>Garbage First（简称G1）收集器是垃圾收集器技术发展历史上的里程碑式的成果，它开创了收集器面向局部收集的设计思路和<strong>基于Region的内存布局</strong>形式。</p><p>G1不再坚持固定大小以及固定数量的分代区域划分，而是<strong>把连续的Java堆划分为多个大小相等的独立区域</strong>，每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。收集器能够对扮演不同角色的Region采用不同的策略去处理，这样无论是新创建的对象还是已经存活了一段时间、熬过多次收集的旧对象都能获取很好的收集效果。</p><p>更具体的处理思路是让G1收集器去跟踪各个Region里面的垃圾堆积的“价值”大小，价值即回收所获得的空间大小以及回收所需时间的经验值，然后在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间，优先处理回收价值收益最大的那些Region，这也就是“Garbage First”名字的由来。</p></li></ul><h5 id="22-CMS收集器的工作过程"><a href="#22-CMS收集器的工作过程" class="headerlink" title="22. CMS收集器的工作过程"></a>22. CMS收集器的工作过程</h5><ul><li><p>初始标记</p><p>标记GC-ROOTS可以直接引用的对象，会停顿工作线程，但是速度很快</p></li><li><p>并发标记</p><p>进行GC ROOTS track的过程，找到引用链其他对象，花费的时间相对长，但是可以与工作线程并发执行</p></li><li><p>重新标记</p><p>重新标记由于并发标记过程中引用关系发生变化的那部分对象，会停顿工作线程</p></li><li><p>并发清除</p><p>并发清除垃圾</p></li></ul><h5 id="23-G1收集器的工作过程"><a href="#23-G1收集器的工作过程" class="headerlink" title="23. G1收集器的工作过程"></a>23. G1收集器的工作过程</h5><ul><li><p>初始标记</p></li><li><p>并发标记</p></li><li><p>再次标记</p></li><li><p>筛选回收</p></li></ul><h5 id="24-CMS与G1的对比"><a href="#24-CMS与G1的对比" class="headerlink" title="24. CMS与G1的对比"></a>24. CMS与G1的对比</h5><p>与CMS的“标记-清除”算法不同，G1从整体来看是基于“标记-整理”算法实现的收集器，但从局部（两个Region之间）上看又是基于“标记-复制”算法实现，无论如何，这两种算法都意味着<strong>G1运作期间不会产生内存空间碎片</strong>，垃圾收集完成之后能提供规整的可用内存。</p><p>内存占用来说，虽然G1和CMS都使用卡表来处理跨代指针，但G1的卡表实现更为复杂，而且堆中每个Region，无论扮演的是新生代还是老年代角色，都必须有一份卡表，这导致<strong>G1的记忆集（和其他内存消耗）可能会占整个堆容量的20%乃至更多的内存空间</strong>；</p><p>目前在小内存应用上CMS的表现大概率仍然要会优于G1，而在大内存应用上G1则大多能发挥其优势，这个优劣势的Java堆容量平衡点通常在6GB至8GB之间</p><h5 id="25-有哪些低延迟垃圾收集器"><a href="#25-有哪些低延迟垃圾收集器" class="headerlink" title="25. 有哪些低延迟垃圾收集器"></a>25. 有哪些低延迟垃圾收集器</h5><p>Shenandoah、ZGC</p><h5 id="26-对象分配要遵循哪些策略"><a href="#26-对象分配要遵循哪些策略" class="headerlink" title="26. 对象分配要遵循哪些策略"></a>26. 对象分配要遵循哪些策略</h5><ul><li><p>对象优先在Eden分配</p><p>大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配时，虚拟<br>机将发起一次Minor GC。</p></li><li><p>大对象直接进入老年代</p></li><li><p>长期存活的对象将进入老年代</p><p>既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这点，虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。对象在Survivor区中每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。</p></li><li><p>动态对象年龄判定</p></li></ul><h5 id="27-如何判断对象的年龄"><a href="#27-如何判断对象的年龄" class="headerlink" title="27. 如何判断对象的年龄"></a>27. 如何判断对象的年龄</h5><p>为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。</p><h5 id="28-什么是内存分配担保"><a href="#28-什么是内存分配担保" class="headerlink" title="28. 什么是内存分配担保"></a>28. 什么是内存分配担保</h5><p>在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。</p><hr><h4 id="二-虚拟机执行子系统"><a href="#二-虚拟机执行子系统" class="headerlink" title="二. 虚拟机执行子系统"></a>二. 虚拟机执行子系统</h4><h5 id="1-什么是java的平台无关性和语言无关性"><a href="#1-什么是java的平台无关性和语言无关性" class="headerlink" title="1. 什么是java的平台无关性和语言无关性"></a>1. 什么是java的平台无关性和语言无关性</h5><p>平台无关性是指java代码可以不经过任何修改在不同的操作系统中运行，平台无关性是通过java虚拟机将物理硬件的区别和实际操作系统的系统调用细节屏蔽实现的，对于java来说看到的java虚拟机是一样的。语言无关性是指java虚拟机运行的是Class文件，至于这个Class文件是怎么产生的，由什么语言产生的都无所谓，只要符合虚拟机规范都可以运行。</p><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/image-20200129103320.png" alt=""></p><h5 id="2-说一下Class文件的结构"><a href="#2-说一下Class文件的结构" class="headerlink" title="2. 说一下Class文件的结构"></a>2. 说一下Class文件的结构</h5><p>《Java虚拟机规范》的规定，Class文件格式采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构中只有两种数据类型：“无符号数”和“表”。</p><p><strong>无符号数</strong>属于基本的数据类型，以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值</p><p><strong>表</strong>是由多个无符号数或者其他表作为数据项构成的复合数据类型，为了便于区分，所有表的命名都习惯性地以“_info”结尾</p><ul><li><p>魔数</p><p>魔数的作用是确定这个文件是否是一个能被虚拟机接受的Class文件，魔数为CAFEBABE</p></li><li><p>Class的版本号</p><p>版本号由次版本号和主板本号组成，虚拟机必须拒绝执行超过其版本号的Class文件。</p></li><li><p>常量池</p><p>紧接着主次版本号之后的是常量池入口，常量池中主要存放两大类常量：<strong>字面量</strong>和<strong>符号引用</strong>。</p></li><li><p>访问标志</p><p>这个标志用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被声明为final等。</p></li><li><p>类索引、父类索引和接口索引集合</p><p>类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名</p></li><li><p>字段表集合</p><p>字段表用于描述接口或者类中声明的变量。字段包括类级变量以及实例级变量，但不包括在方法内部声明的局部变量。</p></li><li><p>方法表集合</p></li><li><p>属性表集合</p></li></ul><h5 id="3-类加载时机"><a href="#3-类加载时机" class="headerlink" title="3. 类加载时机"></a>3. 类加载时机</h5><ol><li><p>遇到new、getStatic、setStatic、invokeStatic指令时</p></li><li><p>反射调用时</p></li><li><p>子类加载时，如果父类没有被加载则会先加载父类</p></li><li><p>main方法所在的类会在虚拟机启动时加载</p></li><li><p>当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄 所对应的类没有进行过初始化，则需要先触发其初始化。</p></li></ol><h5 id="4-类加载的过程"><a href="#4-类加载的过程" class="headerlink" title="4. 类加载的过程"></a>4. 类加载的过程</h5><ul><li><p>加载</p><ul><li>类加载的时机（有且仅有五个）<ol><li>遇到new、getStatic、setStatic、invokeStatic指令时</li><li>反射调用时</li><li>子类加载时，如果父类没有被加载则会先加载父类</li><li>main方法所在的类会在虚拟机启动时加载</li><li>当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄 所对应的类没有进行过初始化，则需要先触发其初始化。</li></ol></li><li>加载需要完成的事情<ol><li>通过类的全限定名获取这个类的二进制字节流</li><li>将这个二进制流代表的静态存储结构转化成运行时数据结构</li><li>在内存中生成一个java.lang.Class对象（虽然是对象，但是在hotspot中放到方法区），作为方法区这个类的各种数据的访问入口</li></ol></li><li>可以从什么地方获取二进制字节流<ul><li>各种zip包，比如jar包，war包，ear包等</li><li>网络中，典型应用是Applet</li><li>运行时计算生成，如动态代理</li><li>其他文件生成，如jsp</li><li>数据库中获取</li></ul></li><li>数组类的加载<ul><li>数组类不是由类加载器去加载的，而是虚拟机创建的</li><li>数组类的元素类型需要类加载器加载</li><li>如果数组的组件类型（Component Type，指的是数组去掉一个维度的类型）是引用类 型，那就递归采用本节中定义的加载过程去加载这个组件类型，数组C将在加载该组件类型 的类加载器的类名称空间上被标识</li><li>如果数组的组件类型不是引用类型（例如int[]数组），Java虚拟机将会把数组C标记为与 引导类加载器关联。</li><li>数组类的可见性与它的组件类型的可见性一致，如果组件类型不是引用类型，那数组类 的可见性将默认为public。</li></ul></li></ul></li><li><p>验证</p><ul><li><p>验证的目的</p><p>确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。</p></li><li><p>验证阶段的检验动作</p><ul><li><p>文件格式验证</p><p>保证输入的字节流能正确地解析并存储于方法区之内，格式上符合描述一个Java类型信息的要求。</p><p>包括魔数检验，版本号检验等……</p></li><li><p>元数据验证</p><p>对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求。</p></li><li><p>字节码验证</p><p>对类的方法体进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。</p></li><li><p>符号引用验证</p><p>发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在连接的第三阶段——解析阶段中发生。符号引用验证可以看做是对类自身以外（常量池中的各种符号引用）的信息进行匹配性校验。</p><p>包括：</p><ul><li>符号引用中通过字符串描述的全限定名是否能找到对应的类。</li><li>在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段。</li><li>符号引用中的类、字段、方法的访问性（private、protected、public、default）是否可被 当前类访问。</li></ul></li></ul></li></ul></li><li><p>准备</p><p>准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。</p></li><li><p>解析</p><p>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程</p></li><li><p>初始化</p><p>初始化阶段是执行类构造器&lt;clinit&gt;()方法的过程</p></li></ul><h5 id="5-有哪些类加载器"><a href="#5-有哪些类加载器" class="headerlink" title="5. 有哪些类加载器"></a>5. 有哪些类加载器</h5><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/image-20200120200132139.png" alt="image-20200120200132139"></p><h5 id="6-什么是双亲委派模型"><a href="#6-什么是双亲委派模型" class="headerlink" title="6. 什么是双亲委派模型"></a>6. 什么是双亲委派模型</h5><ul><li><p>类加载器之间的这种层次关系，称为类加载器的双亲委派模型。</p></li><li><p>双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。</p></li><li><p>双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。</p></li></ul><h5 id="9-双亲委派模型的好处"><a href="#9-双亲委派模型的好处" class="headerlink" title="9. 双亲委派模型的好处"></a>9. 双亲委派模型的好处</h5><p>使用双亲委派模型来组织类加载器之间的关系，有一个显而易见的好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存放在rt.jar之中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，如果用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，那系统中将会出现多个不同的Object类，Java类型体系中最基础的行为也就无法保证，应用程序也将会变得一片混乱。</p><h5 id="10-如何实现自定义类加载器"><a href="#10-如何实现自定义类加载器" class="headerlink" title="10. 如何实现自定义类加载器"></a>10. 如何实现自定义类加载器</h5><p>只需要继承ClassLoader，并覆盖findClass方法。在调用loadClass方法时，会先根据委派模型在父加载器中加载，如果加载失败，则会调用自己的findClass方法来完成加载。</p><h5 id="11-有哪些破坏双亲委派模型的例子"><a href="#11-有哪些破坏双亲委派模型的例子" class="headerlink" title="11. 有哪些破坏双亲委派模型的例子"></a>11. 有哪些破坏双亲委派模型的例子</h5><ul><li><p>第一次被破坏是双亲委派出现之前</p></li><li><p>双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷所导致的，双亲委派很好地解决了各个类加载器的基础类的统一问题（越基础的类由越上层的加载器进行加载），基础类之所以称为“基础”，是因为它们总是作为被用户代码调用的API，但世事往往没有绝对的完美，如果基础类又要调用回用户的代码，那该怎么办</p></li><li><p>双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求而导致的，这里所说的“动态性”指的是当前一些非常“热门”的名词：代码热替换</p></li></ul><h5 id="12-栈帧存放了什么"><a href="#12-栈帧存放了什么" class="headerlink" title="12. 栈帧存放了什么"></a>12. 栈帧存放了什么</h5><p>局部变量表、操作数栈、动态链接和方法返回地址</p><h5 id="13-局部变量表存放什么"><a href="#13-局部变量表存放什么" class="headerlink" title="13. 局部变量表存放什么"></a>13. 局部变量表存放什么</h5><p>局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。</p><p>局部变量表的容量以变量槽（Variable Slot，下称Slot）为最小单位</p><h5 id="14-操作数栈的运行过程"><a href="#14-操作数栈的运行过程" class="headerlink" title="14. 操作数栈的运行过程"></a>14. 操作数栈的运行过程</h5><p>当一个方法刚刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是出栈/入栈操作。例如，在做算术运算的时候是通过操作数栈来进行的，又或者在调用其他方法的时候是通过操作数栈来进行参数传递的。</p><h5 id="15-动态链接是什么"><a href="#15-动态链接是什么" class="headerlink" title="15. 动态链接是什么"></a>15. 动态链接是什么</h5><p>每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接</p>]]></content>
      
      
      <categories>
          
          <category> java进阶 </category>
          
          <category> java虚拟机 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
            <tag> java </tag>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>探究java虚拟机：垃圾收集器总结</title>
      <link href="/2019/12/19/%E6%8E%A2%E7%A9%B6java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%9A%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E6%80%BB%E7%BB%93/"/>
      <url>/2019/12/19/%E6%8E%A2%E7%A9%B6java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%9A%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h4 id="一-经典的垃圾收集器特点总结"><a href="#一-经典的垃圾收集器特点总结" class="headerlink" title="一. 经典的垃圾收集器特点总结"></a>一. 经典的垃圾收集器特点总结</h4><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/%E6%8E%A2%E7%A9%B6java%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%BD%8E%E5%BB%B6%E8%BF%9F%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/image-20200129113418.png" alt=""></p><h5 id="1-Serial收集器"><a href="#1-Serial收集器" class="headerlink" title="1. Serial收集器"></a>1. Serial收集器</h5><p>Serial收集器的工作方式是停止所有正在运行的用户线程，然后启动一个线程进行垃圾收集。它工作在新生代，使用复制算法。特点是简单高效，没有额外的内存开销，并且没有线程切换开销。适合客户端场景和微服务等管理内存小的场景。</p><h5 id="2-ParNew收集器"><a href="#2-ParNew收集器" class="headerlink" title="2. ParNew收集器"></a>2. ParNew收集器</h5><p>ParNew收集器实质上是Serial收集器的多线程并行版本，除了同时使用多条线程进行垃圾收集之外，其他和Serial收集器一样。它的特点是除了Serial收集器外，目前只有它能与CMS收集器配合工作。但是也是HotSpot虚拟机第一款退出历史舞台的垃圾收集器。</p><p>ParNew收集器在单核心处理器的环境不比Serial收集器性能好，甚至由于存在线程交互的开销，该收集器在某些时候不能超越Serial收集器。</p><p>随着可以被使用的处理器核心数量的增加，ParNew对于垃圾收集时系统资源的高效利用还是很有好处的。它默认开启的收集线程数与处理器核心数量相同。</p><h5 id="3-Parallel-Scavenge收集器"><a href="#3-Parallel-Scavenge收集器" class="headerlink" title="3. Parallel Scavenge收集器"></a>3. Parallel Scavenge收集器</h5><p>Parallel Scavenge收集器作用于新生代，使用复制算法，采用多线程进行垃圾收集，与ParNew收集器类似，但是不同的地方是，Parallel Scavenge收集器的目标是达到一个可控制的吞吐量（吞吐量是指CPU处理用户代码的时间与总CPU时间的之比）。</p><p>Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX：GCTimeRatio参数。</p><h5 id="4-Serial-Old收集器"><a href="#4-Serial-Old收集器" class="headerlink" title="4. Serial Old收集器"></a>4. Serial Old收集器</h5><p>Serial收集器的老年版本，使用标记整理算法，作用于老年代，其他特性与Serial收集器一样。</p><h5 id="5-Parallel-Old收集器"><a href="#5-Parallel-Old收集器" class="headerlink" title="5. Parallel Old收集器"></a>5. Parallel Old收集器</h5><p>Parallel Scavenge收集器的老年版本，基于标记整理算法实现。它的意义是使得新生代和老年代都可以达到一个可控制的吞吐量的目标。</p><h5 id="6-CMS收集器"><a href="#6-CMS收集器" class="headerlink" title="6. CMS收集器"></a>6. CMS收集器</h5><p>作用于老年代，使用标记清除算法，是第一个真正可以与用户工作线程并发执行的垃圾收集器，目标是获取最短回收停顿时间。它的优点是并发收集和低停顿。缺点是对CPU资源敏感，无法清除浮动垃圾，会产生大量的内存碎片。</p><p>CMS默认启动的回收线程数是（处理器核心数量+3）/4，也就是说，如果处理器核心数在四个或以上，并发回收时垃圾收集线程只占用不超过25%的处理器运算资源，并且会随着处理器核心数量的增加而下降。</p><p>工作流程如下：</p><ul><li><p>初始标记</p><p>仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，会发生STW。</p></li><li><p>并发标记</p><p>从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行。</p></li><li><p>重新标记</p><p>为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间通常会比初始标记阶段稍长一些，但也远比并发标记阶段的时间短。</p></li><li><p>并发清除</p><p>清理删除掉标记阶段判断的已经死亡的对象，由于采用标记清除算法不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。</p></li></ul><h5 id="7-G1收集器"><a href="#7-G1收集器" class="headerlink" title="7. G1收集器"></a>7. G1收集器</h5><p>G1收集器开创了收集器面向局部收集的设计思路和基于Region的内存布局形式，它不再按照新生代和老年代的方式划分堆，而是将堆划分成相等大小的区域（Region），G1收集器会跟踪每一个区域的回收价值，即回收所获得的空间大小以及回收所需时间的经验值，然后在后台维护一个优先级列表，默认的回收策略是优先回收价值大的区域。Region中还有一类特殊的Humongous区域，专门用来存储大对象。G1认为只要大小超过了一个Region容量一半的对象即可判定为大对象。</p><p>工作过程如下：</p><ul><li><p>初始标记</p><p>仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS指针的值，让下一阶段用户线程并发运行时，能正确地在可用的Region中分配新对象。需要停顿工作线程。</p></li><li><p>并发标记</p><p>从GC Root开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行。当对象图扫描完成以后，还要重新处理SATB记录下的在并发时有引用变动的对象。</p></li><li><p>重新标记<br>对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录。</p></li><li><p>筛选回收</p><p>负责更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划，可以自由选择任意多个Region构成回收集，然后把决定回收的那一部分Region的存活对象复制到空的Region中，再清理掉整个旧Region的全部空间。这里的操作涉及存活对象的移动，是必须暂停用户线程，由多条收集器线程并行完成的。</p></li></ul><hr><h4 id="二-低延迟垃圾收集器"><a href="#二-低延迟垃圾收集器" class="headerlink" title="二. 低延迟垃圾收集器"></a>二. 低延迟垃圾收集器</h4><p>衡量一款垃圾收集器的标准有：内存占用、吞吐量、延迟。垃圾收集器很难同时实现三个标准，但是随着计算机硬件的发展，内存占用和吞吐量逐渐变得不是问题，内存价格的下降使得不在过分关注内存占用问题，CPU性能的提高使得吞吐量提高，但是延迟问题无法通过计算机硬件的进步解决，比如说回收1TB的内存花费的时间自然要比回收1GB的内存的时间长。Shenandoah和ZGC都是低延迟的垃圾收集器，它们都可以在任意可管理的（譬如现在ZGC只能管理4TB以内的堆）堆容量下，实现垃圾收集的停顿都不超过十毫秒的目标。</p><h5 id="1-Shenandoah收集器"><a href="#1-Shenandoah收集器" class="headerlink" title="1. Shenandoah收集器"></a>1. Shenandoah收集器</h5><p>Shenandoah收集器不是由Oracle开发的“官方“垃圾收集器，它是由RedHat公司开发的新型收集器项目，现在已经贡献给OpenJDK 12，并且成为OpenJDK 12的新特性。它的目标是实现一种能在任何堆内存大小下都可以把垃圾收集的停顿时间限制在十毫秒以内的垃圾收集器。</p><p>Shenandoah更像是G1的下一代继承者，它们两者有着相似的堆内存布局，在初始标记、并发标记等许多阶段的处理思路上都高度一致，甚至还直接共享了一部分实现代码。</p><p><strong>Shenandoah相比起G1的改进主要有三点</strong>：</p><ul><li>支持并发的整理算法</li><li>不会有专门的新生代Region或者老年代Region的存在，没有实现分代</li><li>Shenandoah摒弃了在G1中耗费大量内存和计算资源去维护的记忆集，改用名为“连接矩阵”的全局数据结构来记录跨Region的引用关系，降低了处理跨代指针时的记忆集维护消耗，也降低了伪共享问题的发生概率</li></ul><p><strong>工作过程</strong>：</p><ul><li><p>初始标记</p><p>与G1一样，首先标记与GC Roots直接关联的对象，这个阶段仍是“Stop The World”的，但停顿时间与堆大小无关，只与GC Roots的数量相关。</p></li><li><p>并发标记</p><p>与G1一样，遍历对象图，标记出全部可达的对象，这个阶段是与用户线程一起并发的，时间长短取决于堆中存活对象的数量以及对象图的结构复杂程度。</p></li><li><p>最终标记</p><p>与G1一样，处理剩余的SATB扫描，并在这个阶段统计出回收价值最高的Region，将这些Region构成一组回收集（Collection Set）。最终标记阶段也会有一小段短暂的停顿。</p></li><li><p>并发清理</p><p>这个阶段用于清理那些整个区域内连一个存活对象都没有找到的Region。</p></li><li><p>并发回收</p><p>把回收集里面的存活对象先复制一份到其他未被使用的Region之中，并发运行，此时工作线程的引用会发生变化，会通过读屏障和被称为“Brooks Pointers”的转发指针来解决。</p></li><li><p>初始引用更新</p><p>并发回收阶段复制对象结束后，还需要把堆中所有指向旧对象的引用修正到复制后的新地址，这个操作称为引用更新。引用更新的初始化阶段实际上并未做什么具体的处理，设立这个阶段只是为了建立一个线程集合点，确保所有并发回收阶段中进行的收集器线程都已完成分配给它们的对象移动任务而已。初始引用更新时间很短，会产生一个非常短暂的停顿。</p></li><li><p>并发引用更新</p><p>真正开始进行引用更新操作，这个阶段是与用户线程一起并发的，时间长短取决于内存中涉及的引用数量的多少。并发引用更新与并发标记不同，它不再需要沿着对象图来搜索，只需要按照内存物理地址的顺序，线性地搜索出引用类型，把旧值改为新值即可。</p></li><li><p>最终引用更新</p><p>修正存在于GC Roots中的引用</p></li><li><p>并发清理</p><p>经过并发回收和引用更新之后，整个回收集中所有的Region已再无存活对象，这些Region都变成ImmediateGarbage Regions了，最后再调用一次并发清理过程来回收这些Region的内存空间，供以后新对象分配使用。</p></li></ul><p><strong>转发指针</strong></p><p>转发指针是实现对象移动与用户程序并发的一种解决方案。</p><p>此前，要做类似的并发操作，通常是在被移动对象原有的内存上设置保护陷阱，一旦用户程序访问到归属于旧对象的内存空间就会产生自陷中段，进入预设好的异常处理器中，再由其中的代码逻辑把访问转发到复制后的新对象上。虽然确实能够实现对象移动与用户线程并发，但是如果没有操作系统层面的直接支持，这种方案将导致用户态频繁切换到核心态，代价是非常大的，不能频繁使用。</p><p>新方案不需要用到内存保护陷阱，而是在原有对象布局结构的最前面统一增加一个新的引用字段，在正常不处于并发移动的情况下，该引用指向对象自己。使用时只需要修改一处指针的值，即旧对象上转发指针的引用位置，使其指向新对象，便可将所有对该对象的访问转发到新的副本上。</p><p>转发指针与某些早期Java虚拟机使用过的句柄定位有一些相似之处，两者都是一种间接性的对象访问方式，差别是句柄通常会统一存储在专门的句柄池中，而转发指针是分散存放在每一个对象头前面。</p><h5 id="2-ZGC收集器"><a href="#2-ZGC收集器" class="headerlink" title="2. ZGC收集器"></a>2. ZGC收集器</h5><p>ZGC是jdk 11的新特性，由Oracle公司研发，目标是在尽可能对吞吐量影响不太大的前提下，实现在任意堆内存大小下都可以把垃圾收集的停顿时间限制在十毫秒以内的低延迟。</p><p>ZGC收集器是一款基于Region内存布局的，（暂时）不设分代的，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-整理算法的，以低延迟为首要目标的一款垃圾收集器</p><p>ZGC的内存布局与Shenandoah和G1一样，也采用基于Region的堆内存布局，但不同的是，ZGC的Region具有动态性——动态创建和销毁，以及动态的区域容量大小。在x64硬件平台下，ZGC的Region可以具有大、中、小三类容量</p><ul><li>小型Region：容量固定为2MB，用于放置小于256KB的小对象。</li><li>中型Region：容量固定为32MB，用于放置大于等于256KB但小于4MB的对象。</li><li>大型Region：容量不固定，可以动态变化，但必须为2MB的整数倍，用于放置4MB或以上的大对象。每个大型Region中只会存放一个大对象</li></ul><p><strong>染色指针</strong></p><p>染色指针是一种直接将少量额外的信息存储在指针上的技术，因为操作系统寻址的时候并不需要用到指针上的所有位，那么剩下的位就可以存一些信息。染色指针直接将引用的信息记录在引用中，这样一个对象是否存活只与其引用有关，与对象本身无关，这样即使对象移动了，也能知道一个引用是否需要重置。</p><p><strong>工作过程</strong></p><ul><li><p>并发标记</p><p>与G1、Shenandoah一样，并发标记是遍历对象图做可达性分析的阶段，但是ZGC的<strong>标记是在指针上而不是在对象上进行的，标记阶段会更新染色指针中的Marked 0、Marked 1标志位</strong>。</p></li><li><p>并发预备重分配</p><p>统计得出本次收集过程要清理哪些Region，将这些Region组成重分配集。</p><p>ZGC的重分配集只是决定了里面的存活对象会被重新复制到其他的Region中，里面的Region会被释放，而并不能说回收行为就只是针对这个集合里面的Region进行，因为标记过程是针对全堆的</p></li><li><p>并发重分配</p><p>把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个转发表，记录从旧对象到新对象的转向关系。</p><p>因为染色指针技术，ZGC收集器能仅从引用上就明确得知一个对象是否处于重分配集之中，如果用户线程此时并发访问了位于重分配集中的对象，这次访问将会被预置的内存屏障所截获，然后立即根据Region上的转发表记录将访问转发到新复制的对象上，并同时修正更新该引用的值，使其直接指向新对象，ZGC将这种行为称为指针的“自愈”能力。</p><p>染色指针带来的好处：</p><ul><li>只有第一次访问旧对象会陷入转发，也就是额外的开销只有一次</li><li>一旦重分配集中某个Region的存活对象都复制完毕后，这个Region就可以立即释放用于新对象的分配，旧指针一旦被使用，它们都是可以自愈的</li></ul></li><li><p>并发重映射</p><p>重映射所做的就是修正整个堆中指向重分配集中旧对象的所有引用，ZGC很巧妙地把并发重映射阶段要做的工作，合并到了下一次垃圾收集循环中的并发标记阶段里去完成，反正它们都是要遍历所有对象的，这样合并就节省了一次遍历对象图的开销。</p></li></ul><hr><p><em>参考：《深入理解java虚拟机：JVM高级特性与最佳实践（第三版）》周志明</em></p>]]></content>
      
      
      <categories>
          
          <category> java进阶 </category>
          
          <category> java虚拟机 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
            <tag> java </tag>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring原理总结</title>
      <link href="/2019/12/19/Spring%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/"/>
      <url>/2019/12/19/Spring%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>本文不是源码分析，源码分析的过程很复杂，本文的目的是使用精简的语言，基于源码分析的基础，将框架原理进行总结。</p><h5 id="1-Spring-Boot自动装配的原理"><a href="#1-Spring-Boot自动装配的原理" class="headerlink" title="1. Spring Boot自动装配的原理"></a>1. Spring Boot自动装配的原理</h5><p>首先在使用Spring Boot的时候main方法所在的类会加上一个叫做<code>@SpringBootApplication</code>的注解，这个注解之上主要有三个注解</p><ul><li><p><code>@SpringBootConfiguration</code></p></li><li><p><code>@EnableAutoConfiguratio</code></p></li><li><p><code>@ComponentScan</code></p></li></ul><p>其中<code>@SpringBootConfiguratio</code>注解被<code>@Configuration</code>注解修饰，作用是将main方法所在的那个类声明成一个配置类，然后<code>@ComponentScan</code>的作用使容器扫描与main方法同一级的包及其子包，然后最重要的一个注解<code>@EnableAutoConfiguration</code>，<strong>这个注解与自动装配密切相关</strong>。</p><p>注解<code>@EnableAutoConfiguration</code>上面有一个注解<code>@Import</code>，这个注解的作用是将一些类注入到容器中，<code>@Import</code>注解有三个用法</p><ul><li><p>直接将某一个指定的类注入到容器中</p></li><li><p>借助于ImportBeanDefinitionRegistrar接口将类注入到容器中</p></li><li><p>借助于ImportSelector类将类注入到容器中</p></li></ul><p>Spring Boot使用的是第三种方式，借助一个叫<code>AutoConfigurationImportSelector</code>的类，返回类的全限定名数组，这些数组中的元素所代表的的类都会被注入到容器中，具体是哪些类呢？首先会去加载所有Spring预先定义的配置条件信息，这些信息位于<code>org.springframework.boot.autoconfigure</code>包下的<code>META-INF/spring-autoconfigure-metadata.properties</code>文件中，这些类都是被注解<code>@Configuration</code>修饰的配置类，这些配置类还存在一些和条件装配相关的注解，配置类中约定好了配置方式，这样用户就不需要手动去配置，如果需要修改模型信息，可以修改yml文件的内容，这也就是<strong>所谓的约定大于配置</strong>。</p><h5 id="2-Spring-IOC的原理"><a href="#2-Spring-IOC的原理" class="headerlink" title="2. Spring IOC的原理"></a>2. Spring IOC的原理</h5><p>首先解释一下什么是IOC，IOC的意思是控制反转，控制反转是一种思想，它指的是将类管理自身成员变量的权利交给第三方容器，也就是说在没有使用IOC容器的时候，一个对象所依赖的成员变量是需要自己管理、实例化的，但是有了IOC之后，程序员只要通过配置信息描述对象与对象之间的关系，然后交给ioc容器，容器会自动帮我们配置好类与类之间的关系。</p><p>然后在Spring中实现控制反转的方式叫做DI，也就是依赖注入。首先我们使用Spring创建IOC容器是通过ApplicationContex这个类创建的，而这个类有一个顶层的类，叫做BeanFactory，BeanFactory这个类不是由用户直接使用的，而是Spring内部的一个很重要的类，它是实现了ioc的基本功能。ApplicationContex也有几个子类，如<code>ClassPathXmlApplicationContex</code>、<code>FileSystemXmlApplicationContex</code>、<code>AnnotationConfigApplicationContex</code>，这些子类的区别在于配置信息的位置和类型不同，比如<code>ClassPathXmlApplicationContex</code>的配置信息是XML文件，并且会在ClassPath下找，而<code>FileSystemXmlApplicationContex</code>的配置文件是xml文件，但是需要提供一个全路径名的xml文件，<code>AnnotationConfigApplicationContex</code>它的配置信息是java类和一些注解。</p><p>以最简单的<code>ClassPathXmlApplicationContex</code>为例说明IoC容器的初始化过程，首先在构造对象时会调用构造方法，构造方法中有一个叫做<strong>refresh</strong>的方法，它的作用是销毁旧的容器并创建新的容器，也就是初始化的过程。</p><p>首先refresh方法会先加一个同步代码块然后执行后续的步骤，第一步是准备工作，记录下容器的启动时间、标记“已启动”状态、处理配置文件中的占位符、校验配置文件。然后调用obtainFreshBeanFactory()方法返回一个BeanFactory，这个方法内部具体的过程是，首先关闭旧的BeanFactory然后new一个类型是<strong>DefaultListableBeanFactory</strong>的<code>BeanFactory</code>。生成之后会调用<strong>loadBeanDefinition</strong>来加载bean到BeanFactory。</p><p>这个<code>BeanDefinition</code>代表了一个bean的所有信息，如bean的名称，bean的id，bean的类型，是否为单例，是否懒加载，所有的依赖等信息。因此实现ioc容器的一个最重要的步骤是如何把配置信息转化成BeanDefinition对象。</p><p>具体如何和加载BeanDefinition的呢，它会去实例化一个<code>XmlBeanDefinitionReader</code>对象，通过它来加载配置信息，首先会根据配置文件的信息比如说文件地址把这个文件读到内存中，因为这个文件是xml格式的，所以会把他转化为一个DOM树，方便后面的操作，后面就是对这棵DOM树进行解析，将其中的标签解析成BeanDefinition并且把它们注册到BeanFactory中，具体就是把BeanDefinition放入一个Map中。这样我们的BeanFactory就得到了所有的<code>BeanDefinition</code>，但是此时还没有进行初始化。</p><p>Spring 把我们在 xml 配置的 bean 都注册以后，会设置类加载器，然后还会”手动”注册一些特殊的 bean，这些bean有特殊的作用，比如：</p><p>最后一步是把那些没有声明为懒加载的bean实例化，并放在一个单例池中。</p><p>之后我们使用这个容器一般是通过<code>getBean</code>方法来获取一个Bean的实例，这个方法的参数是bean的Name或者是Bean的Class，首先回去单例池中找，如果找到了就返回，否则会去检查当前这个bean所对应的BeanDefinition是否存在，如果存在就回去尝试加载这个<code>BeanDefinition</code>的类，然后实例化，最后进行依赖注入，得到bean实例后返回。</p><h5 id="3-Spring-AOP的原理"><a href="#3-Spring-AOP的原理" class="headerlink" title="3. Spring AOP的原理"></a>3. Spring AOP的原理</h5><p>首先解释一下什么是AOP，AOP的全称是面向切面编程，在开发的过程中，有很多的代码是与业务无关的，比如说日志的打印等，但是这些代码可能散落在源代码的各个地方，如果以硬编码的形式实现则维护难度比较大，而使用AOP可以预编译或者运行时动态代理的方式对对象的方法进行增强。</p><p>Spring的AOP主要使用了两种技术，一是JDK的Proxy类，二是Cglib。Spring AOP作用于IOC容器中的bean，具体的实现是这样的，在从Spring ioc容器中获取bean的过程中，Spring容器提供了一个调用点给用户，具体来说是在创建出bean的实例后，会调用BeanPostProcessor来处理bean，AOP就是在这个过程中对bean的实例进行了动态代理，然后返回的也是代理类。</p><h5 id="4-Spring-MVC的实现原理"><a href="#4-Spring-MVC的实现原理" class="headerlink" title="4. Spring MVC的实现原理"></a>4. Spring MVC的实现原理</h5><p>首先，用户从客户端过来的请求会被一个叫做DispatcherServlet的前端控制器拦截，这个DispatcherServlet类继承自Servlet，拦截到请求后，会通过HandlerMapping去查找处理这个请求的uri的handler，因为handler有多种类型，所以会去找到handleAdapter去处理，处理完以后会返回一个ModelAndView，然后前端控制器会把这个ModelAndView交给视图解析器进行解析和渲染，然后把响应发送到客户端。</p><p><img src="https://severinblog-1257009269.cos.ap-guangzhou.myqcloud.com/SSM%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/clipboard.png" alt=""></p><ol><li>用户发送请求至前端控制器DispatcherServlet</li><li>DispatcherServlet收到请求后，调用HandlerMapping处理器映射器，请求获取Handle</li><li>处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet； </li><li>DispatcherServlet 调用 HandlerAdapter处理器适配器</li><li>HandlerAdapter 经过适配调用 具体处理器(Handler，也叫后端控制器)； </li><li>Handler执行完成返回ModelAndView； </li><li>HandlerAdapter将Handler执行结果ModelAndView返回给DispatcherServlet； </li><li>DispatcherServlet将ModelAndView传给ViewResolver视图解析器进行解析； </li><li>ViewResolver解析后返回具体View； </li><li>DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中） 、</li><li>DispatcherServlet响应用户。</li></ol>]]></content>
      
      
      <categories>
          
          <category> java进阶 </category>
          
          <category> java虚拟机 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
            <tag> java </tag>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
